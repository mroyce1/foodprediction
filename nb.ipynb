{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>FoodGroup</th>\n",
       "      <th>ShortDescrip</th>\n",
       "      <th>Descrip</th>\n",
       "      <th>CommonName</th>\n",
       "      <th>MfgName</th>\n",
       "      <th>ScientificName</th>\n",
       "      <th>Energy_kcal</th>\n",
       "      <th>Protein_g</th>\n",
       "      <th>Fat_g</th>\n",
       "      <th>Carb_g</th>\n",
       "      <th>Sugar_g</th>\n",
       "      <th>Fiber_g</th>\n",
       "      <th>...</th>\n",
       "      <th>VitB12_USRDA</th>\n",
       "      <th>VitC_USRDA</th>\n",
       "      <th>VitE_USRDA</th>\n",
       "      <th>Folate_USRDA</th>\n",
       "      <th>Niacin_USRDA</th>\n",
       "      <th>Riboflavin_USRDA</th>\n",
       "      <th>Thiamin_USRDA</th>\n",
       "      <th>Calcium_USRDA</th>\n",
       "      <th>Copper_USRDA</th>\n",
       "      <th>Magnesium_USRDA</th>\n",
       "      <th>Phosphorus_USRDA</th>\n",
       "      <th>Selenium_USRDA</th>\n",
       "      <th>Zinc_USRDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>BUTTER,WITH SALT</td>\n",
       "      <td>Butter, salted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>81.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154667</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.026154</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.034286</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.008182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>BUTTER,WHIPPED,WITH SALT</td>\n",
       "      <td>Butter, whipped, with salt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>81.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154667</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.026154</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.032857</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.004545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>BUTTER OIL,ANHYDROUS</td>\n",
       "      <td>Butter oil, anhydrous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>876.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>99.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>CHEESE,BLUE</td>\n",
       "      <td>Cheese, blue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>353.0</td>\n",
       "      <td>21.40</td>\n",
       "      <td>28.74</td>\n",
       "      <td>2.34</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.293846</td>\n",
       "      <td>0.024167</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.054762</td>\n",
       "      <td>0.552857</td>\n",
       "      <td>0.263636</td>\n",
       "      <td>0.241818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>CHEESE,BRICK</td>\n",
       "      <td>Cheese, brick</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>371.0</td>\n",
       "      <td>23.24</td>\n",
       "      <td>29.68</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017333</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.007375</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.011667</td>\n",
       "      <td>0.561667</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.644286</td>\n",
       "      <td>0.263636</td>\n",
       "      <td>0.236364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID               FoodGroup              ShortDescrip  \\\n",
       "0  1001  Dairy and Egg Products  BUTTER,WITH SALT           \n",
       "1  1002  Dairy and Egg Products  BUTTER,WHIPPED,WITH SALT   \n",
       "2  1003  Dairy and Egg Products  BUTTER OIL,ANHYDROUS       \n",
       "3  1004  Dairy and Egg Products  CHEESE,BLUE                \n",
       "4  1005  Dairy and Egg Products  CHEESE,BRICK               \n",
       "\n",
       "                      Descrip CommonName MfgName ScientificName  Energy_kcal  \\\n",
       "0  Butter, salted              NaN        NaN     NaN            717.0         \n",
       "1  Butter, whipped, with salt  NaN        NaN     NaN            717.0         \n",
       "2  Butter oil, anhydrous       NaN        NaN     NaN            876.0         \n",
       "3  Cheese, blue                NaN        NaN     NaN            353.0         \n",
       "4  Cheese, brick               NaN        NaN     NaN            371.0         \n",
       "\n",
       "   Protein_g  Fat_g  Carb_g  Sugar_g  Fiber_g     ...      VitB12_USRDA  \\\n",
       "0  0.85       81.11  0.06    0.06     0.0         ...      0.070833       \n",
       "1  0.85       81.11  0.06    0.06     0.0         ...      0.054167       \n",
       "2  0.28       99.48  0.00    0.00     0.0         ...      0.004167       \n",
       "3  21.40      28.74  2.34    0.50     0.0         ...      0.508333       \n",
       "4  23.24      29.68  2.79    0.51     0.0         ...      0.525000       \n",
       "\n",
       "   VitC_USRDA  VitE_USRDA  Folate_USRDA  Niacin_USRDA  Riboflavin_USRDA  \\\n",
       "0  0.0         0.154667    0.0075        0.002625      0.026154           \n",
       "1  0.0         0.154667    0.0075        0.002625      0.026154           \n",
       "2  0.0         0.186667    0.0000        0.000188      0.003846           \n",
       "3  0.0         0.016667    0.0900        0.063500      0.293846           \n",
       "4  0.0         0.017333    0.0500        0.007375      0.270000           \n",
       "\n",
       "   Thiamin_USRDA  Calcium_USRDA  Copper_USRDA  Magnesium_USRDA  \\\n",
       "0  0.004167       0.020000       0.000000      0.004762          \n",
       "1  0.004167       0.020000       0.000018      0.004762          \n",
       "2  0.000833       0.003333       0.000001      0.000000          \n",
       "3  0.024167       0.440000       0.000044      0.054762          \n",
       "4  0.011667       0.561667       0.000027      0.057143          \n",
       "\n",
       "   Phosphorus_USRDA  Selenium_USRDA  Zinc_USRDA  \n",
       "0  0.034286          0.018182        0.008182    \n",
       "1  0.032857          0.018182        0.004545    \n",
       "2  0.004286          0.000000        0.000909    \n",
       "3  0.552857          0.263636        0.241818    \n",
       "4  0.644286          0.263636        0.236364    \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "f=open('nndb_flat.csv')\n",
    "food_data = pd.read_csv(f)\n",
    "food_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FoodGroup</th>\n",
       "      <th>Energy_kcal</th>\n",
       "      <th>Protein_g</th>\n",
       "      <th>Fat_g</th>\n",
       "      <th>Carb_g</th>\n",
       "      <th>Sugar_g</th>\n",
       "      <th>Fiber_g</th>\n",
       "      <th>VitA_mcg</th>\n",
       "      <th>VitB6_mg</th>\n",
       "      <th>VitB12_mcg</th>\n",
       "      <th>VitC_mg</th>\n",
       "      <th>VitE_mg</th>\n",
       "      <th>Folate_mcg</th>\n",
       "      <th>Niacin_mg</th>\n",
       "      <th>Riboflavin_mg</th>\n",
       "      <th>Thiamin_mg</th>\n",
       "      <th>Calcium_mg</th>\n",
       "      <th>Copper_mcg</th>\n",
       "      <th>Iron_mg</th>\n",
       "      <th>Magnesium_mg</th>\n",
       "      <th>Manganese_mg</th>\n",
       "      <th>Phosphorus_mg</th>\n",
       "      <th>Selenium_mcg</th>\n",
       "      <th>Zinc_mg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>81.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.005</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>81.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.005</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.16</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.004</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>876.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>99.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>353.0</td>\n",
       "      <td>21.40</td>\n",
       "      <td>28.74</td>\n",
       "      <td>2.34</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>0.166</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.016</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.029</td>\n",
       "      <td>528.0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.31</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>387.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>371.0</td>\n",
       "      <td>23.24</td>\n",
       "      <td>29.68</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>0.065</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.014</td>\n",
       "      <td>674.0</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.43</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.012</td>\n",
       "      <td>451.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                FoodGroup  Energy_kcal  Protein_g  Fat_g  Carb_g  Sugar_g  \\\n",
       "0  Dairy and Egg Products  717.0        0.85       81.11  0.06    0.06      \n",
       "1  Dairy and Egg Products  717.0        0.85       81.11  0.06    0.06      \n",
       "2  Dairy and Egg Products  876.0        0.28       99.48  0.00    0.00      \n",
       "3  Dairy and Egg Products  353.0        21.40      28.74  2.34    0.50      \n",
       "4  Dairy and Egg Products  371.0        23.24      29.68  2.79    0.51      \n",
       "\n",
       "   Fiber_g  VitA_mcg  VitB6_mg  VitB12_mcg  VitC_mg  VitE_mg  Folate_mcg  \\\n",
       "0  0.0      684.0     0.003     0.17        0.0      2.32     3.0          \n",
       "1  0.0      684.0     0.003     0.13        0.0      2.32     3.0          \n",
       "2  0.0      840.0     0.001     0.01        0.0      2.80     0.0          \n",
       "3  0.0      198.0     0.166     1.22        0.0      0.25     36.0         \n",
       "4  0.0      292.0     0.065     1.26        0.0      0.26     20.0         \n",
       "\n",
       "   Niacin_mg  Riboflavin_mg  Thiamin_mg  Calcium_mg  Copper_mcg  Iron_mg  \\\n",
       "0  0.042      0.034          0.005       24.0        0.000       0.02      \n",
       "1  0.042      0.034          0.005       24.0        0.016       0.16      \n",
       "2  0.003      0.005          0.001       4.0         0.001       0.00      \n",
       "3  1.016      0.382          0.029       528.0       0.040       0.31      \n",
       "4  0.118      0.351          0.014       674.0       0.024       0.43      \n",
       "\n",
       "   Magnesium_mg  Manganese_mg  Phosphorus_mg  Selenium_mcg  Zinc_mg  \n",
       "0  2.0           0.000         24.0           1.0           0.09     \n",
       "1  2.0           0.004         23.0           1.0           0.05     \n",
       "2  0.0           0.000         3.0            0.0           0.01     \n",
       "3  23.0          0.009         387.0          14.5          2.66     \n",
       "4  24.0          0.012         451.0          14.5          2.60     "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. Drop the useless colonums\n",
    "food_data=food_data.drop(columns=['ID','ShortDescrip','Descrip','CommonName','MfgName','ScientificName'])\n",
    "food_data = food_data[food_data.columns.drop(list(food_data.filter(regex='USRDA')))]\n",
    "food_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [FoodGroup, Energy_kcal, Protein_g, Fat_g, Carb_g, Sugar_g, Fiber_g, VitA_mcg, VitB6_mg, VitB12_mcg, VitC_mg, VitE_mg, Folate_mcg, Niacin_mg, Riboflavin_mg, Thiamin_mg, Calcium_mg, Copper_mcg, Iron_mg, Magnesium_mg, Manganese_mg, Phosphorus_mg, Selenium_mcg, Zinc_mg]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8618, 24)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. the check of repeated data and duplicated datas\n",
    "import numpy as np\n",
    "#repeated rows\n",
    "#food_data.isnull().any()\n",
    "print(food_data[food_data.isnull().values==True])\n",
    "\n",
    "#process of duplicated rows\n",
    "food_data.duplicated()\n",
    "food_data.drop_duplicates()\n",
    "food_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 24)\n",
      "(97, 24)\n",
      "(2, 24)\n",
      "(0, 24)\n",
      "(0, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FoodGroup</th>\n",
       "      <th>Energy_kcal</th>\n",
       "      <th>Protein_g</th>\n",
       "      <th>Fat_g</th>\n",
       "      <th>Carb_g</th>\n",
       "      <th>Sugar_g</th>\n",
       "      <th>Fiber_g</th>\n",
       "      <th>VitA_mcg</th>\n",
       "      <th>VitB6_mg</th>\n",
       "      <th>VitB12_mcg</th>\n",
       "      <th>VitC_mg</th>\n",
       "      <th>VitE_mg</th>\n",
       "      <th>Folate_mcg</th>\n",
       "      <th>Niacin_mg</th>\n",
       "      <th>Riboflavin_mg</th>\n",
       "      <th>Thiamin_mg</th>\n",
       "      <th>Calcium_mg</th>\n",
       "      <th>Copper_mcg</th>\n",
       "      <th>Iron_mg</th>\n",
       "      <th>Magnesium_mg</th>\n",
       "      <th>Manganese_mg</th>\n",
       "      <th>Phosphorus_mg</th>\n",
       "      <th>Selenium_mcg</th>\n",
       "      <th>Zinc_mg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>902.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>902.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>862.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>862.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>902.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>763.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6417</th>\n",
       "      <td>Sweets</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8122</th>\n",
       "      <td>American Indian/Alaska Native Foods</td>\n",
       "      <td>900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8177</th>\n",
       "      <td>American Indian/Alaska Native Foods</td>\n",
       "      <td>900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8180</th>\n",
       "      <td>American Indian/Alaska Native Foods</td>\n",
       "      <td>900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8455</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8509</th>\n",
       "      <td>Sweets</td>\n",
       "      <td>368.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>92.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                FoodGroup  Energy_kcal  Protein_g  Fat_g  \\\n",
       "610   Fats and Oils                        902.0        0.0        100.0   \n",
       "611   Fats and Oils                        902.0        0.0        100.0   \n",
       "629   Fats and Oils                        884.0        0.0        100.0   \n",
       "630   Fats and Oils                        884.0        0.0        100.0   \n",
       "631   Fats and Oils                        884.0        0.0        100.0   \n",
       "632   Fats and Oils                        884.0        0.0        100.0   \n",
       "633   Fats and Oils                        884.0        0.0        100.0   \n",
       "634   Fats and Oils                        884.0        0.0        100.0   \n",
       "635   Fats and Oils                        862.0        0.0        100.0   \n",
       "636   Fats and Oils                        884.0        0.0        100.0   \n",
       "637   Fats and Oils                        884.0        0.0        100.0   \n",
       "638   Fats and Oils                        884.0        0.0        100.0   \n",
       "639   Fats and Oils                        884.0        0.0        100.0   \n",
       "653   Fats and Oils                        884.0        0.0        100.0   \n",
       "654   Fats and Oils                        884.0        0.0        100.0   \n",
       "655   Fats and Oils                        884.0        0.0        100.0   \n",
       "656   Fats and Oils                        884.0        0.0        100.0   \n",
       "657   Fats and Oils                        884.0        0.0        100.0   \n",
       "658   Fats and Oils                        862.0        0.0        100.0   \n",
       "659   Fats and Oils                        884.0        0.0        100.0   \n",
       "660   Fats and Oils                        884.0        0.0        100.0   \n",
       "661   Fats and Oils                        884.0        0.0        100.0   \n",
       "662   Fats and Oils                        884.0        0.0        100.0   \n",
       "663   Fats and Oils                        900.0        0.0        100.0   \n",
       "664   Fats and Oils                        902.0        0.0        100.0   \n",
       "665   Fats and Oils                        884.0        0.0        100.0   \n",
       "666   Fats and Oils                        884.0        0.0        100.0   \n",
       "667   Fats and Oils                        884.0        0.0        100.0   \n",
       "668   Fats and Oils                        763.0        0.0        100.0   \n",
       "669   Fats and Oils                        884.0        0.0        100.0   \n",
       "...             ...                          ...        ...          ...   \n",
       "744   Fats and Oils                        884.0        0.0        100.0   \n",
       "745   Fats and Oils                        884.0        0.0        100.0   \n",
       "746   Fats and Oils                        884.0        0.0        100.0   \n",
       "747   Fats and Oils                        884.0        0.0        100.0   \n",
       "748   Fats and Oils                        884.0        0.0        100.0   \n",
       "750   Fats and Oils                        884.0        0.0        100.0   \n",
       "751   Fats and Oils                        884.0        0.0        100.0   \n",
       "752   Fats and Oils                        884.0        0.0        100.0   \n",
       "753   Fats and Oils                        884.0        0.0        100.0   \n",
       "754   Fats and Oils                        884.0        0.0        100.0   \n",
       "757   Fats and Oils                        884.0        0.0        100.0   \n",
       "758   Fats and Oils                        884.0        0.0        100.0   \n",
       "760   Fats and Oils                        884.0        0.0        100.0   \n",
       "761   Fats and Oils                        884.0        0.0        100.0   \n",
       "763   Fats and Oils                        884.0        0.0        100.0   \n",
       "764   Fats and Oils                        884.0        0.0        100.0   \n",
       "770   Fats and Oils                        884.0        0.0        100.0   \n",
       "774   Fats and Oils                        884.0        0.0        100.0   \n",
       "787   Fats and Oils                        900.0        0.0        100.0   \n",
       "788   Fats and Oils                        900.0        0.0        100.0   \n",
       "789   Fats and Oils                        884.0        0.0        100.0   \n",
       "790   Fats and Oils                        884.0        0.0        100.0   \n",
       "791   Fats and Oils                        884.0        0.0        100.0   \n",
       "6417  Sweets                               0.0          0.0        0.0     \n",
       "8122  American Indian/Alaska Native Foods  900.0        0.0        100.0   \n",
       "8177  American Indian/Alaska Native Foods  900.0        0.0        100.0   \n",
       "8180  American Indian/Alaska Native Foods  900.0        0.0        100.0   \n",
       "8455  Fats and Oils                        884.0        0.0        100.0   \n",
       "8509  Sweets                               368.0        0.0        0.0     \n",
       "8599  Fats and Oils                        884.0        0.0        100.0   \n",
       "\n",
       "      Carb_g  Sugar_g  Fiber_g  VitA_mcg  VitB6_mg  VitB12_mcg  VitC_mg  \\\n",
       "610   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "611   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "629   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "630   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "631   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "632   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "633   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "634   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "635   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "636   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "637   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "638   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "639   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "653   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "654   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "655   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "656   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "657   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "658   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "659   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "660   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "661   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "662   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "663   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "664   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "665   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "666   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "667   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "668   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "669   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "...   ...     ...      ...      ...       ...       ...         ...       \n",
       "744   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "745   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "746   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "747   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "748   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "750   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "751   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "752   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "753   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "754   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "757   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "758   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "760   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "761   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "763   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "764   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "770   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "774   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "787   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "788   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "789   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "790   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "791   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "6417  100.0   0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "8122  0.0     0.0      0.0      694.0     0.0       0.0         0.0       \n",
       "8177  0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "8180  0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "8455  0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "8509  100.0   92.7     0.0      0.0       0.0       0.0         0.0       \n",
       "8599  0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "\n",
       "      VitE_mg  Folate_mcg  Niacin_mg  Riboflavin_mg  Thiamin_mg  Calcium_mg  \\\n",
       "610   2.70     0.0         0.0        0.0            0.0         0.0          \n",
       "611   0.60     0.0         0.0        0.0            0.0         0.0          \n",
       "629   6.13     0.0         0.0        0.0            0.0         0.0          \n",
       "630   8.10     0.0         0.0        0.0            0.0         0.0          \n",
       "631   32.30    0.0         0.0        0.0            0.0         0.0          \n",
       "632   149.40   0.0         0.0        0.0            0.0         0.0          \n",
       "633   15.69    0.0         0.0        0.0            0.0         0.0          \n",
       "634   8.18     0.0         0.0        0.0            0.0         0.0          \n",
       "635   0.09     0.0         0.0        0.0            0.0         0.0          \n",
       "636   14.35    0.0         0.0        0.0            0.0         1.0          \n",
       "637   15.94    0.0         0.0        0.0            0.0         0.0          \n",
       "638   1.40     0.0         0.0        0.0            0.0         0.0          \n",
       "639   41.08    0.0         0.0        0.0            0.0         0.0          \n",
       "653   1.80     0.0         0.0        0.0            0.0         0.0          \n",
       "654   35.30    0.0         0.0        0.0            0.0         0.0          \n",
       "655   41.08    0.0         0.0        0.0            0.0         0.0          \n",
       "656   34.10    0.0         0.0        0.0            0.0         0.0          \n",
       "657   34.10    0.0         0.0        0.0            0.0         0.0          \n",
       "658   3.81     0.0         0.0        0.0            0.0         0.0          \n",
       "659   11.40    0.0         0.0        0.0            0.0         0.0          \n",
       "660   3.80     0.0         0.0        0.0            0.0         0.0          \n",
       "661   0.00     0.0         0.0        0.0            0.0         0.0          \n",
       "662   28.80    0.0         0.0        0.0            0.0         0.0          \n",
       "663   14.30    0.0         0.0        0.0            0.0         0.0          \n",
       "664   2.80     0.0         0.0        0.0            0.0         0.0          \n",
       "665   0.40     0.0         0.0        0.0            0.0         0.0          \n",
       "666   39.20    0.0         0.0        0.0            0.0         0.0          \n",
       "667   4.00     0.0         0.0        0.0            0.0         0.0          \n",
       "668   8.18     0.0         0.0        0.0            0.0         0.0          \n",
       "669   47.20    0.0         0.0        0.0            0.0         0.0          \n",
       "...     ...    ...         ...        ...            ...         ...          \n",
       "744   8.18     0.0         0.0        0.0            0.0         0.0          \n",
       "745   8.10     0.0         0.0        0.0            0.0         0.0          \n",
       "746   8.10     0.0         0.0        0.0            0.0         0.0          \n",
       "747   8.10     0.0         0.0        0.0            0.0         0.0          \n",
       "748   12.10    0.0         0.0        0.0            0.0         0.0          \n",
       "750   3.81     0.0         0.0        0.0            0.0         1.0          \n",
       "751   3.81     0.0         0.0        0.0            0.0         1.0          \n",
       "752   3.81     0.0         0.0        0.0            0.0         1.0          \n",
       "753   0.09     0.0         0.0        0.0            0.0         2.0          \n",
       "754   3.81     0.0         0.0        0.0            0.0         1.0          \n",
       "757   3.81     0.0         0.0        0.0            0.0         2.0          \n",
       "758   8.10     0.0         0.0        0.0            0.0         0.0          \n",
       "760   6.13     0.0         0.0        0.0            0.0         0.0          \n",
       "761   6.13     0.0         0.0        0.0            0.0         0.0          \n",
       "763   8.18     0.0         0.0        0.0            0.0         0.0          \n",
       "764   9.21     0.0         0.0        0.0            0.0         0.0          \n",
       "770   21.80    0.0         0.0        0.0            0.0         0.0          \n",
       "774   21.64    0.0         0.0        0.0            0.0         0.0          \n",
       "787   17.46    0.0         0.0        0.0            0.0         0.0          \n",
       "788   8.18     0.0         0.0        0.0            0.0         0.0          \n",
       "789   8.18     0.0         0.0        0.0            0.0         0.0          \n",
       "790   8.18     0.0         0.0        0.0            0.0         0.0          \n",
       "791   35.30    0.0         0.0        0.0            0.0         0.0          \n",
       "6417  0.00     0.0         0.0        0.0            0.0         0.0          \n",
       "8122  8.27     0.0         0.0        0.0            0.0         0.0          \n",
       "8177  0.00     0.0         0.0        0.0            0.0         0.0          \n",
       "8180  0.00     0.0         0.0        0.0            0.0         0.0          \n",
       "8455  14.84    0.0         0.0        0.0            0.0         0.0          \n",
       "8509  0.00     0.0         0.0        0.0            0.0         0.0          \n",
       "8599  14.78    0.0         0.0        0.0            0.0         0.0          \n",
       "\n",
       "      Copper_mcg  Iron_mg  Magnesium_mg  Manganese_mg  Phosphorus_mg  \\\n",
       "610   0.000       0.00     0.0           0.0           0.0             \n",
       "611   0.000       0.00     0.0           0.0           0.0             \n",
       "629   0.000       0.00     0.0           0.0           0.0             \n",
       "630   0.000       0.00     0.0           0.0           0.0             \n",
       "631   0.000       0.07     0.0           0.0           0.0             \n",
       "632   0.000       0.00     0.0           0.0           0.0             \n",
       "633   0.000       0.03     0.0           0.0           0.0             \n",
       "634   0.000       0.05     0.0           0.0           0.0             \n",
       "635   0.000       0.04     0.0           0.0           0.0             \n",
       "636   0.000       0.56     0.0           0.0           0.0             \n",
       "637   0.000       0.01     0.0           0.0           0.0             \n",
       "638   0.000       0.00     0.0           0.0           0.0             \n",
       "639   0.000       0.03     0.0           0.0           0.0             \n",
       "653   0.000       0.00     0.0           0.0           0.0             \n",
       "654   0.000       0.00     0.0           0.0           0.0             \n",
       "655   0.000       0.00     0.0           0.0           0.0             \n",
       "656   0.000       0.00     0.0           0.0           0.0             \n",
       "657   0.000       0.00     0.0           0.0           0.0             \n",
       "658   0.000       0.00     0.0           0.0           0.0             \n",
       "659   0.000       0.00     0.0           0.0           0.0             \n",
       "660   0.000       0.00     0.0           0.0           0.0             \n",
       "661   0.000       0.00     0.0           0.0           0.0             \n",
       "662   0.000       0.00     0.0           0.0           0.0             \n",
       "663   0.000       0.00     0.0           0.0           0.0             \n",
       "664   0.000       0.00     0.0           0.0           0.0             \n",
       "665   0.000       0.00     0.0           0.0           0.0             \n",
       "666   0.000       0.00     0.0           0.0           0.0             \n",
       "667   0.000       0.00     0.0           0.0           0.0             \n",
       "668   0.000       0.00     0.0           0.0           0.0             \n",
       "669   0.000       0.00     0.0           0.0           0.0             \n",
       "...     ...        ...     ...           ...           ...             \n",
       "744   0.000       0.02     0.0           0.0           0.0             \n",
       "745   0.000       0.00     0.0           0.0           0.0             \n",
       "746   0.000       0.00     0.0           0.0           0.0             \n",
       "747   0.000       0.00     0.0           0.0           0.0             \n",
       "748   0.000       0.00     0.0           0.0           0.0             \n",
       "750   0.000       0.29     0.0           0.0           0.0             \n",
       "751   0.000       0.15     0.0           0.0           0.0             \n",
       "752   0.000       0.15     0.0           0.0           0.0             \n",
       "753   0.000       0.15     0.0           0.0           0.0             \n",
       "754   0.000       0.15     0.0           0.0           0.0             \n",
       "757   0.000       0.15     0.0           0.0           0.0             \n",
       "758   0.000       0.00     0.0           0.0           0.0             \n",
       "760   0.000       0.00     0.0           0.0           0.0             \n",
       "761   0.000       0.00     0.0           0.0           0.0             \n",
       "763   0.000       0.02     0.0           0.0           0.0             \n",
       "764   0.000       0.02     0.0           0.0           0.0             \n",
       "770   0.000       0.00     0.0           0.0           0.0             \n",
       "774   0.000       0.00     0.0           0.0           0.0             \n",
       "787   0.000       0.00     0.0           0.0           0.0             \n",
       "788   0.000       0.05     0.0           0.0           0.0             \n",
       "789   0.000       0.05     0.0           0.0           0.0             \n",
       "790   0.000       0.05     0.0           0.0           0.0             \n",
       "791   0.000       0.00     0.0           0.0           0.0             \n",
       "6417  0.000       0.00     0.0           0.0           0.0             \n",
       "8122  0.000       0.00     0.0           0.0           0.0             \n",
       "8177  0.000       0.00     0.0           0.0           0.0             \n",
       "8180  0.000       0.00     0.0           0.0           0.0             \n",
       "8455  0.000       0.00     0.0           0.0           0.0             \n",
       "8509  0.221       0.10     0.0           0.0           0.0             \n",
       "8599  0.000       0.13     0.0           0.0           0.0             \n",
       "\n",
       "      Selenium_mcg  Zinc_mg  \n",
       "610   0.2           0.00     \n",
       "611   0.2           0.11     \n",
       "629   0.0           0.00     \n",
       "630   0.0           0.00     \n",
       "631   0.0           0.00     \n",
       "632   0.0           0.00     \n",
       "633   0.0           0.01     \n",
       "634   0.0           0.01     \n",
       "635   0.0           0.00     \n",
       "636   0.0           0.00     \n",
       "637   0.0           0.00     \n",
       "638   0.0           0.00     \n",
       "639   0.0           0.00     \n",
       "653   0.0           0.00     \n",
       "654   0.0           0.00     \n",
       "655   0.0           0.00     \n",
       "656   0.0           0.00     \n",
       "657   0.0           0.00     \n",
       "658   0.0           0.00     \n",
       "659   0.0           0.00     \n",
       "660   0.0           0.00     \n",
       "661   0.0           0.00     \n",
       "662   0.0           0.00     \n",
       "663   0.0           0.00     \n",
       "664   0.2           0.00     \n",
       "665   0.0           0.00     \n",
       "666   0.0           0.00     \n",
       "667   0.0           0.00     \n",
       "668   0.0           0.00     \n",
       "669   0.0           0.00     \n",
       "...   ...            ...     \n",
       "744   0.0           0.00     \n",
       "745   0.0           0.00     \n",
       "746   0.0           0.00     \n",
       "747   0.0           0.00     \n",
       "748   0.0           0.00     \n",
       "750   0.0           0.04     \n",
       "751   0.0           0.08     \n",
       "752   0.0           0.04     \n",
       "753   0.0           0.04     \n",
       "754   0.0           0.04     \n",
       "757   0.0           0.04     \n",
       "758   0.0           0.00     \n",
       "760   0.0           0.00     \n",
       "761   0.0           0.00     \n",
       "763   0.0           0.00     \n",
       "764   0.0           0.00     \n",
       "770   0.0           0.00     \n",
       "774   0.0           0.00     \n",
       "787   0.0           0.00     \n",
       "788   0.0           0.01     \n",
       "789   0.0           0.01     \n",
       "790   0.0           0.01     \n",
       "791   0.0           0.00     \n",
       "6417  0.0           0.00     \n",
       "8122  3.0           0.00     \n",
       "8177  0.0           0.00     \n",
       "8180  0.0           0.00     \n",
       "8455  0.0           0.00     \n",
       "8509  0.6           0.00     \n",
       "8599  0.0           0.02     \n",
       "\n",
       "[99 rows x 24 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first, we will perform anomaly detection based entirely on domain knowledge\n",
    "\n",
    "for feature in [x for x in food_data.columns if '_g' in x]:\n",
    "    print(food_data[food_data[feature]>=100.0].shape)\n",
    "#no instance with protein, fat, carb, sugar or fiber > 100. there are however instances with protein=100 and carb=100. let's look at those\n",
    "food_data[(food_data.Fat_g>=100.0) | (food_data.Carb_g>=100.0)]\n",
    "#fats and oils as well as artificial sweeteners. so the values make sense. there are nevertheless some traces of other nutrients found. however, we consider this to be in the range of measurement accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.1494\n",
      "100.1703043\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FoodGroup</th>\n",
       "      <th>Energy_kcal</th>\n",
       "      <th>Protein_g</th>\n",
       "      <th>Fat_g</th>\n",
       "      <th>Carb_g</th>\n",
       "      <th>Sugar_g</th>\n",
       "      <th>Fiber_g</th>\n",
       "      <th>VitA_mcg</th>\n",
       "      <th>VitB6_mg</th>\n",
       "      <th>VitB12_mcg</th>\n",
       "      <th>VitC_mg</th>\n",
       "      <th>VitE_mg</th>\n",
       "      <th>Folate_mcg</th>\n",
       "      <th>Niacin_mg</th>\n",
       "      <th>Riboflavin_mg</th>\n",
       "      <th>Thiamin_mg</th>\n",
       "      <th>Calcium_mg</th>\n",
       "      <th>Copper_mcg</th>\n",
       "      <th>Iron_mg</th>\n",
       "      <th>Magnesium_mg</th>\n",
       "      <th>Manganese_mg</th>\n",
       "      <th>Phosphorus_mg</th>\n",
       "      <th>Selenium_mcg</th>\n",
       "      <th>Zinc_mg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8154</th>\n",
       "      <td>American Indian/Alaska Native Foods</td>\n",
       "      <td>899.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>99.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                FoodGroup  Energy_kcal  Protein_g  Fat_g  \\\n",
       "632   Fats and Oils                        884.0        0.00       100.0   \n",
       "8154  American Indian/Alaska Native Foods  899.0        0.56       99.6    \n",
       "\n",
       "      Carb_g  Sugar_g  Fiber_g  VitA_mcg  VitB6_mg  VitB12_mcg  VitC_mg  \\\n",
       "632   0.0     0.0      0.0      0.0       0.0       0.0         0.0       \n",
       "8154  0.0     0.0      0.0      10.0      0.0       0.0         0.0       \n",
       "\n",
       "      VitE_mg  Folate_mcg  Niacin_mg  Riboflavin_mg  Thiamin_mg  Calcium_mg  \\\n",
       "632   149.40   0.0         0.0        0.0            0.000       0.0          \n",
       "8154  10.28    0.0         0.0        0.0            0.011       0.0          \n",
       "\n",
       "      Copper_mcg  Iron_mg  Magnesium_mg  Manganese_mg  Phosphorus_mg  \\\n",
       "632   0.0         0.0      0.0           0.0           0.0             \n",
       "8154  0.0         0.0      0.0           0.0           0.0             \n",
       "\n",
       "      Selenium_mcg  Zinc_mg  \n",
       "632   0.0           0.0      \n",
       "8154  3.3           0.0      "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now, let's sum over all features. however, let's excluse carb_g and fiber_g because they obviously depend on other features. \n",
    "s = 0.0\n",
    "greater_100 = []\n",
    "grams = [x for x in food_data.columns if ('_g' in x and 'Carb' not in x and 'Fiber' not in x)]\n",
    "mgrams = [x for x in food_data.columns if '_mg' in x]\n",
    "mcgrams = [x for x in food_data.columns if '_mcg' in x]\n",
    "\n",
    "#using numpy to avoid float imprecisions\n",
    "mg_1000 = np.float64(1000.0)\n",
    "mcg_1000000 = np.float64(1000000.0)\n",
    "for i in range(food_data.shape[0]):\n",
    "    s = np.float64(0)\n",
    "    for feature in grams:\n",
    "        s += food_data.loc[i,feature]\n",
    "        \n",
    "    for feature in mgrams:\n",
    "        s += food_data.loc[i,feature] / mg_1000\n",
    "        \n",
    "    for feature in mcgrams:\n",
    "        s += food_data.loc[i,feature] / mcg_1000000\n",
    "    #leaving some leverage room for potential imprecisions\n",
    "    if(s > 100.1):\n",
    "        greater_100.append(i)\n",
    "        print(s)\n",
    "food_data.iloc[greater_100,:]\n",
    "\n",
    "#two instances found whose sum is slightly above 100.1. Again, fats and oils. So, we still consider these to be valid items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FoodGroup</th>\n",
       "      <th>Energy_kcal</th>\n",
       "      <th>Protein_g</th>\n",
       "      <th>Fat_g</th>\n",
       "      <th>Carb_g</th>\n",
       "      <th>Sugar_g</th>\n",
       "      <th>Fiber_g</th>\n",
       "      <th>VitA_mcg</th>\n",
       "      <th>VitB6_mg</th>\n",
       "      <th>VitB12_mcg</th>\n",
       "      <th>VitC_mg</th>\n",
       "      <th>VitE_mg</th>\n",
       "      <th>Folate_mcg</th>\n",
       "      <th>Niacin_mg</th>\n",
       "      <th>Riboflavin_mg</th>\n",
       "      <th>Thiamin_mg</th>\n",
       "      <th>Calcium_mg</th>\n",
       "      <th>Copper_mcg</th>\n",
       "      <th>Iron_mg</th>\n",
       "      <th>Magnesium_mg</th>\n",
       "      <th>Manganese_mg</th>\n",
       "      <th>Phosphorus_mg</th>\n",
       "      <th>Selenium_mcg</th>\n",
       "      <th>Zinc_mg</th>\n",
       "      <th>lof</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>81.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.005</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.578307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>81.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.005</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.16</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.004</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.579225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>876.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>99.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.068213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>353.0</td>\n",
       "      <td>21.40</td>\n",
       "      <td>28.74</td>\n",
       "      <td>2.34</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>0.166</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.016</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.029</td>\n",
       "      <td>528.0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.31</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>387.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2.66</td>\n",
       "      <td>-0.503732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>371.0</td>\n",
       "      <td>23.24</td>\n",
       "      <td>29.68</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>0.065</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.014</td>\n",
       "      <td>674.0</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.43</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.012</td>\n",
       "      <td>451.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2.60</td>\n",
       "      <td>-0.737995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                FoodGroup  Energy_kcal  Protein_g  Fat_g  Carb_g  Sugar_g  \\\n",
       "0  Dairy and Egg Products  717.0        0.85       81.11  0.06    0.06      \n",
       "1  Dairy and Egg Products  717.0        0.85       81.11  0.06    0.06      \n",
       "2  Dairy and Egg Products  876.0        0.28       99.48  0.00    0.00      \n",
       "3  Dairy and Egg Products  353.0        21.40      28.74  2.34    0.50      \n",
       "4  Dairy and Egg Products  371.0        23.24      29.68  2.79    0.51      \n",
       "\n",
       "   Fiber_g  VitA_mcg  VitB6_mg  VitB12_mcg  VitC_mg  VitE_mg  Folate_mcg  \\\n",
       "0  0.0      684.0     0.003     0.17        0.0      2.32     3.0          \n",
       "1  0.0      684.0     0.003     0.13        0.0      2.32     3.0          \n",
       "2  0.0      840.0     0.001     0.01        0.0      2.80     0.0          \n",
       "3  0.0      198.0     0.166     1.22        0.0      0.25     36.0         \n",
       "4  0.0      292.0     0.065     1.26        0.0      0.26     20.0         \n",
       "\n",
       "   Niacin_mg  Riboflavin_mg  Thiamin_mg  Calcium_mg  Copper_mcg  Iron_mg  \\\n",
       "0  0.042      0.034          0.005       24.0        0.000       0.02      \n",
       "1  0.042      0.034          0.005       24.0        0.016       0.16      \n",
       "2  0.003      0.005          0.001       4.0         0.001       0.00      \n",
       "3  1.016      0.382          0.029       528.0       0.040       0.31      \n",
       "4  0.118      0.351          0.014       674.0       0.024       0.43      \n",
       "\n",
       "   Magnesium_mg  Manganese_mg  Phosphorus_mg  Selenium_mcg  Zinc_mg       lof  \n",
       "0  2.0           0.000         24.0           1.0           0.09     0.578307  \n",
       "1  2.0           0.004         23.0           1.0           0.05     0.579225  \n",
       "2  0.0           0.000         3.0            0.0           0.01     1.068213  \n",
       "3  23.0          0.009         387.0          14.5          2.66    -0.503732  \n",
       "4  24.0          0.012         451.0          14.5          2.60    -0.737995  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "dummy = pd.DataFrame()\n",
    "for col in set(food_data.FoodGroup):\n",
    "    X = food_data[food_data.FoodGroup==col]\n",
    "    X = X.drop(columns=['FoodGroup'])\n",
    "    clf = LocalOutlierFactor(n_neighbors=20, algorithm='auto', contamination=0.1, n_jobs=-1)\n",
    "    clf.fit_predict(X)\n",
    "    clf.kneighbors(X)\n",
    "    vals = -clf._decision_function(X)\n",
    "    bla = pd.DataFrame(vals, index=food_data[food_data.FoodGroup==col].index)\n",
    "    dummy = dummy.append(bla)\n",
    "    \n",
    "food_data_lof = food_data.assign(lof=dummy)\n",
    "food_data_lof.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.979610494094296e-17"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = []\n",
    "for col in set(food_data_lof.FoodGroup):\n",
    "    group = food_data_lof[food_data_lof.FoodGroup==col]\n",
    "    std = group.lof.std()\n",
    "    mean = group.lof.mean()\n",
    "    for item in group.lof:\n",
    "        items.append((item-mean)/std)\n",
    "\n",
    "food_data_lof = food_data_lof.drop(columns=['lof'])\n",
    "food_data_lof = food_data_lof.assign(lof=items)\n",
    "food_data_lof.lof.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vegetables and Vegetable Products size before: 828    dropping: 56\n",
      "Dairy and Egg Products size before: 264    dropping: 1\n",
      "Spices and Herbs size before: 64    dropping: 0\n",
      "Soups, Sauces, and Gravies size before: 452    dropping: 39\n",
      "American Indian/Alaska Native Foods size before: 165    dropping: 7\n",
      "Lamb, Veal, and Game Products size before: 438    dropping: 2\n",
      "Snacks size before: 171    dropping: 10\n",
      "Legumes and Legume Products size before: 389    dropping: 5\n",
      "Sweets size before: 347    dropping: 1\n",
      "Breakfast Cereals size before: 363    dropping: 8\n",
      "Fast Foods size before: 371    dropping: 18\n",
      "Restaurant Foods size before: 108    dropping: 8\n",
      "Poultry Products size before: 390    dropping: 37\n",
      "Baby Foods size before: 362    dropping: 7\n",
      "Beef Products size before: 946    dropping: 69\n",
      "Cereal Grains and Pasta size before: 183    dropping: 2\n",
      "Fats and Oils size before: 219    dropping: 6\n",
      "Baked Products size before: 797    dropping: 24\n",
      "Beverages size before: 315    dropping: 21\n",
      "Meals, Entrees, and Side Dishes size before: 113    dropping: 4\n",
      "Fruits and Fruit Juices size before: 346    dropping: 37\n",
      "Nut and Seed Products size before: 133    dropping: 15\n",
      "Pork Products size before: 343    dropping: 18\n",
      "Sausages and Luncheon Meats size before: 244    dropping: 10\n",
      "Finfish and Shellfish Products size before: 267    dropping: 35\n"
     ]
    }
   ],
   "source": [
    "for col in set(food_data_lof.FoodGroup):\n",
    "    group = food_data_lof[food_data_lof.FoodGroup==col]\n",
    "    std = group.lof.std()\n",
    "    mean = group.lof.mean()\n",
    "    to_be_dropped = group[(group.lof >= 0.9) | (group.lof <= -0.9)]\n",
    "    print(f'{col} size before: {food_data_lof[food_data_lof.FoodGroup==col].shape[0]}    dropping: {len(to_be_dropped)}')\n",
    "    food_data_lof = food_data_lof.drop(to_be_dropped.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8178, 25)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_data_lof.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new dataset\n",
    "f = \"nndb_flat_lof.csv\"\n",
    "#food_data_lof.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>FoodGroup</th>\n",
       "      <th>Energy_kcal</th>\n",
       "      <th>Protein_g</th>\n",
       "      <th>Fat_g</th>\n",
       "      <th>Carb_g</th>\n",
       "      <th>Sugar_g</th>\n",
       "      <th>Fiber_g</th>\n",
       "      <th>VitA_mcg</th>\n",
       "      <th>VitB6_mg</th>\n",
       "      <th>VitB12_mcg</th>\n",
       "      <th>VitC_mg</th>\n",
       "      <th>VitE_mg</th>\n",
       "      <th>Folate_mcg</th>\n",
       "      <th>Niacin_mg</th>\n",
       "      <th>Riboflavin_mg</th>\n",
       "      <th>Thiamin_mg</th>\n",
       "      <th>Calcium_mg</th>\n",
       "      <th>Copper_mcg</th>\n",
       "      <th>Iron_mg</th>\n",
       "      <th>Magnesium_mg</th>\n",
       "      <th>Manganese_mg</th>\n",
       "      <th>Phosphorus_mg</th>\n",
       "      <th>Selenium_mcg</th>\n",
       "      <th>Zinc_mg</th>\n",
       "      <th>lof</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>81.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.005</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.092685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>81.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.005</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.16</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.004</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.153993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>876.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>99.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.157274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>353.0</td>\n",
       "      <td>21.40</td>\n",
       "      <td>28.74</td>\n",
       "      <td>2.34</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>0.166</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.016</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.029</td>\n",
       "      <td>528.0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.31</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>387.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2.66</td>\n",
       "      <td>-0.145267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>371.0</td>\n",
       "      <td>23.24</td>\n",
       "      <td>29.68</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>0.065</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.014</td>\n",
       "      <td>674.0</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.43</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.012</td>\n",
       "      <td>451.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2.60</td>\n",
       "      <td>-0.156169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0               FoodGroup  Energy_kcal  Protein_g  Fat_g  Carb_g  \\\n",
       "0  0           Dairy and Egg Products  717.0        0.85       81.11  0.06     \n",
       "1  1           Dairy and Egg Products  717.0        0.85       81.11  0.06     \n",
       "2  2           Dairy and Egg Products  876.0        0.28       99.48  0.00     \n",
       "3  3           Dairy and Egg Products  353.0        21.40      28.74  2.34     \n",
       "4  4           Dairy and Egg Products  371.0        23.24      29.68  2.79     \n",
       "\n",
       "   Sugar_g  Fiber_g  VitA_mcg  VitB6_mg  VitB12_mcg  VitC_mg  VitE_mg  \\\n",
       "0  0.06     0.0      684.0     0.003     0.17        0.0      2.32      \n",
       "1  0.06     0.0      684.0     0.003     0.13        0.0      2.32      \n",
       "2  0.00     0.0      840.0     0.001     0.01        0.0      2.80      \n",
       "3  0.50     0.0      198.0     0.166     1.22        0.0      0.25      \n",
       "4  0.51     0.0      292.0     0.065     1.26        0.0      0.26      \n",
       "\n",
       "   Folate_mcg  Niacin_mg  Riboflavin_mg  Thiamin_mg  Calcium_mg  Copper_mcg  \\\n",
       "0  3.0         0.042      0.034          0.005       24.0        0.000        \n",
       "1  3.0         0.042      0.034          0.005       24.0        0.016        \n",
       "2  0.0         0.003      0.005          0.001       4.0         0.001        \n",
       "3  36.0        1.016      0.382          0.029       528.0       0.040        \n",
       "4  20.0        0.118      0.351          0.014       674.0       0.024        \n",
       "\n",
       "   Iron_mg  Magnesium_mg  Manganese_mg  Phosphorus_mg  Selenium_mcg  Zinc_mg  \\\n",
       "0  0.02     2.0           0.000         24.0           1.0           0.09      \n",
       "1  0.16     2.0           0.004         23.0           1.0           0.05      \n",
       "2  0.00     0.0           0.000         3.0            0.0           0.01      \n",
       "3  0.31     23.0          0.009         387.0          14.5          2.66      \n",
       "4  0.43     24.0          0.012         451.0          14.5          2.60      \n",
       "\n",
       "        lof  \n",
       "0  0.092685  \n",
       "1 -0.153993  \n",
       "2 -0.157274  \n",
       "3 -0.145267  \n",
       "4 -0.156169  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lof results varied when run on different computers. we load the data here in order to provide replicable results\n",
    "food_data = pd.read_csv('nndb_flat_lof.csv')\n",
    "food_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_data=food_data.drop(columns=['Unnamed: 0','lof'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FoodGroup</th>\n",
       "      <th>Energy_kcal</th>\n",
       "      <th>Protein_g</th>\n",
       "      <th>Fat_g</th>\n",
       "      <th>Carb_g</th>\n",
       "      <th>Sugar_g</th>\n",
       "      <th>Fiber_g</th>\n",
       "      <th>VitA_mcg</th>\n",
       "      <th>VitB6_mg</th>\n",
       "      <th>VitB12_mcg</th>\n",
       "      <th>VitC_mg</th>\n",
       "      <th>VitE_mg</th>\n",
       "      <th>Folate_mcg</th>\n",
       "      <th>Niacin_mg</th>\n",
       "      <th>Riboflavin_mg</th>\n",
       "      <th>Thiamin_mg</th>\n",
       "      <th>Calcium_mg</th>\n",
       "      <th>Copper_mcg</th>\n",
       "      <th>Iron_mg</th>\n",
       "      <th>Magnesium_mg</th>\n",
       "      <th>Manganese_mg</th>\n",
       "      <th>Phosphorus_mg</th>\n",
       "      <th>Selenium_mcg</th>\n",
       "      <th>Zinc_mg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>81.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.005</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>81.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.005</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.16</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.004</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>876.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>99.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>353.0</td>\n",
       "      <td>21.40</td>\n",
       "      <td>28.74</td>\n",
       "      <td>2.34</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>0.166</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.016</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.029</td>\n",
       "      <td>528.0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.31</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>387.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>371.0</td>\n",
       "      <td>23.24</td>\n",
       "      <td>29.68</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>0.065</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.014</td>\n",
       "      <td>674.0</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.43</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.012</td>\n",
       "      <td>451.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>334.0</td>\n",
       "      <td>20.75</td>\n",
       "      <td>27.68</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.235</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.070</td>\n",
       "      <td>184.0</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.50</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.034</td>\n",
       "      <td>188.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>300.0</td>\n",
       "      <td>19.80</td>\n",
       "      <td>24.26</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>0.227</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.028</td>\n",
       "      <td>388.0</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.33</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.038</td>\n",
       "      <td>347.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>376.0</td>\n",
       "      <td>25.18</td>\n",
       "      <td>29.20</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.031</td>\n",
       "      <td>673.0</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.64</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.021</td>\n",
       "      <td>490.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>406.0</td>\n",
       "      <td>24.04</td>\n",
       "      <td>33.82</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.027</td>\n",
       "      <td>675.0</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.16</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.033</td>\n",
       "      <td>473.0</td>\n",
       "      <td>28.3</td>\n",
       "      <td>3.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>387.0</td>\n",
       "      <td>23.37</td>\n",
       "      <td>30.60</td>\n",
       "      <td>4.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.046</td>\n",
       "      <td>643.0</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.21</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.012</td>\n",
       "      <td>464.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>394.0</td>\n",
       "      <td>23.76</td>\n",
       "      <td>32.11</td>\n",
       "      <td>2.57</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.015</td>\n",
       "      <td>685.0</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.76</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.012</td>\n",
       "      <td>457.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>3.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>98.0</td>\n",
       "      <td>11.12</td>\n",
       "      <td>4.30</td>\n",
       "      <td>3.38</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.027</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.07</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>159.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>97.0</td>\n",
       "      <td>10.69</td>\n",
       "      <td>3.85</td>\n",
       "      <td>4.61</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.04</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.033</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.16</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>113.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>72.0</td>\n",
       "      <td>10.34</td>\n",
       "      <td>0.29</td>\n",
       "      <td>6.66</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.023</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.15</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.022</td>\n",
       "      <td>190.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>81.0</td>\n",
       "      <td>10.45</td>\n",
       "      <td>2.27</td>\n",
       "      <td>4.76</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.020</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.13</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.015</td>\n",
       "      <td>150.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>72.0</td>\n",
       "      <td>12.39</td>\n",
       "      <td>1.02</td>\n",
       "      <td>2.72</td>\n",
       "      <td>2.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.021</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>134.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>342.0</td>\n",
       "      <td>5.93</td>\n",
       "      <td>34.24</td>\n",
       "      <td>4.07</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.020</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.38</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>106.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>357.0</td>\n",
       "      <td>24.99</td>\n",
       "      <td>27.80</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>0.076</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.037</td>\n",
       "      <td>731.0</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.44</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>536.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>264.0</td>\n",
       "      <td>14.21</td>\n",
       "      <td>21.28</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.424</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.154</td>\n",
       "      <td>493.0</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.65</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.028</td>\n",
       "      <td>337.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>389.0</td>\n",
       "      <td>25.60</td>\n",
       "      <td>31.14</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>0.083</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.021</td>\n",
       "      <td>550.0</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.23</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.014</td>\n",
       "      <td>346.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>466.0</td>\n",
       "      <td>9.65</td>\n",
       "      <td>29.51</td>\n",
       "      <td>42.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>0.271</td>\n",
       "      <td>2.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.813</td>\n",
       "      <td>1.382</td>\n",
       "      <td>0.315</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.52</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>444.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>356.0</td>\n",
       "      <td>24.94</td>\n",
       "      <td>27.44</td>\n",
       "      <td>2.22</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.080</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.030</td>\n",
       "      <td>700.0</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.24</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>546.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>3.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>413.0</td>\n",
       "      <td>29.81</td>\n",
       "      <td>32.34</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>0.081</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.060</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.17</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.017</td>\n",
       "      <td>605.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>3.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>327.0</td>\n",
       "      <td>20.05</td>\n",
       "      <td>27.25</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>0.086</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.080</td>\n",
       "      <td>497.0</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.13</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.038</td>\n",
       "      <td>393.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>373.0</td>\n",
       "      <td>24.48</td>\n",
       "      <td>30.28</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.015</td>\n",
       "      <td>746.0</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.72</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>444.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>300.0</td>\n",
       "      <td>22.17</td>\n",
       "      <td>22.35</td>\n",
       "      <td>2.19</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.037</td>\n",
       "      <td>2.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.030</td>\n",
       "      <td>505.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.44</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.030</td>\n",
       "      <td>354.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>318.0</td>\n",
       "      <td>21.60</td>\n",
       "      <td>24.64</td>\n",
       "      <td>2.47</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.016</td>\n",
       "      <td>575.0</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.20</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>412.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>2.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>254.0</td>\n",
       "      <td>24.26</td>\n",
       "      <td>15.92</td>\n",
       "      <td>2.77</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.018</td>\n",
       "      <td>782.0</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.22</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>463.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>2.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>301.0</td>\n",
       "      <td>24.58</td>\n",
       "      <td>19.72</td>\n",
       "      <td>6.36</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>0.111</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.059</td>\n",
       "      <td>716.0</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.23</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.041</td>\n",
       "      <td>537.0</td>\n",
       "      <td>26.8</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>368.0</td>\n",
       "      <td>23.41</td>\n",
       "      <td>30.04</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>0.056</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.013</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.41</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>468.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8148</th>\n",
       "      <td>Baby Foods</td>\n",
       "      <td>389.0</td>\n",
       "      <td>6.60</td>\n",
       "      <td>0.90</td>\n",
       "      <td>88.60</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.00</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.240</td>\n",
       "      <td>1.880</td>\n",
       "      <td>1.600</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.377</td>\n",
       "      <td>9.00</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.298</td>\n",
       "      <td>253.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8149</th>\n",
       "      <td>Baby Foods</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>21.34</td>\n",
       "      <td>11.36</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.25</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.30</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8150</th>\n",
       "      <td>Baby Foods</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>16.30</td>\n",
       "      <td>14.66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0.02</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8151</th>\n",
       "      <td>Snacks</td>\n",
       "      <td>465.0</td>\n",
       "      <td>8.70</td>\n",
       "      <td>15.20</td>\n",
       "      <td>73.40</td>\n",
       "      <td>0.53</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.53</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.220</td>\n",
       "      <td>159.0</td>\n",
       "      <td>0.116</td>\n",
       "      <td>1.63</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>318.0</td>\n",
       "      <td>15.7</td>\n",
       "      <td>1.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8152</th>\n",
       "      <td>Breakfast Cereals</td>\n",
       "      <td>401.0</td>\n",
       "      <td>7.12</td>\n",
       "      <td>5.46</td>\n",
       "      <td>81.19</td>\n",
       "      <td>19.79</td>\n",
       "      <td>4.2</td>\n",
       "      <td>806.0</td>\n",
       "      <td>2.640</td>\n",
       "      <td>9.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>17.800</td>\n",
       "      <td>1.250</td>\n",
       "      <td>1.300</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>34.82</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.278</td>\n",
       "      <td>149.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>5.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8153</th>\n",
       "      <td>Snacks</td>\n",
       "      <td>429.0</td>\n",
       "      <td>12.60</td>\n",
       "      <td>9.50</td>\n",
       "      <td>73.39</td>\n",
       "      <td>0.54</td>\n",
       "      <td>14.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.01</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.070</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.350</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.545</td>\n",
       "      <td>2.28</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>264.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>3.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8154</th>\n",
       "      <td>Baby Foods</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.20</td>\n",
       "      <td>17.18</td>\n",
       "      <td>14.87</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.7</td>\n",
       "      <td>0.79</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.010</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.17</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8155</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>179.0</td>\n",
       "      <td>28.40</td>\n",
       "      <td>5.10</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.080</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.020</td>\n",
       "      <td>961.0</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.17</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>605.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>3.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8156</th>\n",
       "      <td>Snacks</td>\n",
       "      <td>377.0</td>\n",
       "      <td>4.40</td>\n",
       "      <td>7.50</td>\n",
       "      <td>72.90</td>\n",
       "      <td>35.10</td>\n",
       "      <td>2.1</td>\n",
       "      <td>608.0</td>\n",
       "      <td>1.400</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>174.0</td>\n",
       "      <td>13.500</td>\n",
       "      <td>1.100</td>\n",
       "      <td>1.000</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>4.86</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>103.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8157</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>280.0</td>\n",
       "      <td>27.50</td>\n",
       "      <td>17.10</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.020</td>\n",
       "      <td>731.0</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.25</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>524.0</td>\n",
       "      <td>15.7</td>\n",
       "      <td>3.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8158</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>688.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>77.80</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.010</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8159</th>\n",
       "      <td>Fats and Oils</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8160</th>\n",
       "      <td>Sweets</td>\n",
       "      <td>279.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>76.10</td>\n",
       "      <td>76.00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8161</th>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>257.0</td>\n",
       "      <td>4.08</td>\n",
       "      <td>19.50</td>\n",
       "      <td>16.18</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.15</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.000</td>\n",
       "      <td>649.0</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.68</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.026</td>\n",
       "      <td>596.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8162</th>\n",
       "      <td>Vegetables and Vegetable Products</td>\n",
       "      <td>319.0</td>\n",
       "      <td>11.30</td>\n",
       "      <td>2.10</td>\n",
       "      <td>63.70</td>\n",
       "      <td>35.90</td>\n",
       "      <td>27.8</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.00</td>\n",
       "      <td>86.5</td>\n",
       "      <td>5.55</td>\n",
       "      <td>107.0</td>\n",
       "      <td>4.640</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.440</td>\n",
       "      <td>587.0</td>\n",
       "      <td>0.571</td>\n",
       "      <td>7.83</td>\n",
       "      <td>196.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>402.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>2.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8163</th>\n",
       "      <td>Sweets</td>\n",
       "      <td>356.0</td>\n",
       "      <td>5.30</td>\n",
       "      <td>2.40</td>\n",
       "      <td>78.20</td>\n",
       "      <td>0.70</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.020</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.838</td>\n",
       "      <td>3.11</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.703</td>\n",
       "      <td>1660.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8164</th>\n",
       "      <td>Baby Foods</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.010</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.30</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8165</th>\n",
       "      <td>Sweets</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.03</td>\n",
       "      <td>46.10</td>\n",
       "      <td>45.30</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.010</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.18</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8166</th>\n",
       "      <td>Sweets</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.20</td>\n",
       "      <td>44.38</td>\n",
       "      <td>37.75</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.023</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.80</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.215</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8167</th>\n",
       "      <td>Beverages</td>\n",
       "      <td>287.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>71.60</td>\n",
       "      <td>24.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.009</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.045</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8168</th>\n",
       "      <td>Sweets</td>\n",
       "      <td>365.0</td>\n",
       "      <td>10.08</td>\n",
       "      <td>3.00</td>\n",
       "      <td>74.42</td>\n",
       "      <td>0.70</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.025</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.854</td>\n",
       "      <td>3.87</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.887</td>\n",
       "      <td>174.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8169</th>\n",
       "      <td>Sweets</td>\n",
       "      <td>351.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.10</td>\n",
       "      <td>86.04</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.05</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8170</th>\n",
       "      <td>Sweets</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.90</td>\n",
       "      <td>84.66</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.005</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.38</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.041</td>\n",
       "      <td>2368.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8171</th>\n",
       "      <td>Cereal Grains and Pasta</td>\n",
       "      <td>370.0</td>\n",
       "      <td>75.16</td>\n",
       "      <td>1.85</td>\n",
       "      <td>13.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.182</td>\n",
       "      <td>5.20</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>260.0</td>\n",
       "      <td>39.7</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8172</th>\n",
       "      <td>Finfish and Shellfish Products</td>\n",
       "      <td>73.0</td>\n",
       "      <td>16.40</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.200</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.140</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>1.50</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>147.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8173</th>\n",
       "      <td>Finfish and Shellfish Products</td>\n",
       "      <td>305.0</td>\n",
       "      <td>18.50</td>\n",
       "      <td>25.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.410</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.38</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.300</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.020</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.40</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>254.0</td>\n",
       "      <td>73.4</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8174</th>\n",
       "      <td>Finfish and Shellfish Products</td>\n",
       "      <td>111.0</td>\n",
       "      <td>20.54</td>\n",
       "      <td>0.84</td>\n",
       "      <td>5.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.112</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.076</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.012</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.58</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.029</td>\n",
       "      <td>426.0</td>\n",
       "      <td>21.7</td>\n",
       "      <td>1.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8175</th>\n",
       "      <td>Sweets</td>\n",
       "      <td>269.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>73.14</td>\n",
       "      <td>73.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.130</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.020</td>\n",
       "      <td>3.60</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8176</th>\n",
       "      <td>Finfish and Shellfish Products</td>\n",
       "      <td>90.0</td>\n",
       "      <td>16.10</td>\n",
       "      <td>1.40</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.400</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.400</td>\n",
       "      <td>3.50</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>272.0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8177</th>\n",
       "      <td>Finfish and Shellfish Products</td>\n",
       "      <td>89.0</td>\n",
       "      <td>19.80</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.120</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.100</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.120</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>1.40</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8178 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              FoodGroup  Energy_kcal  Protein_g   Fat_g  \\\n",
       "0     Dairy and Egg Products             717.0        0.85       81.11    \n",
       "1     Dairy and Egg Products             717.0        0.85       81.11    \n",
       "2     Dairy and Egg Products             876.0        0.28       99.48    \n",
       "3     Dairy and Egg Products             353.0        21.40      28.74    \n",
       "4     Dairy and Egg Products             371.0        23.24      29.68    \n",
       "5     Dairy and Egg Products             334.0        20.75      27.68    \n",
       "6     Dairy and Egg Products             300.0        19.80      24.26    \n",
       "7     Dairy and Egg Products             376.0        25.18      29.20    \n",
       "8     Dairy and Egg Products             406.0        24.04      33.82    \n",
       "9     Dairy and Egg Products             387.0        23.37      30.60    \n",
       "10    Dairy and Egg Products             394.0        23.76      32.11    \n",
       "11    Dairy and Egg Products             98.0         11.12      4.30     \n",
       "12    Dairy and Egg Products             97.0         10.69      3.85     \n",
       "13    Dairy and Egg Products             72.0         10.34      0.29     \n",
       "14    Dairy and Egg Products             81.0         10.45      2.27     \n",
       "15    Dairy and Egg Products             72.0         12.39      1.02     \n",
       "16    Dairy and Egg Products             342.0        5.93       34.24    \n",
       "17    Dairy and Egg Products             357.0        24.99      27.80    \n",
       "18    Dairy and Egg Products             264.0        14.21      21.28    \n",
       "19    Dairy and Egg Products             389.0        25.60      31.14    \n",
       "20    Dairy and Egg Products             466.0        9.65       29.51    \n",
       "21    Dairy and Egg Products             356.0        24.94      27.44    \n",
       "22    Dairy and Egg Products             413.0        29.81      32.34    \n",
       "23    Dairy and Egg Products             327.0        20.05      27.25    \n",
       "24    Dairy and Egg Products             373.0        24.48      30.28    \n",
       "25    Dairy and Egg Products             300.0        22.17      22.35    \n",
       "26    Dairy and Egg Products             318.0        21.60      24.64    \n",
       "27    Dairy and Egg Products             254.0        24.26      15.92    \n",
       "28    Dairy and Egg Products             301.0        24.58      19.72    \n",
       "29    Dairy and Egg Products             368.0        23.41      30.04    \n",
       "...                      ...               ...          ...        ...    \n",
       "8148  Baby Foods                         389.0        6.60       0.90     \n",
       "8149  Baby Foods                         91.0         1.00       0.20     \n",
       "8150  Baby Foods                         68.0         0.30       0.20     \n",
       "8151  Snacks                             465.0        8.70       15.20    \n",
       "8152  Breakfast Cereals                  401.0        7.12       5.46     \n",
       "8153  Snacks                             429.0        12.60      9.50     \n",
       "8154  Baby Foods                         73.0         0.50       0.20     \n",
       "8155  Dairy and Egg Products             179.0        28.40      5.10     \n",
       "8156  Snacks                             377.0        4.40       7.50     \n",
       "8157  Dairy and Egg Products             280.0        27.50      17.10    \n",
       "8158  Fats and Oils                      688.0        0.00       77.80    \n",
       "8159  Fats and Oils                      884.0        0.00       100.00   \n",
       "8160  Sweets                             279.0        0.00       0.00     \n",
       "8161  Dairy and Egg Products             257.0        4.08       19.50    \n",
       "8162  Vegetables and Vegetable Products  319.0        11.30      2.10     \n",
       "8163  Sweets                             356.0        5.30       2.40     \n",
       "8164  Baby Foods                         62.0         0.00       0.00     \n",
       "8165  Sweets                             179.0        0.30       0.03     \n",
       "8166  Sweets                             181.0        0.41       0.20     \n",
       "8167  Beverages                          287.0        0.08       0.01     \n",
       "8168  Sweets                             365.0        10.08      3.00     \n",
       "8169  Sweets                             351.0        1.60       0.10     \n",
       "8170  Sweets                             350.0        0.81       0.90     \n",
       "8171  Cereal Grains and Pasta            370.0        75.16      1.85     \n",
       "8172  Finfish and Shellfish Products     73.0         16.40      0.30     \n",
       "8173  Finfish and Shellfish Products     305.0        18.50      25.10    \n",
       "8174  Finfish and Shellfish Products     111.0        20.54      0.84     \n",
       "8175  Sweets                             269.0        0.00       0.00     \n",
       "8176  Finfish and Shellfish Products     90.0         16.10      1.40     \n",
       "8177  Finfish and Shellfish Products     89.0         19.80      0.50     \n",
       "\n",
       "      Carb_g  Sugar_g  Fiber_g  VitA_mcg  VitB6_mg  VitB12_mcg  VitC_mg  \\\n",
       "0     0.06    0.06     0.0      684.0     0.003     0.17        0.0       \n",
       "1     0.06    0.06     0.0      684.0     0.003     0.13        0.0       \n",
       "2     0.00    0.00     0.0      840.0     0.001     0.01        0.0       \n",
       "3     2.34    0.50     0.0      198.0     0.166     1.22        0.0       \n",
       "4     2.79    0.51     0.0      292.0     0.065     1.26        0.0       \n",
       "5     0.45    0.45     0.0      174.0     0.235     1.65        0.0       \n",
       "6     0.46    0.46     0.0      241.0     0.227     1.30        0.0       \n",
       "7     3.06    0.00     0.0      271.0     0.074     0.27        0.0       \n",
       "8     1.33    0.28     0.0      263.0     0.049     0.88        0.0       \n",
       "9     4.78    0.00     0.0      233.0     0.074     0.83        0.0       \n",
       "10    2.57    0.52     0.0      264.0     0.079     0.83        0.0       \n",
       "11    3.38    2.67     0.0      37.0      0.046     0.43        0.0       \n",
       "12    4.61    2.38     0.2      38.0      0.068     0.53        1.4       \n",
       "13    6.66    1.85     0.0      2.0       0.016     0.46        0.0       \n",
       "14    4.76    4.00     0.0      68.0      0.057     0.47        0.0       \n",
       "15    2.72    2.72     0.0      11.0      0.068     0.63        0.0       \n",
       "16    4.07    3.21     0.0      366.0     0.035     0.25        0.0       \n",
       "17    1.43    1.43     0.0      243.0     0.076     1.54        0.0       \n",
       "18    4.09    4.09     0.0      125.0     0.424     1.69        0.0       \n",
       "19    1.55    1.55     0.0      261.0     0.083     1.68        0.0       \n",
       "20    42.65   0.00     0.0      334.0     0.271     2.42        0.0       \n",
       "21    2.22    2.22     0.0      165.0     0.080     1.54        0.0       \n",
       "22    0.36    0.36     0.0      271.0     0.081     1.60        0.0       \n",
       "23    0.49    0.49     0.0      340.0     0.086     1.04        0.0       \n",
       "24    0.68    0.50     0.0      198.0     0.079     0.83        0.0       \n",
       "25    2.19    1.03     0.0      179.0     0.037     2.28        0.0       \n",
       "26    2.47    1.01     0.0      197.0     0.062     0.73        0.0       \n",
       "27    2.77    1.13     0.0      127.0     0.070     0.82        0.0       \n",
       "28    6.36    2.24     0.0      254.0     0.111     1.82        0.0       \n",
       "29    1.12    1.12     0.0      298.0     0.056     1.47        0.0       \n",
       "...    ...     ...     ...        ...       ...      ...        ...       \n",
       "8148  88.60   1.35     2.6      0.0       0.090     0.00        250.0     \n",
       "8149  21.34   11.36    1.6      0.0       0.260     0.00        21.9      \n",
       "8150  16.30   14.66    1.0      2.0       0.060     0.00        12.3      \n",
       "8151  73.40   0.53     5.7      4.0       0.180     0.06        0.2       \n",
       "8152  81.19   19.79    4.2      806.0     2.640     9.67        0.0       \n",
       "8153  73.39   0.54     14.2     7.0       0.170     0.00        0.0       \n",
       "8154  17.18   14.87    2.0      3.0       0.070     0.00        12.7      \n",
       "8155  3.40    1.33     0.0      40.0      0.080     1.68        0.0       \n",
       "8156  72.90   35.10    2.1      608.0     1.400     0.00        0.0       \n",
       "8157  3.10    1.23     0.0      137.0     0.080     0.92        0.0       \n",
       "8158  0.30    0.30     0.0      0.0       0.010     0.00        0.0       \n",
       "8159  0.00    0.00     0.0      0.0       0.000     0.00        0.0       \n",
       "8160  76.10   76.00    0.1      0.0       0.000     0.00        0.0       \n",
       "8161  16.18   8.21     0.0      45.0      0.027     0.71        0.0       \n",
       "8162  63.70   35.90    27.8     98.0      0.460     0.00        86.5      \n",
       "8163  78.20   0.70     6.1      0.0       0.040     0.01        0.0       \n",
       "8164  15.38   0.00     0.1      0.0       0.060     0.00        33.8      \n",
       "8165  46.10   45.30    0.8      0.0       0.040     0.00        0.0       \n",
       "8166  44.38   37.75    2.6      1.0       0.029     0.00        0.7       \n",
       "8167  71.60   24.53    0.0      1.0       0.005     0.00        4.2       \n",
       "8168  74.42   0.70     10.1     0.0       0.027     0.00        0.0       \n",
       "8169  86.04   2.90     0.9      0.0       0.000     0.00        0.0       \n",
       "8170  84.66   0.90     0.8      0.0       0.005     0.05        0.0       \n",
       "8171  13.79   0.00     0.6      0.0       0.000     0.00        0.0       \n",
       "8172  0.00    0.00     0.0      15.0      0.120     0.40        0.0       \n",
       "8173  0.00    0.00     0.0      47.0      0.410     12.00       0.0       \n",
       "8174  5.41    0.00     0.0      2.0       0.112     2.15        0.0       \n",
       "8175  73.14   73.20    0.0      0.0       0.000     0.00        0.0       \n",
       "8176  2.00    0.00     0.0      30.0      0.130     0.50        0.0       \n",
       "8177  0.00    0.00     0.0      30.0      0.120     1.00        0.0       \n",
       "\n",
       "      VitE_mg  Folate_mcg  Niacin_mg  Riboflavin_mg  Thiamin_mg  Calcium_mg  \\\n",
       "0     2.32     3.0         0.042      0.034          0.005       24.0         \n",
       "1     2.32     3.0         0.042      0.034          0.005       24.0         \n",
       "2     2.80     0.0         0.003      0.005          0.001       4.0          \n",
       "3     0.25     36.0        1.016      0.382          0.029       528.0        \n",
       "4     0.26     20.0        0.118      0.351          0.014       674.0        \n",
       "5     0.24     65.0        0.380      0.520          0.070       184.0        \n",
       "6     0.21     62.0        0.630      0.488          0.028       388.0        \n",
       "7     0.00     18.0        0.180      0.450          0.031       673.0        \n",
       "8     0.78     26.0        0.039      0.434          0.027       675.0        \n",
       "9     0.00     18.0        0.080      0.293          0.046       643.0        \n",
       "10    0.28     18.0        0.093      0.375          0.015       685.0        \n",
       "11    0.08     12.0        0.099      0.163          0.027       83.0         \n",
       "12    0.04     11.0        0.150      0.142          0.033       53.0         \n",
       "13    0.01     9.0         0.144      0.226          0.023       86.0         \n",
       "14    0.08     8.0         0.103      0.251          0.020       111.0        \n",
       "15    0.01     12.0        0.128      0.165          0.021       61.0         \n",
       "16    0.29     11.0        0.145      0.125          0.020       98.0         \n",
       "17    0.24     16.0        0.082      0.389          0.037       731.0        \n",
       "18    0.18     32.0        0.991      0.844          0.154       493.0        \n",
       "19    0.27     6.0         0.150      0.204          0.021       550.0        \n",
       "20    0.00     5.0         0.813      1.382          0.315       400.0        \n",
       "21    0.24     21.0        0.063      0.334          0.030       700.0        \n",
       "22    0.28     10.0        0.106      0.279          0.060       1011.0       \n",
       "23    0.23     58.0        0.158      0.503          0.080       497.0        \n",
       "24    0.26     18.0        0.093      0.390          0.015       746.0        \n",
       "25    0.19     7.0         0.104      0.283          0.030       505.0        \n",
       "26    0.21     8.0         0.094      0.270          0.016       575.0        \n",
       "27    0.14     9.0         0.105      0.303          0.018       782.0        \n",
       "28    0.43     27.0        0.144      0.348          0.059       716.0        \n",
       "29    0.26     12.0        0.103      0.320          0.013       717.0        \n",
       "...    ...      ...          ...        ...            ...         ...        \n",
       "8148  0.13     5.0         25.240     1.880          1.600       38.0         \n",
       "8149  0.25     17.0        0.540      0.060          0.020       4.0          \n",
       "8150  0.02     4.0         0.130      0.020          0.020       3.0          \n",
       "8151  3.53     16.0        0.420      0.280          0.220       159.0        \n",
       "8152  1.22     1120.0      17.800     1.250          1.300       23.0         \n",
       "8153  5.01     17.0        2.070      0.110          0.350       11.0         \n",
       "8154  0.79     6.0         0.280      0.040          0.010       6.0          \n",
       "8155  0.07     6.0         0.090      0.360          0.020       961.0        \n",
       "8156  0.76     174.0       13.500     1.100          1.000       41.0         \n",
       "8157  0.15     9.0         0.120      0.340          0.020       731.0        \n",
       "8158  11.79    0.0         0.010      0.060          0.010       7.0          \n",
       "8159  14.78    0.0         0.000      0.000          0.000       0.0          \n",
       "8160  0.00     0.0         0.000      0.020          0.000       1.0          \n",
       "8161  2.15     8.0         0.060      0.090          0.000       649.0        \n",
       "8162  5.55     107.0       4.640      0.500          0.440       587.0        \n",
       "8163  0.02     6.0         0.400      0.090          0.020       126.0        \n",
       "8164  0.00     0.0         0.200      0.020          0.010       12.0         \n",
       "8165  0.00     1.0         0.140      0.020          0.010       5.0          \n",
       "8166  0.23     1.0         0.091      0.034          0.023       27.0         \n",
       "8167  0.02     5.0         0.026      0.017          0.009       2.0          \n",
       "8168  0.02     0.0         0.545      0.105          0.025       50.0         \n",
       "8169  0.05     0.0         0.000      0.000          0.000       49.0         \n",
       "8170  0.08     1.0         0.014      0.021          0.005       143.0        \n",
       "8171  0.00     0.0         0.000      0.000          0.000       142.0        \n",
       "8172  1.00     15.0        1.200      0.250          0.140       18.0         \n",
       "8173  2.38     15.0        3.300      0.190          0.020       66.0         \n",
       "8174  0.00     20.0        1.076      0.024          0.012       10.0         \n",
       "8175  0.00     0.0         0.100      0.060          0.130       13.0         \n",
       "8176  5.00     6.0         1.400      0.120          0.010       10.0         \n",
       "8177  0.50     15.0        1.100      0.150          0.120       118.0        \n",
       "\n",
       "      Copper_mcg  Iron_mg  Magnesium_mg  Manganese_mg  Phosphorus_mg  \\\n",
       "0     0.000       0.02     2.0           0.000         24.0            \n",
       "1     0.016       0.16     2.0           0.004         23.0            \n",
       "2     0.001       0.00     0.0           0.000         3.0             \n",
       "3     0.040       0.31     23.0          0.009         387.0           \n",
       "4     0.024       0.43     24.0          0.012         451.0           \n",
       "5     0.019       0.50     20.0          0.034         188.0           \n",
       "6     0.021       0.33     20.0          0.038         347.0           \n",
       "7     0.024       0.64     22.0          0.021         490.0           \n",
       "8     0.056       0.16     27.0          0.033         473.0           \n",
       "9     0.042       0.21     21.0          0.012         464.0           \n",
       "10    0.042       0.76     26.0          0.012         457.0           \n",
       "11    0.029       0.07     8.0           0.002         159.0           \n",
       "12    0.040       0.16     7.0           0.003         113.0           \n",
       "13    0.030       0.15     11.0          0.022         190.0           \n",
       "14    0.033       0.13     9.0           0.015         150.0           \n",
       "15    0.028       0.14     5.0           0.003         134.0           \n",
       "16    0.019       0.38     9.0           0.011         106.0           \n",
       "17    0.036       0.44     30.0          0.011         536.0           \n",
       "18    0.032       0.65     19.0          0.028         337.0           \n",
       "19    0.025       0.23     14.0          0.014         346.0           \n",
       "20    0.080       0.52     70.0          0.040         444.0           \n",
       "21    0.036       0.24     29.0          0.011         546.0           \n",
       "22    0.032       0.17     36.0          0.017         605.0           \n",
       "23    0.021       0.13     21.0          0.038         393.0           \n",
       "24    0.032       0.72     27.0          0.011         444.0           \n",
       "25    0.011       0.44     20.0          0.030         354.0           \n",
       "26    0.022       0.20     21.0          0.009         412.0           \n",
       "27    0.025       0.22     23.0          0.010         463.0           \n",
       "28    0.034       0.23     29.0          0.041         537.0           \n",
       "29    0.031       0.41     27.0          0.008         468.0           \n",
       "...     ...        ...      ...            ...           ...           \n",
       "8148  0.377       9.00     37.0          1.298         253.0           \n",
       "8149  0.040       0.30     26.0          0.000         20.0            \n",
       "8150  0.030       0.10     8.0           0.000         9.0             \n",
       "8151  0.116       1.63     97.0          0.000         318.0           \n",
       "8152  0.200       34.82    46.0          1.278         149.0           \n",
       "8153  0.545       2.28     151.0         0.000         264.0           \n",
       "8154  0.035       0.17     7.0           0.000         9.0             \n",
       "8155  0.027       0.17     36.0          0.000         605.0           \n",
       "8156  0.100       4.86     27.0          0.000         103.0           \n",
       "8157  0.027       0.25     26.0          0.000         524.0           \n",
       "8158  0.000       0.23     1.0           0.000         25.0            \n",
       "8159  0.000       0.13     0.0           0.000         0.0             \n",
       "8160  0.037       0.11     0.0           0.000         0.0             \n",
       "8161  0.026       0.68     10.0          0.026         596.0           \n",
       "8162  0.571       7.83     196.0         0.000         402.0           \n",
       "8163  0.838       3.11     89.0          0.703         1660.0          \n",
       "8164  0.028       0.30     10.0          0.000         11.0            \n",
       "8165  0.023       0.18     6.0           0.000         6.0             \n",
       "8166  0.112       0.80     10.0          0.215         12.0            \n",
       "8167  0.020       0.04     1.0           0.045         2.0             \n",
       "8168  0.854       3.87     110.0         0.887         174.0           \n",
       "8169  0.040       0.05     17.0          0.000         12.0            \n",
       "8170  0.038       0.38     5.0           0.041         2368.0          \n",
       "8171  0.182       5.20     25.0          0.000         260.0           \n",
       "8172  0.250       1.50     20.0          0.000         147.0           \n",
       "8173  0.100       1.40     60.0          0.000         254.0           \n",
       "8174  0.033       0.58     37.0          0.029         426.0           \n",
       "8175  0.020       3.60     10.0          0.000         8.0             \n",
       "8176  0.400       3.50     250.0         0.000         272.0           \n",
       "8177  0.250       1.40     20.0          0.000         180.0           \n",
       "\n",
       "      Selenium_mcg  Zinc_mg  \n",
       "0     1.0           0.09     \n",
       "1     1.0           0.05     \n",
       "2     0.0           0.01     \n",
       "3     14.5          2.66     \n",
       "4     14.5          2.60     \n",
       "5     14.5          2.38     \n",
       "6     14.5          2.38     \n",
       "7     14.5          2.94     \n",
       "8     28.3          3.43     \n",
       "9     14.5          2.79     \n",
       "10    14.5          3.07     \n",
       "11    9.7           0.40     \n",
       "12    7.7           0.33     \n",
       "13    9.4           0.47     \n",
       "14    11.9          0.51     \n",
       "15    9.0           0.38     \n",
       "16    2.4           0.51     \n",
       "17    14.5          3.75     \n",
       "18    15.0          2.88     \n",
       "19    14.5          3.50     \n",
       "20    14.5          1.14     \n",
       "21    14.5          3.90     \n",
       "22    14.5          3.90     \n",
       "23    14.5          2.10     \n",
       "24    14.5          3.00     \n",
       "25    17.0          2.92     \n",
       "26    16.1          2.46     \n",
       "27    14.4          2.76     \n",
       "28    26.8          3.61     \n",
       "29    14.5          2.81     \n",
       "...    ...           ...     \n",
       "8148  16.3          3.30     \n",
       "8149  1.1           0.05     \n",
       "8150  0.6           0.05     \n",
       "8151  15.7          1.15     \n",
       "8152  7.3           5.03     \n",
       "8153  8.6           3.83     \n",
       "8154  0.4           0.08     \n",
       "8155  12.7          3.90     \n",
       "8156  15.0          4.10     \n",
       "8157  15.7          3.13     \n",
       "8158  1.6           0.13     \n",
       "8159  0.0           0.02     \n",
       "8160  0.5           0.09     \n",
       "8161  2.9           0.21     \n",
       "8162  15.3          2.77     \n",
       "8163  3.9           0.41     \n",
       "8164  0.0           0.05     \n",
       "8165  1.4           0.03     \n",
       "8166  0.4           0.10     \n",
       "8167  0.5           0.02     \n",
       "8168  5.1           1.49     \n",
       "8169  0.9           0.19     \n",
       "8170  0.8           0.10     \n",
       "8171  39.7          0.85     \n",
       "8172  14.1          1.00     \n",
       "8173  73.4          1.10     \n",
       "8174  21.7          1.55     \n",
       "8175  0.7           0.19     \n",
       "8176  27.4          1.00     \n",
       "8177  16.8          1.00     \n",
       "\n",
       "[8178 rows x 24 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Energy_kcal</th>\n",
       "      <th>Protein_g</th>\n",
       "      <th>Fat_g</th>\n",
       "      <th>Carb_g</th>\n",
       "      <th>Sugar_g</th>\n",
       "      <th>Fiber_g</th>\n",
       "      <th>VitA_mcg</th>\n",
       "      <th>VitB6_mg</th>\n",
       "      <th>VitB12_mcg</th>\n",
       "      <th>VitC_mg</th>\n",
       "      <th>VitE_mg</th>\n",
       "      <th>Folate_mcg</th>\n",
       "      <th>Niacin_mg</th>\n",
       "      <th>Riboflavin_mg</th>\n",
       "      <th>Thiamin_mg</th>\n",
       "      <th>Calcium_mg</th>\n",
       "      <th>Copper_mcg</th>\n",
       "      <th>Iron_mg</th>\n",
       "      <th>Magnesium_mg</th>\n",
       "      <th>Manganese_mg</th>\n",
       "      <th>Phosphorus_mg</th>\n",
       "      <th>Selenium_mcg</th>\n",
       "      <th>Zinc_mg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.794900</td>\n",
       "      <td>0.009624</td>\n",
       "      <td>0.8111</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.001719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015529</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.005540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.002561</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003494</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.000990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.794900</td>\n",
       "      <td>0.009624</td>\n",
       "      <td>0.8111</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015529</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.005540</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>0.002561</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.003348</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.000550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.971175</td>\n",
       "      <td>0.003170</td>\n",
       "      <td>0.9948</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.391353</td>\n",
       "      <td>0.242301</td>\n",
       "      <td>0.2874</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.005010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.013833</td>\n",
       "      <td>0.012337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.006121</td>\n",
       "      <td>0.007969</td>\n",
       "      <td>0.021829</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>0.121884</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.002508</td>\n",
       "      <td>0.029449</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.056340</td>\n",
       "      <td>0.007564</td>\n",
       "      <td>0.029247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.411308</td>\n",
       "      <td>0.263134</td>\n",
       "      <td>0.2968</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>0.005110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009733</td>\n",
       "      <td>0.005417</td>\n",
       "      <td>0.012741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>0.020057</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.155586</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>0.030730</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.065657</td>\n",
       "      <td>0.007564</td>\n",
       "      <td>0.028587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Energy_kcal  Protein_g   Fat_g  Carb_g   Sugar_g  Fiber_g  VitA_mcg  \\\n",
       "0  0.794900     0.009624   0.8111  0.0006  0.000601  0.0      0.022800   \n",
       "1  0.794900     0.009624   0.8111  0.0006  0.000601  0.0      0.022800   \n",
       "2  0.971175     0.003170   0.9948  0.0000  0.000000  0.0      0.028000   \n",
       "3  0.391353     0.242301   0.2874  0.0234  0.005010  0.0      0.006600   \n",
       "4  0.411308     0.263134   0.2968  0.0279  0.005110  0.0      0.009733   \n",
       "\n",
       "   VitB6_mg  VitB12_mcg  VitC_mg   VitE_mg  Folate_mcg  Niacin_mg  \\\n",
       "0  0.000250  0.001719    0.0      0.015529  0.000510    0.000329    \n",
       "1  0.000250  0.001315    0.0      0.015529  0.000510    0.000329    \n",
       "2  0.000083  0.000101    0.0      0.018742  0.000000    0.000024    \n",
       "3  0.013833  0.012337    0.0      0.001673  0.006121    0.007969    \n",
       "4  0.005417  0.012741    0.0      0.001740  0.003401    0.000925    \n",
       "\n",
       "   Riboflavin_mg  Thiamin_mg  Calcium_mg  Copper_mcg   Iron_mg  Magnesium_mg  \\\n",
       "0  0.001943       0.000214    0.005540    0.000000    0.000162  0.002561       \n",
       "1  0.001943       0.000214    0.005540    0.001063    0.001294  0.002561       \n",
       "2  0.000286       0.000043    0.000923    0.000066    0.000000  0.000000       \n",
       "3  0.021829       0.001241    0.121884    0.002658    0.002508  0.029449       \n",
       "4  0.020057       0.000599    0.155586    0.001595    0.003479  0.030730       \n",
       "\n",
       "   Manganese_mg  Phosphorus_mg  Selenium_mcg   Zinc_mg  \n",
       "0  0.000000      0.003494       0.000522      0.000990  \n",
       "1  0.000012      0.003348       0.000522      0.000550  \n",
       "2  0.000000      0.000437       0.000000      0.000110  \n",
       "3  0.000027      0.056340       0.007564      0.029247  \n",
       "4  0.000037      0.065657       0.007564      0.028587  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4. data normalization\n",
    "\n",
    "food_data_exp = food_data.drop(columns=['FoodGroup'])\n",
    "food_data_target = food_data.FoodGroup\n",
    "\n",
    "from sklearn import preprocessing\n",
    "food_data_exp = pd.DataFrame(\n",
    "    preprocessing.MinMaxScaler().fit_transform(food_data_exp),\n",
    "    columns=['Energy_kcal','Protein_g', 'Fat_g', 'Carb_g',\n",
    "       'Sugar_g', 'Fiber_g', 'VitA_mcg', 'VitB6_mg', 'VitB12_mcg',\n",
    "       'VitC_mg', 'VitE_mg', 'Folate_mcg', 'Niacin_mg', 'Riboflavin_mg',\n",
    "       'Thiamin_mg', 'Calcium_mg', 'Copper_mcg', 'Iron_mg',\n",
    "       'Magnesium_mg', 'Manganese_mg', 'Phosphorus_mg', 'Selenium_mcg',\n",
    "       'Zinc_mg']\n",
    ")\n",
    "food_data_exp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Energy_kcal</th>\n",
       "      <th>Protein_g</th>\n",
       "      <th>Fat_g</th>\n",
       "      <th>Carb_g</th>\n",
       "      <th>Sugar_g</th>\n",
       "      <th>Fiber_g</th>\n",
       "      <th>VitA_mcg</th>\n",
       "      <th>VitB6_mg</th>\n",
       "      <th>VitB12_mcg</th>\n",
       "      <th>VitC_mg</th>\n",
       "      <th>VitE_mg</th>\n",
       "      <th>Folate_mcg</th>\n",
       "      <th>Niacin_mg</th>\n",
       "      <th>Riboflavin_mg</th>\n",
       "      <th>Thiamin_mg</th>\n",
       "      <th>Calcium_mg</th>\n",
       "      <th>Copper_mcg</th>\n",
       "      <th>Iron_mg</th>\n",
       "      <th>Magnesium_mg</th>\n",
       "      <th>Manganese_mg</th>\n",
       "      <th>Phosphorus_mg</th>\n",
       "      <th>Selenium_mcg</th>\n",
       "      <th>Zinc_mg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Energy_kcal</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.633667</td>\n",
       "      <td>0.849344</td>\n",
       "      <td>0.723890</td>\n",
       "      <td>0.514850</td>\n",
       "      <td>0.444475</td>\n",
       "      <td>0.114950</td>\n",
       "      <td>0.449060</td>\n",
       "      <td>0.215808</td>\n",
       "      <td>0.087609</td>\n",
       "      <td>0.355812</td>\n",
       "      <td>0.287575</td>\n",
       "      <td>0.544722</td>\n",
       "      <td>0.453717</td>\n",
       "      <td>0.398596</td>\n",
       "      <td>0.385803</td>\n",
       "      <td>0.311823</td>\n",
       "      <td>0.447371</td>\n",
       "      <td>0.532141</td>\n",
       "      <td>0.084908</td>\n",
       "      <td>0.636663</td>\n",
       "      <td>0.349990</td>\n",
       "      <td>0.459805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Protein_g</th>\n",
       "      <td>0.633667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.439886</td>\n",
       "      <td>0.301298</td>\n",
       "      <td>0.158528</td>\n",
       "      <td>0.267816</td>\n",
       "      <td>0.104374</td>\n",
       "      <td>0.489240</td>\n",
       "      <td>0.367282</td>\n",
       "      <td>0.055134</td>\n",
       "      <td>0.141700</td>\n",
       "      <td>0.193191</td>\n",
       "      <td>0.629932</td>\n",
       "      <td>0.463299</td>\n",
       "      <td>0.333349</td>\n",
       "      <td>0.321588</td>\n",
       "      <td>0.335313</td>\n",
       "      <td>0.385484</td>\n",
       "      <td>0.495921</td>\n",
       "      <td>0.085277</td>\n",
       "      <td>0.756445</td>\n",
       "      <td>0.523954</td>\n",
       "      <td>0.611805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fat_g</th>\n",
       "      <td>0.849344</td>\n",
       "      <td>0.439886</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.309798</td>\n",
       "      <td>0.237585</td>\n",
       "      <td>0.214106</td>\n",
       "      <td>0.089759</td>\n",
       "      <td>0.232468</td>\n",
       "      <td>0.136991</td>\n",
       "      <td>0.025449</td>\n",
       "      <td>0.399340</td>\n",
       "      <td>0.095294</td>\n",
       "      <td>0.302234</td>\n",
       "      <td>0.229691</td>\n",
       "      <td>0.200149</td>\n",
       "      <td>0.228190</td>\n",
       "      <td>0.211551</td>\n",
       "      <td>0.205638</td>\n",
       "      <td>0.329600</td>\n",
       "      <td>0.043005</td>\n",
       "      <td>0.420771</td>\n",
       "      <td>0.250839</td>\n",
       "      <td>0.299095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carb_g</th>\n",
       "      <td>0.723890</td>\n",
       "      <td>0.301298</td>\n",
       "      <td>0.309798</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.705978</td>\n",
       "      <td>0.588489</td>\n",
       "      <td>0.080867</td>\n",
       "      <td>0.439056</td>\n",
       "      <td>0.104197</td>\n",
       "      <td>0.144249</td>\n",
       "      <td>0.189625</td>\n",
       "      <td>0.405672</td>\n",
       "      <td>0.474099</td>\n",
       "      <td>0.455133</td>\n",
       "      <td>0.436369</td>\n",
       "      <td>0.391409</td>\n",
       "      <td>0.248292</td>\n",
       "      <td>0.522209</td>\n",
       "      <td>0.507055</td>\n",
       "      <td>0.091997</td>\n",
       "      <td>0.464062</td>\n",
       "      <td>0.168791</td>\n",
       "      <td>0.307205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sugar_g</th>\n",
       "      <td>0.514850</td>\n",
       "      <td>0.158528</td>\n",
       "      <td>0.237585</td>\n",
       "      <td>0.705978</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.277170</td>\n",
       "      <td>0.064980</td>\n",
       "      <td>0.279604</td>\n",
       "      <td>0.077580</td>\n",
       "      <td>0.114590</td>\n",
       "      <td>0.149870</td>\n",
       "      <td>0.251256</td>\n",
       "      <td>0.275656</td>\n",
       "      <td>0.303632</td>\n",
       "      <td>0.242777</td>\n",
       "      <td>0.286461</td>\n",
       "      <td>0.133010</td>\n",
       "      <td>0.283730</td>\n",
       "      <td>0.248467</td>\n",
       "      <td>0.043915</td>\n",
       "      <td>0.249930</td>\n",
       "      <td>0.074555</td>\n",
       "      <td>0.201107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fiber_g</th>\n",
       "      <td>0.444475</td>\n",
       "      <td>0.267816</td>\n",
       "      <td>0.214106</td>\n",
       "      <td>0.588489</td>\n",
       "      <td>0.277170</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.060091</td>\n",
       "      <td>0.400208</td>\n",
       "      <td>0.073839</td>\n",
       "      <td>0.130695</td>\n",
       "      <td>0.234848</td>\n",
       "      <td>0.324608</td>\n",
       "      <td>0.346828</td>\n",
       "      <td>0.327400</td>\n",
       "      <td>0.329183</td>\n",
       "      <td>0.388942</td>\n",
       "      <td>0.308138</td>\n",
       "      <td>0.506442</td>\n",
       "      <td>0.638502</td>\n",
       "      <td>0.124949</td>\n",
       "      <td>0.411295</td>\n",
       "      <td>0.141708</td>\n",
       "      <td>0.280464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VitA_mcg</th>\n",
       "      <td>0.114950</td>\n",
       "      <td>0.104374</td>\n",
       "      <td>0.089759</td>\n",
       "      <td>0.080867</td>\n",
       "      <td>0.064980</td>\n",
       "      <td>0.060091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.179172</td>\n",
       "      <td>0.551557</td>\n",
       "      <td>0.133914</td>\n",
       "      <td>0.072817</td>\n",
       "      <td>0.135406</td>\n",
       "      <td>0.193504</td>\n",
       "      <td>0.331630</td>\n",
       "      <td>0.096917</td>\n",
       "      <td>0.088250</td>\n",
       "      <td>0.514709</td>\n",
       "      <td>0.148577</td>\n",
       "      <td>0.084902</td>\n",
       "      <td>0.400590</td>\n",
       "      <td>0.126909</td>\n",
       "      <td>0.090805</td>\n",
       "      <td>0.112235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VitB6_mg</th>\n",
       "      <td>0.449060</td>\n",
       "      <td>0.489240</td>\n",
       "      <td>0.232468</td>\n",
       "      <td>0.439056</td>\n",
       "      <td>0.279604</td>\n",
       "      <td>0.400208</td>\n",
       "      <td>0.179172</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.358119</td>\n",
       "      <td>0.300247</td>\n",
       "      <td>0.337471</td>\n",
       "      <td>0.582070</td>\n",
       "      <td>0.783134</td>\n",
       "      <td>0.673398</td>\n",
       "      <td>0.512619</td>\n",
       "      <td>0.335545</td>\n",
       "      <td>0.248638</td>\n",
       "      <td>0.590467</td>\n",
       "      <td>0.457876</td>\n",
       "      <td>0.097245</td>\n",
       "      <td>0.484895</td>\n",
       "      <td>0.279476</td>\n",
       "      <td>0.574361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VitB12_mcg</th>\n",
       "      <td>0.215808</td>\n",
       "      <td>0.367282</td>\n",
       "      <td>0.136991</td>\n",
       "      <td>0.104197</td>\n",
       "      <td>0.077580</td>\n",
       "      <td>0.073839</td>\n",
       "      <td>0.551557</td>\n",
       "      <td>0.358119</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042564</td>\n",
       "      <td>0.116171</td>\n",
       "      <td>0.215890</td>\n",
       "      <td>0.376684</td>\n",
       "      <td>0.485538</td>\n",
       "      <td>0.194360</td>\n",
       "      <td>0.115055</td>\n",
       "      <td>0.558516</td>\n",
       "      <td>0.274872</td>\n",
       "      <td>0.140917</td>\n",
       "      <td>0.270868</td>\n",
       "      <td>0.308949</td>\n",
       "      <td>0.301306</td>\n",
       "      <td>0.387946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VitC_mg</th>\n",
       "      <td>0.087609</td>\n",
       "      <td>0.055134</td>\n",
       "      <td>0.025449</td>\n",
       "      <td>0.144249</td>\n",
       "      <td>0.114590</td>\n",
       "      <td>0.130695</td>\n",
       "      <td>0.133914</td>\n",
       "      <td>0.300247</td>\n",
       "      <td>0.042564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.088876</td>\n",
       "      <td>0.098877</td>\n",
       "      <td>0.247042</td>\n",
       "      <td>0.262685</td>\n",
       "      <td>0.100743</td>\n",
       "      <td>0.166521</td>\n",
       "      <td>0.069355</td>\n",
       "      <td>0.124424</td>\n",
       "      <td>0.164318</td>\n",
       "      <td>0.028353</td>\n",
       "      <td>0.100202</td>\n",
       "      <td>0.022864</td>\n",
       "      <td>0.082463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VitE_mg</th>\n",
       "      <td>0.355812</td>\n",
       "      <td>0.141700</td>\n",
       "      <td>0.399340</td>\n",
       "      <td>0.189625</td>\n",
       "      <td>0.149870</td>\n",
       "      <td>0.234848</td>\n",
       "      <td>0.072817</td>\n",
       "      <td>0.337471</td>\n",
       "      <td>0.116171</td>\n",
       "      <td>0.088876</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.213788</td>\n",
       "      <td>0.270387</td>\n",
       "      <td>0.230655</td>\n",
       "      <td>0.182370</td>\n",
       "      <td>0.180324</td>\n",
       "      <td>0.146270</td>\n",
       "      <td>0.229573</td>\n",
       "      <td>0.269097</td>\n",
       "      <td>0.118795</td>\n",
       "      <td>0.203789</td>\n",
       "      <td>0.103910</td>\n",
       "      <td>0.245000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Folate_mcg</th>\n",
       "      <td>0.287575</td>\n",
       "      <td>0.193191</td>\n",
       "      <td>0.095294</td>\n",
       "      <td>0.405672</td>\n",
       "      <td>0.251256</td>\n",
       "      <td>0.324608</td>\n",
       "      <td>0.135406</td>\n",
       "      <td>0.582070</td>\n",
       "      <td>0.215890</td>\n",
       "      <td>0.098877</td>\n",
       "      <td>0.213788</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.565268</td>\n",
       "      <td>0.607366</td>\n",
       "      <td>0.577117</td>\n",
       "      <td>0.233171</td>\n",
       "      <td>0.191492</td>\n",
       "      <td>0.528007</td>\n",
       "      <td>0.320728</td>\n",
       "      <td>0.076416</td>\n",
       "      <td>0.271784</td>\n",
       "      <td>0.133811</td>\n",
       "      <td>0.389820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Niacin_mg</th>\n",
       "      <td>0.544722</td>\n",
       "      <td>0.629932</td>\n",
       "      <td>0.302234</td>\n",
       "      <td>0.474099</td>\n",
       "      <td>0.275656</td>\n",
       "      <td>0.346828</td>\n",
       "      <td>0.193504</td>\n",
       "      <td>0.783134</td>\n",
       "      <td>0.376684</td>\n",
       "      <td>0.247042</td>\n",
       "      <td>0.270387</td>\n",
       "      <td>0.565268</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.811387</td>\n",
       "      <td>0.671829</td>\n",
       "      <td>0.324186</td>\n",
       "      <td>0.287173</td>\n",
       "      <td>0.617670</td>\n",
       "      <td>0.476265</td>\n",
       "      <td>0.128605</td>\n",
       "      <td>0.566982</td>\n",
       "      <td>0.360083</td>\n",
       "      <td>0.616919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Riboflavin_mg</th>\n",
       "      <td>0.453717</td>\n",
       "      <td>0.463299</td>\n",
       "      <td>0.229691</td>\n",
       "      <td>0.455133</td>\n",
       "      <td>0.303632</td>\n",
       "      <td>0.327400</td>\n",
       "      <td>0.331630</td>\n",
       "      <td>0.673398</td>\n",
       "      <td>0.485538</td>\n",
       "      <td>0.262685</td>\n",
       "      <td>0.230655</td>\n",
       "      <td>0.607366</td>\n",
       "      <td>0.811387</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695776</td>\n",
       "      <td>0.383644</td>\n",
       "      <td>0.381470</td>\n",
       "      <td>0.610033</td>\n",
       "      <td>0.407274</td>\n",
       "      <td>0.132550</td>\n",
       "      <td>0.484691</td>\n",
       "      <td>0.296794</td>\n",
       "      <td>0.508958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thiamin_mg</th>\n",
       "      <td>0.398596</td>\n",
       "      <td>0.333349</td>\n",
       "      <td>0.200149</td>\n",
       "      <td>0.436369</td>\n",
       "      <td>0.242777</td>\n",
       "      <td>0.329183</td>\n",
       "      <td>0.096917</td>\n",
       "      <td>0.512619</td>\n",
       "      <td>0.194360</td>\n",
       "      <td>0.100743</td>\n",
       "      <td>0.182370</td>\n",
       "      <td>0.577117</td>\n",
       "      <td>0.671829</td>\n",
       "      <td>0.695776</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.268800</td>\n",
       "      <td>0.211432</td>\n",
       "      <td>0.501668</td>\n",
       "      <td>0.378112</td>\n",
       "      <td>0.073586</td>\n",
       "      <td>0.389395</td>\n",
       "      <td>0.193862</td>\n",
       "      <td>0.382505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calcium_mg</th>\n",
       "      <td>0.385803</td>\n",
       "      <td>0.321588</td>\n",
       "      <td>0.228190</td>\n",
       "      <td>0.391409</td>\n",
       "      <td>0.286461</td>\n",
       "      <td>0.388942</td>\n",
       "      <td>0.088250</td>\n",
       "      <td>0.335545</td>\n",
       "      <td>0.115055</td>\n",
       "      <td>0.166521</td>\n",
       "      <td>0.180324</td>\n",
       "      <td>0.233171</td>\n",
       "      <td>0.324186</td>\n",
       "      <td>0.383644</td>\n",
       "      <td>0.268800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216524</td>\n",
       "      <td>0.487069</td>\n",
       "      <td>0.475692</td>\n",
       "      <td>0.106731</td>\n",
       "      <td>0.570311</td>\n",
       "      <td>0.166295</td>\n",
       "      <td>0.315453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Copper_mcg</th>\n",
       "      <td>0.311823</td>\n",
       "      <td>0.335313</td>\n",
       "      <td>0.211551</td>\n",
       "      <td>0.248292</td>\n",
       "      <td>0.133010</td>\n",
       "      <td>0.308138</td>\n",
       "      <td>0.514709</td>\n",
       "      <td>0.248638</td>\n",
       "      <td>0.558516</td>\n",
       "      <td>0.069355</td>\n",
       "      <td>0.146270</td>\n",
       "      <td>0.191492</td>\n",
       "      <td>0.287173</td>\n",
       "      <td>0.381470</td>\n",
       "      <td>0.211432</td>\n",
       "      <td>0.216524</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.298581</td>\n",
       "      <td>0.462657</td>\n",
       "      <td>0.198564</td>\n",
       "      <td>0.397601</td>\n",
       "      <td>0.237917</td>\n",
       "      <td>0.375766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iron_mg</th>\n",
       "      <td>0.447371</td>\n",
       "      <td>0.385484</td>\n",
       "      <td>0.205638</td>\n",
       "      <td>0.522209</td>\n",
       "      <td>0.283730</td>\n",
       "      <td>0.506442</td>\n",
       "      <td>0.148577</td>\n",
       "      <td>0.590467</td>\n",
       "      <td>0.274872</td>\n",
       "      <td>0.124424</td>\n",
       "      <td>0.229573</td>\n",
       "      <td>0.528007</td>\n",
       "      <td>0.617670</td>\n",
       "      <td>0.610033</td>\n",
       "      <td>0.501668</td>\n",
       "      <td>0.487069</td>\n",
       "      <td>0.298581</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.533767</td>\n",
       "      <td>0.119003</td>\n",
       "      <td>0.449180</td>\n",
       "      <td>0.218177</td>\n",
       "      <td>0.505101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Magnesium_mg</th>\n",
       "      <td>0.532141</td>\n",
       "      <td>0.495921</td>\n",
       "      <td>0.329600</td>\n",
       "      <td>0.507055</td>\n",
       "      <td>0.248467</td>\n",
       "      <td>0.638502</td>\n",
       "      <td>0.084902</td>\n",
       "      <td>0.457876</td>\n",
       "      <td>0.140917</td>\n",
       "      <td>0.164318</td>\n",
       "      <td>0.269097</td>\n",
       "      <td>0.320728</td>\n",
       "      <td>0.476265</td>\n",
       "      <td>0.407274</td>\n",
       "      <td>0.378112</td>\n",
       "      <td>0.475692</td>\n",
       "      <td>0.462657</td>\n",
       "      <td>0.533767</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.193979</td>\n",
       "      <td>0.658858</td>\n",
       "      <td>0.301562</td>\n",
       "      <td>0.442163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manganese_mg</th>\n",
       "      <td>0.084908</td>\n",
       "      <td>0.085277</td>\n",
       "      <td>0.043005</td>\n",
       "      <td>0.091997</td>\n",
       "      <td>0.043915</td>\n",
       "      <td>0.124949</td>\n",
       "      <td>0.400590</td>\n",
       "      <td>0.097245</td>\n",
       "      <td>0.270868</td>\n",
       "      <td>0.028353</td>\n",
       "      <td>0.118795</td>\n",
       "      <td>0.076416</td>\n",
       "      <td>0.128605</td>\n",
       "      <td>0.132550</td>\n",
       "      <td>0.073586</td>\n",
       "      <td>0.106731</td>\n",
       "      <td>0.198564</td>\n",
       "      <td>0.119003</td>\n",
       "      <td>0.193979</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.121482</td>\n",
       "      <td>0.051999</td>\n",
       "      <td>0.096211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phosphorus_mg</th>\n",
       "      <td>0.636663</td>\n",
       "      <td>0.756445</td>\n",
       "      <td>0.420771</td>\n",
       "      <td>0.464062</td>\n",
       "      <td>0.249930</td>\n",
       "      <td>0.411295</td>\n",
       "      <td>0.126909</td>\n",
       "      <td>0.484895</td>\n",
       "      <td>0.308949</td>\n",
       "      <td>0.100202</td>\n",
       "      <td>0.203789</td>\n",
       "      <td>0.271784</td>\n",
       "      <td>0.566982</td>\n",
       "      <td>0.484691</td>\n",
       "      <td>0.389395</td>\n",
       "      <td>0.570311</td>\n",
       "      <td>0.397601</td>\n",
       "      <td>0.449180</td>\n",
       "      <td>0.658858</td>\n",
       "      <td>0.121482</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.444874</td>\n",
       "      <td>0.538108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Selenium_mcg</th>\n",
       "      <td>0.349990</td>\n",
       "      <td>0.523954</td>\n",
       "      <td>0.250839</td>\n",
       "      <td>0.168791</td>\n",
       "      <td>0.074555</td>\n",
       "      <td>0.141708</td>\n",
       "      <td>0.090805</td>\n",
       "      <td>0.279476</td>\n",
       "      <td>0.301306</td>\n",
       "      <td>0.022864</td>\n",
       "      <td>0.103910</td>\n",
       "      <td>0.133811</td>\n",
       "      <td>0.360083</td>\n",
       "      <td>0.296794</td>\n",
       "      <td>0.193862</td>\n",
       "      <td>0.166295</td>\n",
       "      <td>0.237917</td>\n",
       "      <td>0.218177</td>\n",
       "      <td>0.301562</td>\n",
       "      <td>0.051999</td>\n",
       "      <td>0.444874</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.362090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zinc_mg</th>\n",
       "      <td>0.459805</td>\n",
       "      <td>0.611805</td>\n",
       "      <td>0.299095</td>\n",
       "      <td>0.307205</td>\n",
       "      <td>0.201107</td>\n",
       "      <td>0.280464</td>\n",
       "      <td>0.112235</td>\n",
       "      <td>0.574361</td>\n",
       "      <td>0.387946</td>\n",
       "      <td>0.082463</td>\n",
       "      <td>0.245000</td>\n",
       "      <td>0.389820</td>\n",
       "      <td>0.616919</td>\n",
       "      <td>0.508958</td>\n",
       "      <td>0.382505</td>\n",
       "      <td>0.315453</td>\n",
       "      <td>0.375766</td>\n",
       "      <td>0.505101</td>\n",
       "      <td>0.442163</td>\n",
       "      <td>0.096211</td>\n",
       "      <td>0.538108</td>\n",
       "      <td>0.362090</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Energy_kcal  Protein_g     Fat_g    Carb_g   Sugar_g   Fiber_g  \\\n",
       "Energy_kcal    1.000000     0.633667   0.849344  0.723890  0.514850  0.444475   \n",
       "Protein_g      0.633667     1.000000   0.439886  0.301298  0.158528  0.267816   \n",
       "Fat_g          0.849344     0.439886   1.000000  0.309798  0.237585  0.214106   \n",
       "Carb_g         0.723890     0.301298   0.309798  1.000000  0.705978  0.588489   \n",
       "Sugar_g        0.514850     0.158528   0.237585  0.705978  1.000000  0.277170   \n",
       "Fiber_g        0.444475     0.267816   0.214106  0.588489  0.277170  1.000000   \n",
       "VitA_mcg       0.114950     0.104374   0.089759  0.080867  0.064980  0.060091   \n",
       "VitB6_mg       0.449060     0.489240   0.232468  0.439056  0.279604  0.400208   \n",
       "VitB12_mcg     0.215808     0.367282   0.136991  0.104197  0.077580  0.073839   \n",
       "VitC_mg        0.087609     0.055134   0.025449  0.144249  0.114590  0.130695   \n",
       "VitE_mg        0.355812     0.141700   0.399340  0.189625  0.149870  0.234848   \n",
       "Folate_mcg     0.287575     0.193191   0.095294  0.405672  0.251256  0.324608   \n",
       "Niacin_mg      0.544722     0.629932   0.302234  0.474099  0.275656  0.346828   \n",
       "Riboflavin_mg  0.453717     0.463299   0.229691  0.455133  0.303632  0.327400   \n",
       "Thiamin_mg     0.398596     0.333349   0.200149  0.436369  0.242777  0.329183   \n",
       "Calcium_mg     0.385803     0.321588   0.228190  0.391409  0.286461  0.388942   \n",
       "Copper_mcg     0.311823     0.335313   0.211551  0.248292  0.133010  0.308138   \n",
       "Iron_mg        0.447371     0.385484   0.205638  0.522209  0.283730  0.506442   \n",
       "Magnesium_mg   0.532141     0.495921   0.329600  0.507055  0.248467  0.638502   \n",
       "Manganese_mg   0.084908     0.085277   0.043005  0.091997  0.043915  0.124949   \n",
       "Phosphorus_mg  0.636663     0.756445   0.420771  0.464062  0.249930  0.411295   \n",
       "Selenium_mcg   0.349990     0.523954   0.250839  0.168791  0.074555  0.141708   \n",
       "Zinc_mg        0.459805     0.611805   0.299095  0.307205  0.201107  0.280464   \n",
       "\n",
       "               VitA_mcg  VitB6_mg  VitB12_mcg   VitC_mg   VitE_mg  Folate_mcg  \\\n",
       "Energy_kcal    0.114950  0.449060  0.215808    0.087609  0.355812  0.287575     \n",
       "Protein_g      0.104374  0.489240  0.367282    0.055134  0.141700  0.193191     \n",
       "Fat_g          0.089759  0.232468  0.136991    0.025449  0.399340  0.095294     \n",
       "Carb_g         0.080867  0.439056  0.104197    0.144249  0.189625  0.405672     \n",
       "Sugar_g        0.064980  0.279604  0.077580    0.114590  0.149870  0.251256     \n",
       "Fiber_g        0.060091  0.400208  0.073839    0.130695  0.234848  0.324608     \n",
       "VitA_mcg       1.000000  0.179172  0.551557    0.133914  0.072817  0.135406     \n",
       "VitB6_mg       0.179172  1.000000  0.358119    0.300247  0.337471  0.582070     \n",
       "VitB12_mcg     0.551557  0.358119  1.000000    0.042564  0.116171  0.215890     \n",
       "VitC_mg        0.133914  0.300247  0.042564    1.000000  0.088876  0.098877     \n",
       "VitE_mg        0.072817  0.337471  0.116171    0.088876  1.000000  0.213788     \n",
       "Folate_mcg     0.135406  0.582070  0.215890    0.098877  0.213788  1.000000     \n",
       "Niacin_mg      0.193504  0.783134  0.376684    0.247042  0.270387  0.565268     \n",
       "Riboflavin_mg  0.331630  0.673398  0.485538    0.262685  0.230655  0.607366     \n",
       "Thiamin_mg     0.096917  0.512619  0.194360    0.100743  0.182370  0.577117     \n",
       "Calcium_mg     0.088250  0.335545  0.115055    0.166521  0.180324  0.233171     \n",
       "Copper_mcg     0.514709  0.248638  0.558516    0.069355  0.146270  0.191492     \n",
       "Iron_mg        0.148577  0.590467  0.274872    0.124424  0.229573  0.528007     \n",
       "Magnesium_mg   0.084902  0.457876  0.140917    0.164318  0.269097  0.320728     \n",
       "Manganese_mg   0.400590  0.097245  0.270868    0.028353  0.118795  0.076416     \n",
       "Phosphorus_mg  0.126909  0.484895  0.308949    0.100202  0.203789  0.271784     \n",
       "Selenium_mcg   0.090805  0.279476  0.301306    0.022864  0.103910  0.133811     \n",
       "Zinc_mg        0.112235  0.574361  0.387946    0.082463  0.245000  0.389820     \n",
       "\n",
       "               Niacin_mg  Riboflavin_mg  Thiamin_mg  Calcium_mg  Copper_mcg  \\\n",
       "Energy_kcal    0.544722   0.453717       0.398596    0.385803    0.311823     \n",
       "Protein_g      0.629932   0.463299       0.333349    0.321588    0.335313     \n",
       "Fat_g          0.302234   0.229691       0.200149    0.228190    0.211551     \n",
       "Carb_g         0.474099   0.455133       0.436369    0.391409    0.248292     \n",
       "Sugar_g        0.275656   0.303632       0.242777    0.286461    0.133010     \n",
       "Fiber_g        0.346828   0.327400       0.329183    0.388942    0.308138     \n",
       "VitA_mcg       0.193504   0.331630       0.096917    0.088250    0.514709     \n",
       "VitB6_mg       0.783134   0.673398       0.512619    0.335545    0.248638     \n",
       "VitB12_mcg     0.376684   0.485538       0.194360    0.115055    0.558516     \n",
       "VitC_mg        0.247042   0.262685       0.100743    0.166521    0.069355     \n",
       "VitE_mg        0.270387   0.230655       0.182370    0.180324    0.146270     \n",
       "Folate_mcg     0.565268   0.607366       0.577117    0.233171    0.191492     \n",
       "Niacin_mg      1.000000   0.811387       0.671829    0.324186    0.287173     \n",
       "Riboflavin_mg  0.811387   1.000000       0.695776    0.383644    0.381470     \n",
       "Thiamin_mg     0.671829   0.695776       1.000000    0.268800    0.211432     \n",
       "Calcium_mg     0.324186   0.383644       0.268800    1.000000    0.216524     \n",
       "Copper_mcg     0.287173   0.381470       0.211432    0.216524    1.000000     \n",
       "Iron_mg        0.617670   0.610033       0.501668    0.487069    0.298581     \n",
       "Magnesium_mg   0.476265   0.407274       0.378112    0.475692    0.462657     \n",
       "Manganese_mg   0.128605   0.132550       0.073586    0.106731    0.198564     \n",
       "Phosphorus_mg  0.566982   0.484691       0.389395    0.570311    0.397601     \n",
       "Selenium_mcg   0.360083   0.296794       0.193862    0.166295    0.237917     \n",
       "Zinc_mg        0.616919   0.508958       0.382505    0.315453    0.375766     \n",
       "\n",
       "                Iron_mg  Magnesium_mg  Manganese_mg  Phosphorus_mg  \\\n",
       "Energy_kcal    0.447371  0.532141      0.084908      0.636663        \n",
       "Protein_g      0.385484  0.495921      0.085277      0.756445        \n",
       "Fat_g          0.205638  0.329600      0.043005      0.420771        \n",
       "Carb_g         0.522209  0.507055      0.091997      0.464062        \n",
       "Sugar_g        0.283730  0.248467      0.043915      0.249930        \n",
       "Fiber_g        0.506442  0.638502      0.124949      0.411295        \n",
       "VitA_mcg       0.148577  0.084902      0.400590      0.126909        \n",
       "VitB6_mg       0.590467  0.457876      0.097245      0.484895        \n",
       "VitB12_mcg     0.274872  0.140917      0.270868      0.308949        \n",
       "VitC_mg        0.124424  0.164318      0.028353      0.100202        \n",
       "VitE_mg        0.229573  0.269097      0.118795      0.203789        \n",
       "Folate_mcg     0.528007  0.320728      0.076416      0.271784        \n",
       "Niacin_mg      0.617670  0.476265      0.128605      0.566982        \n",
       "Riboflavin_mg  0.610033  0.407274      0.132550      0.484691        \n",
       "Thiamin_mg     0.501668  0.378112      0.073586      0.389395        \n",
       "Calcium_mg     0.487069  0.475692      0.106731      0.570311        \n",
       "Copper_mcg     0.298581  0.462657      0.198564      0.397601        \n",
       "Iron_mg        1.000000  0.533767      0.119003      0.449180        \n",
       "Magnesium_mg   0.533767  1.000000      0.193979      0.658858        \n",
       "Manganese_mg   0.119003  0.193979      1.000000      0.121482        \n",
       "Phosphorus_mg  0.449180  0.658858      0.121482      1.000000        \n",
       "Selenium_mcg   0.218177  0.301562      0.051999      0.444874        \n",
       "Zinc_mg        0.505101  0.442163      0.096211      0.538108        \n",
       "\n",
       "               Selenium_mcg   Zinc_mg  \n",
       "Energy_kcal    0.349990      0.459805  \n",
       "Protein_g      0.523954      0.611805  \n",
       "Fat_g          0.250839      0.299095  \n",
       "Carb_g         0.168791      0.307205  \n",
       "Sugar_g        0.074555      0.201107  \n",
       "Fiber_g        0.141708      0.280464  \n",
       "VitA_mcg       0.090805      0.112235  \n",
       "VitB6_mg       0.279476      0.574361  \n",
       "VitB12_mcg     0.301306      0.387946  \n",
       "VitC_mg        0.022864      0.082463  \n",
       "VitE_mg        0.103910      0.245000  \n",
       "Folate_mcg     0.133811      0.389820  \n",
       "Niacin_mg      0.360083      0.616919  \n",
       "Riboflavin_mg  0.296794      0.508958  \n",
       "Thiamin_mg     0.193862      0.382505  \n",
       "Calcium_mg     0.166295      0.315453  \n",
       "Copper_mcg     0.237917      0.375766  \n",
       "Iron_mg        0.218177      0.505101  \n",
       "Magnesium_mg   0.301562      0.442163  \n",
       "Manganese_mg   0.051999      0.096211  \n",
       "Phosphorus_mg  0.444874      0.538108  \n",
       "Selenium_mcg   1.000000      0.362090  \n",
       "Zinc_mg        0.362090      1.000000  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5. Feature selection according to the correlation\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.options.display.max_columns = 27\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarities = cosine_similarity(food_data_exp.iloc[:,0:].transpose())\n",
    "similarities = pd.DataFrame(similarities, columns=food_data_exp.columns[0:], index=food_data_exp.columns[0:])\n",
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Energy_kcal</th>\n",
       "      <th>Protein_g</th>\n",
       "      <th>Fat_g</th>\n",
       "      <th>Carb_g</th>\n",
       "      <th>Sugar_g</th>\n",
       "      <th>Fiber_g</th>\n",
       "      <th>VitA_mcg</th>\n",
       "      <th>VitB6_mg</th>\n",
       "      <th>VitB12_mcg</th>\n",
       "      <th>VitC_mg</th>\n",
       "      <th>VitE_mg</th>\n",
       "      <th>Folate_mcg</th>\n",
       "      <th>Niacin_mg</th>\n",
       "      <th>Riboflavin_mg</th>\n",
       "      <th>Thiamin_mg</th>\n",
       "      <th>Calcium_mg</th>\n",
       "      <th>Copper_mcg</th>\n",
       "      <th>Iron_mg</th>\n",
       "      <th>Magnesium_mg</th>\n",
       "      <th>Manganese_mg</th>\n",
       "      <th>Phosphorus_mg</th>\n",
       "      <th>Selenium_mcg</th>\n",
       "      <th>Zinc_mg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Energy_kcal</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.113075</td>\n",
       "      <td>0.810032</td>\n",
       "      <td>0.480454</td>\n",
       "      <td>0.309132</td>\n",
       "      <td>0.196089</td>\n",
       "      <td>0.028998</td>\n",
       "      <td>0.120040</td>\n",
       "      <td>-0.011519</td>\n",
       "      <td>-0.034207</td>\n",
       "      <td>0.305811</td>\n",
       "      <td>0.141852</td>\n",
       "      <td>0.173559</td>\n",
       "      <td>0.154671</td>\n",
       "      <td>0.184114</td>\n",
       "      <td>0.148047</td>\n",
       "      <td>0.109043</td>\n",
       "      <td>0.197628</td>\n",
       "      <td>0.253930</td>\n",
       "      <td>0.037101</td>\n",
       "      <td>0.237934</td>\n",
       "      <td>0.057343</td>\n",
       "      <td>0.111197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Protein_g</th>\n",
       "      <td>0.113075</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.054437</td>\n",
       "      <td>-0.296643</td>\n",
       "      <td>-0.264515</td>\n",
       "      <td>-0.070076</td>\n",
       "      <td>0.021516</td>\n",
       "      <td>0.225822</td>\n",
       "      <td>0.249643</td>\n",
       "      <td>-0.066024</td>\n",
       "      <td>-0.031358</td>\n",
       "      <td>0.006607</td>\n",
       "      <td>0.373454</td>\n",
       "      <td>0.202333</td>\n",
       "      <td>0.097013</td>\n",
       "      <td>0.067324</td>\n",
       "      <td>0.164022</td>\n",
       "      <td>0.118426</td>\n",
       "      <td>0.217711</td>\n",
       "      <td>0.040836</td>\n",
       "      <td>0.530065</td>\n",
       "      <td>0.371473</td>\n",
       "      <td>0.412753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fat_g</th>\n",
       "      <td>0.810032</td>\n",
       "      <td>0.054437</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.056866</td>\n",
       "      <td>-0.005833</td>\n",
       "      <td>-0.027884</td>\n",
       "      <td>0.026382</td>\n",
       "      <td>-0.049827</td>\n",
       "      <td>-0.022493</td>\n",
       "      <td>-0.060452</td>\n",
       "      <td>0.341167</td>\n",
       "      <td>-0.059215</td>\n",
       "      <td>-0.025974</td>\n",
       "      <td>-0.039332</td>\n",
       "      <td>-0.007518</td>\n",
       "      <td>0.021942</td>\n",
       "      <td>0.047853</td>\n",
       "      <td>-0.041231</td>\n",
       "      <td>0.071006</td>\n",
       "      <td>-0.000766</td>\n",
       "      <td>0.083566</td>\n",
       "      <td>0.038201</td>\n",
       "      <td>0.026614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carb_g</th>\n",
       "      <td>0.480454</td>\n",
       "      <td>-0.296643</td>\n",
       "      <td>-0.056866</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.617633</td>\n",
       "      <td>0.458705</td>\n",
       "      <td>0.006041</td>\n",
       "      <td>0.201565</td>\n",
       "      <td>-0.092368</td>\n",
       "      <td>0.077416</td>\n",
       "      <td>0.068188</td>\n",
       "      <td>0.325015</td>\n",
       "      <td>0.180896</td>\n",
       "      <td>0.238894</td>\n",
       "      <td>0.283086</td>\n",
       "      <td>0.213814</td>\n",
       "      <td>0.072177</td>\n",
       "      <td>0.363276</td>\n",
       "      <td>0.288108</td>\n",
       "      <td>0.055297</td>\n",
       "      <td>0.086996</td>\n",
       "      <td>-0.110976</td>\n",
       "      <td>-0.009538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sugar_g</th>\n",
       "      <td>0.309132</td>\n",
       "      <td>-0.264515</td>\n",
       "      <td>-0.005833</td>\n",
       "      <td>0.617633</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.114439</td>\n",
       "      <td>0.013232</td>\n",
       "      <td>0.088212</td>\n",
       "      <td>-0.050334</td>\n",
       "      <td>0.062534</td>\n",
       "      <td>0.061310</td>\n",
       "      <td>0.160402</td>\n",
       "      <td>0.034759</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>0.097777</td>\n",
       "      <td>0.145591</td>\n",
       "      <td>-0.003302</td>\n",
       "      <td>0.121174</td>\n",
       "      <td>0.039454</td>\n",
       "      <td>0.010921</td>\n",
       "      <td>-0.056850</td>\n",
       "      <td>-0.119580</td>\n",
       "      <td>-0.022806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fiber_g</th>\n",
       "      <td>0.196089</td>\n",
       "      <td>-0.070076</td>\n",
       "      <td>-0.027884</td>\n",
       "      <td>0.458705</td>\n",
       "      <td>0.114439</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009382</td>\n",
       "      <td>0.247103</td>\n",
       "      <td>-0.050372</td>\n",
       "      <td>0.081917</td>\n",
       "      <td>0.160121</td>\n",
       "      <td>0.246715</td>\n",
       "      <td>0.140053</td>\n",
       "      <td>0.163199</td>\n",
       "      <td>0.205182</td>\n",
       "      <td>0.272461</td>\n",
       "      <td>0.204587</td>\n",
       "      <td>0.398290</td>\n",
       "      <td>0.544178</td>\n",
       "      <td>0.101604</td>\n",
       "      <td>0.193317</td>\n",
       "      <td>-0.032126</td>\n",
       "      <td>0.086569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VitA_mcg</th>\n",
       "      <td>0.028998</td>\n",
       "      <td>0.021516</td>\n",
       "      <td>0.026382</td>\n",
       "      <td>0.006041</td>\n",
       "      <td>0.013232</td>\n",
       "      <td>0.009382</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.138238</td>\n",
       "      <td>0.542905</td>\n",
       "      <td>0.119372</td>\n",
       "      <td>0.047343</td>\n",
       "      <td>0.108445</td>\n",
       "      <td>0.151750</td>\n",
       "      <td>0.312731</td>\n",
       "      <td>0.056042</td>\n",
       "      <td>0.045554</td>\n",
       "      <td>0.505419</td>\n",
       "      <td>0.107529</td>\n",
       "      <td>0.027599</td>\n",
       "      <td>0.395174</td>\n",
       "      <td>0.061753</td>\n",
       "      <td>0.046243</td>\n",
       "      <td>0.059143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VitB6_mg</th>\n",
       "      <td>0.120040</td>\n",
       "      <td>0.225822</td>\n",
       "      <td>-0.049827</td>\n",
       "      <td>0.201565</td>\n",
       "      <td>0.088212</td>\n",
       "      <td>0.247103</td>\n",
       "      <td>0.138238</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.265888</td>\n",
       "      <td>0.270805</td>\n",
       "      <td>0.270281</td>\n",
       "      <td>0.541268</td>\n",
       "      <td>0.705492</td>\n",
       "      <td>0.578992</td>\n",
       "      <td>0.410394</td>\n",
       "      <td>0.187758</td>\n",
       "      <td>0.117541</td>\n",
       "      <td>0.485856</td>\n",
       "      <td>0.285059</td>\n",
       "      <td>0.068001</td>\n",
       "      <td>0.251267</td>\n",
       "      <td>0.108312</td>\n",
       "      <td>0.437833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VitB12_mcg</th>\n",
       "      <td>-0.011519</td>\n",
       "      <td>0.249643</td>\n",
       "      <td>-0.022493</td>\n",
       "      <td>-0.092368</td>\n",
       "      <td>-0.050334</td>\n",
       "      <td>-0.050372</td>\n",
       "      <td>0.542905</td>\n",
       "      <td>0.265888</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005161</td>\n",
       "      <td>0.058371</td>\n",
       "      <td>0.155546</td>\n",
       "      <td>0.275586</td>\n",
       "      <td>0.418739</td>\n",
       "      <td>0.102293</td>\n",
       "      <td>0.010437</td>\n",
       "      <td>0.516809</td>\n",
       "      <td>0.179947</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.260083</td>\n",
       "      <td>0.172916</td>\n",
       "      <td>0.216055</td>\n",
       "      <td>0.298563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VitC_mg</th>\n",
       "      <td>-0.034207</td>\n",
       "      <td>-0.066024</td>\n",
       "      <td>-0.060452</td>\n",
       "      <td>0.077416</td>\n",
       "      <td>0.062534</td>\n",
       "      <td>0.081917</td>\n",
       "      <td>0.119372</td>\n",
       "      <td>0.270805</td>\n",
       "      <td>0.005161</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.061078</td>\n",
       "      <td>0.067004</td>\n",
       "      <td>0.208848</td>\n",
       "      <td>0.227796</td>\n",
       "      <td>0.055077</td>\n",
       "      <td>0.125651</td>\n",
       "      <td>0.028818</td>\n",
       "      <td>0.074624</td>\n",
       "      <td>0.112664</td>\n",
       "      <td>0.017967</td>\n",
       "      <td>0.014266</td>\n",
       "      <td>-0.034133</td>\n",
       "      <td>0.016846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VitE_mg</th>\n",
       "      <td>0.305811</td>\n",
       "      <td>-0.031358</td>\n",
       "      <td>0.341167</td>\n",
       "      <td>0.068188</td>\n",
       "      <td>0.061310</td>\n",
       "      <td>0.160121</td>\n",
       "      <td>0.047343</td>\n",
       "      <td>0.270281</td>\n",
       "      <td>0.058371</td>\n",
       "      <td>0.061078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166658</td>\n",
       "      <td>0.179741</td>\n",
       "      <td>0.148242</td>\n",
       "      <td>0.111069</td>\n",
       "      <td>0.106907</td>\n",
       "      <td>0.083432</td>\n",
       "      <td>0.153681</td>\n",
       "      <td>0.187797</td>\n",
       "      <td>0.104365</td>\n",
       "      <td>0.078640</td>\n",
       "      <td>0.017788</td>\n",
       "      <td>0.158849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Folate_mcg</th>\n",
       "      <td>0.141852</td>\n",
       "      <td>0.006607</td>\n",
       "      <td>-0.059215</td>\n",
       "      <td>0.325015</td>\n",
       "      <td>0.160402</td>\n",
       "      <td>0.246715</td>\n",
       "      <td>0.108445</td>\n",
       "      <td>0.541268</td>\n",
       "      <td>0.155546</td>\n",
       "      <td>0.067004</td>\n",
       "      <td>0.166658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.528162</td>\n",
       "      <td>0.570303</td>\n",
       "      <td>0.536935</td>\n",
       "      <td>0.151721</td>\n",
       "      <td>0.121219</td>\n",
       "      <td>0.478794</td>\n",
       "      <td>0.229714</td>\n",
       "      <td>0.058408</td>\n",
       "      <td>0.140389</td>\n",
       "      <td>0.035520</td>\n",
       "      <td>0.312040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Niacin_mg</th>\n",
       "      <td>0.173559</td>\n",
       "      <td>0.373454</td>\n",
       "      <td>-0.025974</td>\n",
       "      <td>0.180896</td>\n",
       "      <td>0.034759</td>\n",
       "      <td>0.140053</td>\n",
       "      <td>0.151750</td>\n",
       "      <td>0.705492</td>\n",
       "      <td>0.275586</td>\n",
       "      <td>0.208848</td>\n",
       "      <td>0.179741</td>\n",
       "      <td>0.528162</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.751114</td>\n",
       "      <td>0.603888</td>\n",
       "      <td>0.139776</td>\n",
       "      <td>0.138413</td>\n",
       "      <td>0.503876</td>\n",
       "      <td>0.266029</td>\n",
       "      <td>0.102378</td>\n",
       "      <td>0.303390</td>\n",
       "      <td>0.174490</td>\n",
       "      <td>0.463304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Riboflavin_mg</th>\n",
       "      <td>0.154671</td>\n",
       "      <td>0.202333</td>\n",
       "      <td>-0.039332</td>\n",
       "      <td>0.238894</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>0.163199</td>\n",
       "      <td>0.312731</td>\n",
       "      <td>0.578992</td>\n",
       "      <td>0.418739</td>\n",
       "      <td>0.227796</td>\n",
       "      <td>0.148242</td>\n",
       "      <td>0.570303</td>\n",
       "      <td>0.751114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636720</td>\n",
       "      <td>0.252828</td>\n",
       "      <td>0.280912</td>\n",
       "      <td>0.514546</td>\n",
       "      <td>0.227744</td>\n",
       "      <td>0.108861</td>\n",
       "      <td>0.266330</td>\n",
       "      <td>0.137348</td>\n",
       "      <td>0.359455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thiamin_mg</th>\n",
       "      <td>0.184114</td>\n",
       "      <td>0.097013</td>\n",
       "      <td>-0.007518</td>\n",
       "      <td>0.283086</td>\n",
       "      <td>0.097777</td>\n",
       "      <td>0.205182</td>\n",
       "      <td>0.056042</td>\n",
       "      <td>0.410394</td>\n",
       "      <td>0.102293</td>\n",
       "      <td>0.055077</td>\n",
       "      <td>0.111069</td>\n",
       "      <td>0.536935</td>\n",
       "      <td>0.603888</td>\n",
       "      <td>0.636720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.149175</td>\n",
       "      <td>0.108564</td>\n",
       "      <td>0.409417</td>\n",
       "      <td>0.239739</td>\n",
       "      <td>0.048104</td>\n",
       "      <td>0.207057</td>\n",
       "      <td>0.054380</td>\n",
       "      <td>0.244424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calcium_mg</th>\n",
       "      <td>0.148047</td>\n",
       "      <td>0.067324</td>\n",
       "      <td>0.021942</td>\n",
       "      <td>0.213814</td>\n",
       "      <td>0.145591</td>\n",
       "      <td>0.272461</td>\n",
       "      <td>0.045554</td>\n",
       "      <td>0.187758</td>\n",
       "      <td>0.010437</td>\n",
       "      <td>0.125651</td>\n",
       "      <td>0.106907</td>\n",
       "      <td>0.151721</td>\n",
       "      <td>0.139776</td>\n",
       "      <td>0.252828</td>\n",
       "      <td>0.149175</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111385</td>\n",
       "      <td>0.388803</td>\n",
       "      <td>0.356572</td>\n",
       "      <td>0.083428</td>\n",
       "      <td>0.459891</td>\n",
       "      <td>0.017584</td>\n",
       "      <td>0.155498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Copper_mcg</th>\n",
       "      <td>0.109043</td>\n",
       "      <td>0.164022</td>\n",
       "      <td>0.047853</td>\n",
       "      <td>0.072177</td>\n",
       "      <td>-0.003302</td>\n",
       "      <td>0.204587</td>\n",
       "      <td>0.505419</td>\n",
       "      <td>0.117541</td>\n",
       "      <td>0.516809</td>\n",
       "      <td>0.028818</td>\n",
       "      <td>0.083432</td>\n",
       "      <td>0.121219</td>\n",
       "      <td>0.138413</td>\n",
       "      <td>0.280912</td>\n",
       "      <td>0.108564</td>\n",
       "      <td>0.111385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.192758</td>\n",
       "      <td>0.372453</td>\n",
       "      <td>0.183798</td>\n",
       "      <td>0.267908</td>\n",
       "      <td>0.130196</td>\n",
       "      <td>0.266263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iron_mg</th>\n",
       "      <td>0.197628</td>\n",
       "      <td>0.118426</td>\n",
       "      <td>-0.041231</td>\n",
       "      <td>0.363276</td>\n",
       "      <td>0.121174</td>\n",
       "      <td>0.398290</td>\n",
       "      <td>0.107529</td>\n",
       "      <td>0.485856</td>\n",
       "      <td>0.179947</td>\n",
       "      <td>0.074624</td>\n",
       "      <td>0.153681</td>\n",
       "      <td>0.478794</td>\n",
       "      <td>0.503876</td>\n",
       "      <td>0.514546</td>\n",
       "      <td>0.409417</td>\n",
       "      <td>0.388803</td>\n",
       "      <td>0.192758</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.409505</td>\n",
       "      <td>0.094919</td>\n",
       "      <td>0.246793</td>\n",
       "      <td>0.058624</td>\n",
       "      <td>0.372145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Magnesium_mg</th>\n",
       "      <td>0.253930</td>\n",
       "      <td>0.217711</td>\n",
       "      <td>0.071006</td>\n",
       "      <td>0.288108</td>\n",
       "      <td>0.039454</td>\n",
       "      <td>0.544178</td>\n",
       "      <td>0.027599</td>\n",
       "      <td>0.285059</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.112664</td>\n",
       "      <td>0.187797</td>\n",
       "      <td>0.229714</td>\n",
       "      <td>0.266029</td>\n",
       "      <td>0.227744</td>\n",
       "      <td>0.239739</td>\n",
       "      <td>0.356572</td>\n",
       "      <td>0.372453</td>\n",
       "      <td>0.409505</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.179271</td>\n",
       "      <td>0.504529</td>\n",
       "      <td>0.128531</td>\n",
       "      <td>0.254293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manganese_mg</th>\n",
       "      <td>0.037101</td>\n",
       "      <td>0.040836</td>\n",
       "      <td>-0.000766</td>\n",
       "      <td>0.055297</td>\n",
       "      <td>0.010921</td>\n",
       "      <td>0.101604</td>\n",
       "      <td>0.395174</td>\n",
       "      <td>0.068001</td>\n",
       "      <td>0.260083</td>\n",
       "      <td>0.017967</td>\n",
       "      <td>0.104365</td>\n",
       "      <td>0.058408</td>\n",
       "      <td>0.102378</td>\n",
       "      <td>0.108861</td>\n",
       "      <td>0.048104</td>\n",
       "      <td>0.083428</td>\n",
       "      <td>0.183798</td>\n",
       "      <td>0.094919</td>\n",
       "      <td>0.179271</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.093094</td>\n",
       "      <td>0.022682</td>\n",
       "      <td>0.065860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phosphorus_mg</th>\n",
       "      <td>0.237934</td>\n",
       "      <td>0.530065</td>\n",
       "      <td>0.083566</td>\n",
       "      <td>0.086996</td>\n",
       "      <td>-0.056850</td>\n",
       "      <td>0.193317</td>\n",
       "      <td>0.061753</td>\n",
       "      <td>0.251267</td>\n",
       "      <td>0.172916</td>\n",
       "      <td>0.014266</td>\n",
       "      <td>0.078640</td>\n",
       "      <td>0.140389</td>\n",
       "      <td>0.303390</td>\n",
       "      <td>0.266330</td>\n",
       "      <td>0.207057</td>\n",
       "      <td>0.459891</td>\n",
       "      <td>0.267908</td>\n",
       "      <td>0.246793</td>\n",
       "      <td>0.504529</td>\n",
       "      <td>0.093094</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.263145</td>\n",
       "      <td>0.316108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Selenium_mcg</th>\n",
       "      <td>0.057343</td>\n",
       "      <td>0.371473</td>\n",
       "      <td>0.038201</td>\n",
       "      <td>-0.110976</td>\n",
       "      <td>-0.119580</td>\n",
       "      <td>-0.032126</td>\n",
       "      <td>0.046243</td>\n",
       "      <td>0.108312</td>\n",
       "      <td>0.216055</td>\n",
       "      <td>-0.034133</td>\n",
       "      <td>0.017788</td>\n",
       "      <td>0.035520</td>\n",
       "      <td>0.174490</td>\n",
       "      <td>0.137348</td>\n",
       "      <td>0.054380</td>\n",
       "      <td>0.017584</td>\n",
       "      <td>0.130196</td>\n",
       "      <td>0.058624</td>\n",
       "      <td>0.128531</td>\n",
       "      <td>0.022682</td>\n",
       "      <td>0.263145</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.203809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zinc_mg</th>\n",
       "      <td>0.111197</td>\n",
       "      <td>0.412753</td>\n",
       "      <td>0.026614</td>\n",
       "      <td>-0.009538</td>\n",
       "      <td>-0.022806</td>\n",
       "      <td>0.086569</td>\n",
       "      <td>0.059143</td>\n",
       "      <td>0.437833</td>\n",
       "      <td>0.298563</td>\n",
       "      <td>0.016846</td>\n",
       "      <td>0.158849</td>\n",
       "      <td>0.312040</td>\n",
       "      <td>0.463304</td>\n",
       "      <td>0.359455</td>\n",
       "      <td>0.244424</td>\n",
       "      <td>0.155498</td>\n",
       "      <td>0.266263</td>\n",
       "      <td>0.372145</td>\n",
       "      <td>0.254293</td>\n",
       "      <td>0.065860</td>\n",
       "      <td>0.316108</td>\n",
       "      <td>0.203809</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Energy_kcal  Protein_g     Fat_g    Carb_g   Sugar_g   Fiber_g  \\\n",
       "Energy_kcal    1.000000     0.113075   0.810032  0.480454  0.309132  0.196089   \n",
       "Protein_g      0.113075     1.000000   0.054437 -0.296643 -0.264515 -0.070076   \n",
       "Fat_g          0.810032     0.054437   1.000000 -0.056866 -0.005833 -0.027884   \n",
       "Carb_g         0.480454    -0.296643  -0.056866  1.000000  0.617633  0.458705   \n",
       "Sugar_g        0.309132    -0.264515  -0.005833  0.617633  1.000000  0.114439   \n",
       "Fiber_g        0.196089    -0.070076  -0.027884  0.458705  0.114439  1.000000   \n",
       "VitA_mcg       0.028998     0.021516   0.026382  0.006041  0.013232  0.009382   \n",
       "VitB6_mg       0.120040     0.225822  -0.049827  0.201565  0.088212  0.247103   \n",
       "VitB12_mcg    -0.011519     0.249643  -0.022493 -0.092368 -0.050334 -0.050372   \n",
       "VitC_mg       -0.034207    -0.066024  -0.060452  0.077416  0.062534  0.081917   \n",
       "VitE_mg        0.305811    -0.031358   0.341167  0.068188  0.061310  0.160121   \n",
       "Folate_mcg     0.141852     0.006607  -0.059215  0.325015  0.160402  0.246715   \n",
       "Niacin_mg      0.173559     0.373454  -0.025974  0.180896  0.034759  0.140053   \n",
       "Riboflavin_mg  0.154671     0.202333  -0.039332  0.238894  0.127273  0.163199   \n",
       "Thiamin_mg     0.184114     0.097013  -0.007518  0.283086  0.097777  0.205182   \n",
       "Calcium_mg     0.148047     0.067324   0.021942  0.213814  0.145591  0.272461   \n",
       "Copper_mcg     0.109043     0.164022   0.047853  0.072177 -0.003302  0.204587   \n",
       "Iron_mg        0.197628     0.118426  -0.041231  0.363276  0.121174  0.398290   \n",
       "Magnesium_mg   0.253930     0.217711   0.071006  0.288108  0.039454  0.544178   \n",
       "Manganese_mg   0.037101     0.040836  -0.000766  0.055297  0.010921  0.101604   \n",
       "Phosphorus_mg  0.237934     0.530065   0.083566  0.086996 -0.056850  0.193317   \n",
       "Selenium_mcg   0.057343     0.371473   0.038201 -0.110976 -0.119580 -0.032126   \n",
       "Zinc_mg        0.111197     0.412753   0.026614 -0.009538 -0.022806  0.086569   \n",
       "\n",
       "               VitA_mcg  VitB6_mg  VitB12_mcg   VitC_mg   VitE_mg  Folate_mcg  \\\n",
       "Energy_kcal    0.028998  0.120040 -0.011519   -0.034207  0.305811  0.141852     \n",
       "Protein_g      0.021516  0.225822  0.249643   -0.066024 -0.031358  0.006607     \n",
       "Fat_g          0.026382 -0.049827 -0.022493   -0.060452  0.341167 -0.059215     \n",
       "Carb_g         0.006041  0.201565 -0.092368    0.077416  0.068188  0.325015     \n",
       "Sugar_g        0.013232  0.088212 -0.050334    0.062534  0.061310  0.160402     \n",
       "Fiber_g        0.009382  0.247103 -0.050372    0.081917  0.160121  0.246715     \n",
       "VitA_mcg       1.000000  0.138238  0.542905    0.119372  0.047343  0.108445     \n",
       "VitB6_mg       0.138238  1.000000  0.265888    0.270805  0.270281  0.541268     \n",
       "VitB12_mcg     0.542905  0.265888  1.000000    0.005161  0.058371  0.155546     \n",
       "VitC_mg        0.119372  0.270805  0.005161    1.000000  0.061078  0.067004     \n",
       "VitE_mg        0.047343  0.270281  0.058371    0.061078  1.000000  0.166658     \n",
       "Folate_mcg     0.108445  0.541268  0.155546    0.067004  0.166658  1.000000     \n",
       "Niacin_mg      0.151750  0.705492  0.275586    0.208848  0.179741  0.528162     \n",
       "Riboflavin_mg  0.312731  0.578992  0.418739    0.227796  0.148242  0.570303     \n",
       "Thiamin_mg     0.056042  0.410394  0.102293    0.055077  0.111069  0.536935     \n",
       "Calcium_mg     0.045554  0.187758  0.010437    0.125651  0.106907  0.151721     \n",
       "Copper_mcg     0.505419  0.117541  0.516809    0.028818  0.083432  0.121219     \n",
       "Iron_mg        0.107529  0.485856  0.179947    0.074624  0.153681  0.478794     \n",
       "Magnesium_mg   0.027599  0.285059  0.001800    0.112664  0.187797  0.229714     \n",
       "Manganese_mg   0.395174  0.068001  0.260083    0.017967  0.104365  0.058408     \n",
       "Phosphorus_mg  0.061753  0.251267  0.172916    0.014266  0.078640  0.140389     \n",
       "Selenium_mcg   0.046243  0.108312  0.216055   -0.034133  0.017788  0.035520     \n",
       "Zinc_mg        0.059143  0.437833  0.298563    0.016846  0.158849  0.312040     \n",
       "\n",
       "               Niacin_mg  Riboflavin_mg  Thiamin_mg  Calcium_mg  Copper_mcg  \\\n",
       "Energy_kcal    0.173559   0.154671       0.184114    0.148047    0.109043     \n",
       "Protein_g      0.373454   0.202333       0.097013    0.067324    0.164022     \n",
       "Fat_g         -0.025974  -0.039332      -0.007518    0.021942    0.047853     \n",
       "Carb_g         0.180896   0.238894       0.283086    0.213814    0.072177     \n",
       "Sugar_g        0.034759   0.127273       0.097777    0.145591   -0.003302     \n",
       "Fiber_g        0.140053   0.163199       0.205182    0.272461    0.204587     \n",
       "VitA_mcg       0.151750   0.312731       0.056042    0.045554    0.505419     \n",
       "VitB6_mg       0.705492   0.578992       0.410394    0.187758    0.117541     \n",
       "VitB12_mcg     0.275586   0.418739       0.102293    0.010437    0.516809     \n",
       "VitC_mg        0.208848   0.227796       0.055077    0.125651    0.028818     \n",
       "VitE_mg        0.179741   0.148242       0.111069    0.106907    0.083432     \n",
       "Folate_mcg     0.528162   0.570303       0.536935    0.151721    0.121219     \n",
       "Niacin_mg      1.000000   0.751114       0.603888    0.139776    0.138413     \n",
       "Riboflavin_mg  0.751114   1.000000       0.636720    0.252828    0.280912     \n",
       "Thiamin_mg     0.603888   0.636720       1.000000    0.149175    0.108564     \n",
       "Calcium_mg     0.139776   0.252828       0.149175    1.000000    0.111385     \n",
       "Copper_mcg     0.138413   0.280912       0.108564    0.111385    1.000000     \n",
       "Iron_mg        0.503876   0.514546       0.409417    0.388803    0.192758     \n",
       "Magnesium_mg   0.266029   0.227744       0.239739    0.356572    0.372453     \n",
       "Manganese_mg   0.102378   0.108861       0.048104    0.083428    0.183798     \n",
       "Phosphorus_mg  0.303390   0.266330       0.207057    0.459891    0.267908     \n",
       "Selenium_mcg   0.174490   0.137348       0.054380    0.017584    0.130196     \n",
       "Zinc_mg        0.463304   0.359455       0.244424    0.155498    0.266263     \n",
       "\n",
       "                Iron_mg  Magnesium_mg  Manganese_mg  Phosphorus_mg  \\\n",
       "Energy_kcal    0.197628  0.253930      0.037101      0.237934        \n",
       "Protein_g      0.118426  0.217711      0.040836      0.530065        \n",
       "Fat_g         -0.041231  0.071006     -0.000766      0.083566        \n",
       "Carb_g         0.363276  0.288108      0.055297      0.086996        \n",
       "Sugar_g        0.121174  0.039454      0.010921     -0.056850        \n",
       "Fiber_g        0.398290  0.544178      0.101604      0.193317        \n",
       "VitA_mcg       0.107529  0.027599      0.395174      0.061753        \n",
       "VitB6_mg       0.485856  0.285059      0.068001      0.251267        \n",
       "VitB12_mcg     0.179947  0.001800      0.260083      0.172916        \n",
       "VitC_mg        0.074624  0.112664      0.017967      0.014266        \n",
       "VitE_mg        0.153681  0.187797      0.104365      0.078640        \n",
       "Folate_mcg     0.478794  0.229714      0.058408      0.140389        \n",
       "Niacin_mg      0.503876  0.266029      0.102378      0.303390        \n",
       "Riboflavin_mg  0.514546  0.227744      0.108861      0.266330        \n",
       "Thiamin_mg     0.409417  0.239739      0.048104      0.207057        \n",
       "Calcium_mg     0.388803  0.356572      0.083428      0.459891        \n",
       "Copper_mcg     0.192758  0.372453      0.183798      0.267908        \n",
       "Iron_mg        1.000000  0.409505      0.094919      0.246793        \n",
       "Magnesium_mg   0.409505  1.000000      0.179271      0.504529        \n",
       "Manganese_mg   0.094919  0.179271      1.000000      0.093094        \n",
       "Phosphorus_mg  0.246793  0.504529      0.093094      1.000000        \n",
       "Selenium_mcg   0.058624  0.128531      0.022682      0.263145        \n",
       "Zinc_mg        0.372145  0.254293      0.065860      0.316108        \n",
       "\n",
       "               Selenium_mcg   Zinc_mg  \n",
       "Energy_kcal    0.057343      0.111197  \n",
       "Protein_g      0.371473      0.412753  \n",
       "Fat_g          0.038201      0.026614  \n",
       "Carb_g        -0.110976     -0.009538  \n",
       "Sugar_g       -0.119580     -0.022806  \n",
       "Fiber_g       -0.032126      0.086569  \n",
       "VitA_mcg       0.046243      0.059143  \n",
       "VitB6_mg       0.108312      0.437833  \n",
       "VitB12_mcg     0.216055      0.298563  \n",
       "VitC_mg       -0.034133      0.016846  \n",
       "VitE_mg        0.017788      0.158849  \n",
       "Folate_mcg     0.035520      0.312040  \n",
       "Niacin_mg      0.174490      0.463304  \n",
       "Riboflavin_mg  0.137348      0.359455  \n",
       "Thiamin_mg     0.054380      0.244424  \n",
       "Calcium_mg     0.017584      0.155498  \n",
       "Copper_mcg     0.130196      0.266263  \n",
       "Iron_mg        0.058624      0.372145  \n",
       "Magnesium_mg   0.128531      0.254293  \n",
       "Manganese_mg   0.022682      0.065860  \n",
       "Phosphorus_mg  0.263145      0.316108  \n",
       "Selenium_mcg   1.000000      0.203809  \n",
       "Zinc_mg        0.203809      1.000000  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_data_exp.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein_g</th>\n",
       "      <th>Fat_g</th>\n",
       "      <th>Carb_g</th>\n",
       "      <th>Sugar_g</th>\n",
       "      <th>Fiber_g</th>\n",
       "      <th>VitA_mcg</th>\n",
       "      <th>VitB6_mg</th>\n",
       "      <th>VitB12_mcg</th>\n",
       "      <th>VitC_mg</th>\n",
       "      <th>VitE_mg</th>\n",
       "      <th>Folate_mcg</th>\n",
       "      <th>Niacin_mg</th>\n",
       "      <th>Riboflavin_mg</th>\n",
       "      <th>Thiamin_mg</th>\n",
       "      <th>Calcium_mg</th>\n",
       "      <th>Copper_mcg</th>\n",
       "      <th>Iron_mg</th>\n",
       "      <th>Magnesium_mg</th>\n",
       "      <th>Manganese_mg</th>\n",
       "      <th>Phosphorus_mg</th>\n",
       "      <th>Selenium_mcg</th>\n",
       "      <th>Zinc_mg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009624</td>\n",
       "      <td>0.8111</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.001719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015529</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.005540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.002561</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003494</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.000990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009624</td>\n",
       "      <td>0.8111</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015529</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.005540</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>0.002561</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.003348</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.000550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003170</td>\n",
       "      <td>0.9948</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.242301</td>\n",
       "      <td>0.2874</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.005010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.013833</td>\n",
       "      <td>0.012337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.006121</td>\n",
       "      <td>0.007969</td>\n",
       "      <td>0.021829</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>0.121884</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.002508</td>\n",
       "      <td>0.029449</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.056340</td>\n",
       "      <td>0.007564</td>\n",
       "      <td>0.029247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.263134</td>\n",
       "      <td>0.2968</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>0.005110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009733</td>\n",
       "      <td>0.005417</td>\n",
       "      <td>0.012741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>0.020057</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.155586</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>0.030730</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.065657</td>\n",
       "      <td>0.007564</td>\n",
       "      <td>0.028587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.234941</td>\n",
       "      <td>0.2768</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.004509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.019583</td>\n",
       "      <td>0.016685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.011053</td>\n",
       "      <td>0.002980</td>\n",
       "      <td>0.029714</td>\n",
       "      <td>0.002995</td>\n",
       "      <td>0.042475</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.004045</td>\n",
       "      <td>0.025608</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.027369</td>\n",
       "      <td>0.007564</td>\n",
       "      <td>0.026168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.224185</td>\n",
       "      <td>0.2426</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.004609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008033</td>\n",
       "      <td>0.018917</td>\n",
       "      <td>0.013146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.010542</td>\n",
       "      <td>0.004941</td>\n",
       "      <td>0.027886</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.089566</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>0.002670</td>\n",
       "      <td>0.025608</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.050517</td>\n",
       "      <td>0.007564</td>\n",
       "      <td>0.026168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.285100</td>\n",
       "      <td>0.2920</td>\n",
       "      <td>0.0306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009033</td>\n",
       "      <td>0.006167</td>\n",
       "      <td>0.002730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003061</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>0.025714</td>\n",
       "      <td>0.001326</td>\n",
       "      <td>0.155355</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.005178</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.071335</td>\n",
       "      <td>0.007564</td>\n",
       "      <td>0.032325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.272192</td>\n",
       "      <td>0.3382</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>0.002806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008767</td>\n",
       "      <td>0.004083</td>\n",
       "      <td>0.008899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005221</td>\n",
       "      <td>0.004421</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.155817</td>\n",
       "      <td>0.003721</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>0.034571</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.068860</td>\n",
       "      <td>0.014763</td>\n",
       "      <td>0.037713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.264606</td>\n",
       "      <td>0.3060</td>\n",
       "      <td>0.0478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>0.006167</td>\n",
       "      <td>0.008393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003061</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.016743</td>\n",
       "      <td>0.001968</td>\n",
       "      <td>0.148430</td>\n",
       "      <td>0.002791</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.026889</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.067550</td>\n",
       "      <td>0.007564</td>\n",
       "      <td>0.030676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.269022</td>\n",
       "      <td>0.3211</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.005210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.008393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>0.003061</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.158126</td>\n",
       "      <td>0.002791</td>\n",
       "      <td>0.006149</td>\n",
       "      <td>0.033291</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.066531</td>\n",
       "      <td>0.007564</td>\n",
       "      <td>0.033755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.125906</td>\n",
       "      <td>0.0430</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.026754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>0.003833</td>\n",
       "      <td>0.004348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.009314</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.019160</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.010243</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.023147</td>\n",
       "      <td>0.005060</td>\n",
       "      <td>0.004398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.121037</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.0461</td>\n",
       "      <td>0.023848</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>0.005667</td>\n",
       "      <td>0.005359</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.001870</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.008114</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>0.012235</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>0.008963</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.016451</td>\n",
       "      <td>0.004017</td>\n",
       "      <td>0.003628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.117074</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.018537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.004652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.012914</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.019852</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>0.001214</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.027661</td>\n",
       "      <td>0.004903</td>\n",
       "      <td>0.005168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.118320</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>0.040080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>0.004750</td>\n",
       "      <td>0.004753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.014343</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.025623</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>0.011524</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.021837</td>\n",
       "      <td>0.006208</td>\n",
       "      <td>0.005607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.140285</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.027255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.005667</td>\n",
       "      <td>0.006371</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.009429</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.014081</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.006402</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.019508</td>\n",
       "      <td>0.004695</td>\n",
       "      <td>0.004178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.067142</td>\n",
       "      <td>0.3424</td>\n",
       "      <td>0.0407</td>\n",
       "      <td>0.032164</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>0.002528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>0.001870</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.022622</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.003074</td>\n",
       "      <td>0.011524</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.015432</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.005607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.282948</td>\n",
       "      <td>0.2780</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.014329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.006333</td>\n",
       "      <td>0.015573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>0.022229</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>0.168744</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.003560</td>\n",
       "      <td>0.038412</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.078032</td>\n",
       "      <td>0.007564</td>\n",
       "      <td>0.041231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.160892</td>\n",
       "      <td>0.2128</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>0.040982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.035333</td>\n",
       "      <td>0.017090</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.005441</td>\n",
       "      <td>0.007773</td>\n",
       "      <td>0.048229</td>\n",
       "      <td>0.006588</td>\n",
       "      <td>0.113804</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>0.005259</td>\n",
       "      <td>0.024328</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.049061</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.031666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.289855</td>\n",
       "      <td>0.3114</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.015531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>0.006917</td>\n",
       "      <td>0.016989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001807</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.011657</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.126962</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>0.001861</td>\n",
       "      <td>0.017926</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.050371</td>\n",
       "      <td>0.007564</td>\n",
       "      <td>0.038483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.109262</td>\n",
       "      <td>0.2951</td>\n",
       "      <td>0.4265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011133</td>\n",
       "      <td>0.022583</td>\n",
       "      <td>0.024472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>0.006376</td>\n",
       "      <td>0.078971</td>\n",
       "      <td>0.013476</td>\n",
       "      <td>0.092336</td>\n",
       "      <td>0.005316</td>\n",
       "      <td>0.004207</td>\n",
       "      <td>0.089629</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.064638</td>\n",
       "      <td>0.007564</td>\n",
       "      <td>0.012534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.282382</td>\n",
       "      <td>0.2744</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.022244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.015573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.019086</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.161588</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.037132</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.079488</td>\n",
       "      <td>0.007564</td>\n",
       "      <td>0.042881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.337523</td>\n",
       "      <td>0.3234</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.003607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009033</td>\n",
       "      <td>0.006750</td>\n",
       "      <td>0.016180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>0.015943</td>\n",
       "      <td>0.002567</td>\n",
       "      <td>0.233380</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>0.046095</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.088077</td>\n",
       "      <td>0.007564</td>\n",
       "      <td>0.042881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.227015</td>\n",
       "      <td>0.2725</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.004910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011333</td>\n",
       "      <td>0.007167</td>\n",
       "      <td>0.010517</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.009862</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>0.028743</td>\n",
       "      <td>0.003422</td>\n",
       "      <td>0.114728</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>0.026889</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.057214</td>\n",
       "      <td>0.007564</td>\n",
       "      <td>0.023090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.277174</td>\n",
       "      <td>0.3028</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.005010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.008393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>0.003061</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.022286</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.172207</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>0.005825</td>\n",
       "      <td>0.034571</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.064638</td>\n",
       "      <td>0.007564</td>\n",
       "      <td>0.032985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.251019</td>\n",
       "      <td>0.2235</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.010321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005967</td>\n",
       "      <td>0.003083</td>\n",
       "      <td>0.023056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.016171</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.116574</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.003560</td>\n",
       "      <td>0.025608</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.051536</td>\n",
       "      <td>0.008868</td>\n",
       "      <td>0.032106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.244565</td>\n",
       "      <td>0.2464</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>0.010120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006567</td>\n",
       "      <td>0.005167</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.015429</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.132733</td>\n",
       "      <td>0.001462</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>0.026889</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.059980</td>\n",
       "      <td>0.008399</td>\n",
       "      <td>0.027048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.274683</td>\n",
       "      <td>0.1592</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.011323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>0.005833</td>\n",
       "      <td>0.008292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.017314</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>0.180517</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>0.029449</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.067404</td>\n",
       "      <td>0.007512</td>\n",
       "      <td>0.030346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.278306</td>\n",
       "      <td>0.1972</td>\n",
       "      <td>0.0636</td>\n",
       "      <td>0.022445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008467</td>\n",
       "      <td>0.009250</td>\n",
       "      <td>0.018404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>0.004591</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.019886</td>\n",
       "      <td>0.002524</td>\n",
       "      <td>0.165282</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>0.001861</td>\n",
       "      <td>0.037132</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.078177</td>\n",
       "      <td>0.013980</td>\n",
       "      <td>0.039692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.265059</td>\n",
       "      <td>0.3004</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.011222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009933</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>0.014865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.018286</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.165512</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>0.003317</td>\n",
       "      <td>0.034571</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.068132</td>\n",
       "      <td>0.007564</td>\n",
       "      <td>0.030896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8148</th>\n",
       "      <td>0.074728</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.8860</td>\n",
       "      <td>0.013527</td>\n",
       "      <td>0.032911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>0.197961</td>\n",
       "      <td>0.107429</td>\n",
       "      <td>0.068449</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.025050</td>\n",
       "      <td>0.072816</td>\n",
       "      <td>0.047375</td>\n",
       "      <td>0.003957</td>\n",
       "      <td>0.036832</td>\n",
       "      <td>0.008503</td>\n",
       "      <td>0.036284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8149</th>\n",
       "      <td>0.011322</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.2134</td>\n",
       "      <td>0.113828</td>\n",
       "      <td>0.020253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009125</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.002891</td>\n",
       "      <td>0.004235</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.033291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002912</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.000550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8150</th>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.146894</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005125</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.010243</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8151</th>\n",
       "      <td>0.098505</td>\n",
       "      <td>0.1520</td>\n",
       "      <td>0.7340</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>0.072152</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.023628</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>0.003294</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.009412</td>\n",
       "      <td>0.036704</td>\n",
       "      <td>0.007708</td>\n",
       "      <td>0.013188</td>\n",
       "      <td>0.124200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046295</td>\n",
       "      <td>0.008190</td>\n",
       "      <td>0.012644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8152</th>\n",
       "      <td>0.080616</td>\n",
       "      <td>0.0546</td>\n",
       "      <td>0.8119</td>\n",
       "      <td>0.198297</td>\n",
       "      <td>0.053165</td>\n",
       "      <td>0.026867</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.097785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008166</td>\n",
       "      <td>0.190444</td>\n",
       "      <td>0.139608</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.055615</td>\n",
       "      <td>0.005309</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.281715</td>\n",
       "      <td>0.058899</td>\n",
       "      <td>0.003896</td>\n",
       "      <td>0.021692</td>\n",
       "      <td>0.003808</td>\n",
       "      <td>0.055305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8153</th>\n",
       "      <td>0.142663</td>\n",
       "      <td>0.0950</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>0.005411</td>\n",
       "      <td>0.179747</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.014167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033534</td>\n",
       "      <td>0.002891</td>\n",
       "      <td>0.016235</td>\n",
       "      <td>0.006286</td>\n",
       "      <td>0.014973</td>\n",
       "      <td>0.002539</td>\n",
       "      <td>0.036213</td>\n",
       "      <td>0.018447</td>\n",
       "      <td>0.193342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038434</td>\n",
       "      <td>0.004486</td>\n",
       "      <td>0.042111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8154</th>\n",
       "      <td>0.005661</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.1718</td>\n",
       "      <td>0.148998</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.005833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005292</td>\n",
       "      <td>0.005288</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.002196</td>\n",
       "      <td>0.002286</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.001385</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>0.008963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8155</th>\n",
       "      <td>0.321558</td>\n",
       "      <td>0.0510</td>\n",
       "      <td>0.0340</td>\n",
       "      <td>0.013327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.016989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.020571</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.221837</td>\n",
       "      <td>0.001794</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>0.046095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088077</td>\n",
       "      <td>0.006625</td>\n",
       "      <td>0.042881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8156</th>\n",
       "      <td>0.049819</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.7290</td>\n",
       "      <td>0.351703</td>\n",
       "      <td>0.026582</td>\n",
       "      <td>0.020267</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005087</td>\n",
       "      <td>0.029587</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>0.062857</td>\n",
       "      <td>0.042781</td>\n",
       "      <td>0.009464</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.039320</td>\n",
       "      <td>0.034571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014995</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.045080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8157</th>\n",
       "      <td>0.311368</td>\n",
       "      <td>0.1710</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.012325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004567</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.009303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.019429</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.168744</td>\n",
       "      <td>0.001794</td>\n",
       "      <td>0.002023</td>\n",
       "      <td>0.033291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076285</td>\n",
       "      <td>0.008190</td>\n",
       "      <td>0.034415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8158</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7780</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.003006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.001616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001861</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003640</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.001429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8159</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8160</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7610</td>\n",
       "      <td>0.761523</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.002458</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8161</th>\n",
       "      <td>0.046196</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.1618</td>\n",
       "      <td>0.082265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>0.007180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014391</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.005143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149815</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>0.005502</td>\n",
       "      <td>0.012804</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.086767</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.002309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8162</th>\n",
       "      <td>0.127944</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.6370</td>\n",
       "      <td>0.359719</td>\n",
       "      <td>0.351899</td>\n",
       "      <td>0.003267</td>\n",
       "      <td>0.038333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036042</td>\n",
       "      <td>0.037149</td>\n",
       "      <td>0.018194</td>\n",
       "      <td>0.036392</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.018824</td>\n",
       "      <td>0.135503</td>\n",
       "      <td>0.037940</td>\n",
       "      <td>0.063350</td>\n",
       "      <td>0.250960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058524</td>\n",
       "      <td>0.007981</td>\n",
       "      <td>0.030456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8163</th>\n",
       "      <td>0.060009</td>\n",
       "      <td>0.0240</td>\n",
       "      <td>0.7820</td>\n",
       "      <td>0.007014</td>\n",
       "      <td>0.077215</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.003137</td>\n",
       "      <td>0.005143</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.029086</td>\n",
       "      <td>0.055681</td>\n",
       "      <td>0.025162</td>\n",
       "      <td>0.113956</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.241665</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.004508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8164</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.012804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8165</th>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.4610</td>\n",
       "      <td>0.453908</td>\n",
       "      <td>0.010127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.001528</td>\n",
       "      <td>0.001456</td>\n",
       "      <td>0.007682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.000330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8166</th>\n",
       "      <td>0.004642</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.4438</td>\n",
       "      <td>0.378257</td>\n",
       "      <td>0.032911</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.006233</td>\n",
       "      <td>0.007442</td>\n",
       "      <td>0.006472</td>\n",
       "      <td>0.012804</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8167</th>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.7160</td>\n",
       "      <td>0.245792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001750</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8168</th>\n",
       "      <td>0.114130</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.7442</td>\n",
       "      <td>0.007014</td>\n",
       "      <td>0.127848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004275</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.001070</td>\n",
       "      <td>0.011542</td>\n",
       "      <td>0.056744</td>\n",
       "      <td>0.031311</td>\n",
       "      <td>0.140845</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.025331</td>\n",
       "      <td>0.002660</td>\n",
       "      <td>0.016383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8169</th>\n",
       "      <td>0.018116</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>0.029058</td>\n",
       "      <td>0.011392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011311</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.021767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.002089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8170</th>\n",
       "      <td>0.009171</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.8466</td>\n",
       "      <td>0.009018</td>\n",
       "      <td>0.010127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.033010</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.003074</td>\n",
       "      <td>0.006402</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.344737</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8171</th>\n",
       "      <td>0.850996</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032779</td>\n",
       "      <td>0.012093</td>\n",
       "      <td>0.042071</td>\n",
       "      <td>0.032010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037851</td>\n",
       "      <td>0.020709</td>\n",
       "      <td>0.009346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8172</th>\n",
       "      <td>0.185688</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.004045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006693</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>0.009412</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.005989</td>\n",
       "      <td>0.004155</td>\n",
       "      <td>0.016611</td>\n",
       "      <td>0.012136</td>\n",
       "      <td>0.025608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.007355</td>\n",
       "      <td>0.010995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8173</th>\n",
       "      <td>0.209466</td>\n",
       "      <td>0.2510</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001567</td>\n",
       "      <td>0.034167</td>\n",
       "      <td>0.121347</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015930</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>0.025882</td>\n",
       "      <td>0.010857</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.015235</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.011327</td>\n",
       "      <td>0.076825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036978</td>\n",
       "      <td>0.038289</td>\n",
       "      <td>0.012095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8174</th>\n",
       "      <td>0.232563</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0541</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.009333</td>\n",
       "      <td>0.021741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.004693</td>\n",
       "      <td>0.047375</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.062018</td>\n",
       "      <td>0.011320</td>\n",
       "      <td>0.017042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8175</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7314</td>\n",
       "      <td>0.733467</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.005561</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>0.029126</td>\n",
       "      <td>0.012804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.002089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8176</th>\n",
       "      <td>0.182292</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.010833</td>\n",
       "      <td>0.005056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033467</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.010980</td>\n",
       "      <td>0.006857</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>0.026578</td>\n",
       "      <td>0.028317</td>\n",
       "      <td>0.320102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039598</td>\n",
       "      <td>0.014293</td>\n",
       "      <td>0.010995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8177</th>\n",
       "      <td>0.224185</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003347</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>0.008627</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.005134</td>\n",
       "      <td>0.027239</td>\n",
       "      <td>0.016611</td>\n",
       "      <td>0.011327</td>\n",
       "      <td>0.025608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026205</td>\n",
       "      <td>0.008764</td>\n",
       "      <td>0.010995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8178 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Protein_g   Fat_g  Carb_g   Sugar_g   Fiber_g  VitA_mcg  VitB6_mg  \\\n",
       "0     0.009624   0.8111  0.0006  0.000601  0.000000  0.022800  0.000250   \n",
       "1     0.009624   0.8111  0.0006  0.000601  0.000000  0.022800  0.000250   \n",
       "2     0.003170   0.9948  0.0000  0.000000  0.000000  0.028000  0.000083   \n",
       "3     0.242301   0.2874  0.0234  0.005010  0.000000  0.006600  0.013833   \n",
       "4     0.263134   0.2968  0.0279  0.005110  0.000000  0.009733  0.005417   \n",
       "5     0.234941   0.2768  0.0045  0.004509  0.000000  0.005800  0.019583   \n",
       "6     0.224185   0.2426  0.0046  0.004609  0.000000  0.008033  0.018917   \n",
       "7     0.285100   0.2920  0.0306  0.000000  0.000000  0.009033  0.006167   \n",
       "8     0.272192   0.3382  0.0133  0.002806  0.000000  0.008767  0.004083   \n",
       "9     0.264606   0.3060  0.0478  0.000000  0.000000  0.007767  0.006167   \n",
       "10    0.269022   0.3211  0.0257  0.005210  0.000000  0.008800  0.006583   \n",
       "11    0.125906   0.0430  0.0338  0.026754  0.000000  0.001233  0.003833   \n",
       "12    0.121037   0.0385  0.0461  0.023848  0.002532  0.001267  0.005667   \n",
       "13    0.117074   0.0029  0.0666  0.018537  0.000000  0.000067  0.001333   \n",
       "14    0.118320   0.0227  0.0476  0.040080  0.000000  0.002267  0.004750   \n",
       "15    0.140285   0.0102  0.0272  0.027255  0.000000  0.000367  0.005667   \n",
       "16    0.067142   0.3424  0.0407  0.032164  0.000000  0.012200  0.002917   \n",
       "17    0.282948   0.2780  0.0143  0.014329  0.000000  0.008100  0.006333   \n",
       "18    0.160892   0.2128  0.0409  0.040982  0.000000  0.004167  0.035333   \n",
       "19    0.289855   0.3114  0.0155  0.015531  0.000000  0.008700  0.006917   \n",
       "20    0.109262   0.2951  0.4265  0.000000  0.000000  0.011133  0.022583   \n",
       "21    0.282382   0.2744  0.0222  0.022244  0.000000  0.005500  0.006667   \n",
       "22    0.337523   0.3234  0.0036  0.003607  0.000000  0.009033  0.006750   \n",
       "23    0.227015   0.2725  0.0049  0.004910  0.000000  0.011333  0.007167   \n",
       "24    0.277174   0.3028  0.0068  0.005010  0.000000  0.006600  0.006583   \n",
       "25    0.251019   0.2235  0.0219  0.010321  0.000000  0.005967  0.003083   \n",
       "26    0.244565   0.2464  0.0247  0.010120  0.000000  0.006567  0.005167   \n",
       "27    0.274683   0.1592  0.0277  0.011323  0.000000  0.004233  0.005833   \n",
       "28    0.278306   0.1972  0.0636  0.022445  0.000000  0.008467  0.009250   \n",
       "29    0.265059   0.3004  0.0112  0.011222  0.000000  0.009933  0.004667   \n",
       "...        ...      ...     ...       ...       ...       ...       ...   \n",
       "8148  0.074728   0.0090  0.8860  0.013527  0.032911  0.000000  0.007500   \n",
       "8149  0.011322   0.0020  0.2134  0.113828  0.020253  0.000000  0.021667   \n",
       "8150  0.003397   0.0020  0.1630  0.146894  0.012658  0.000067  0.005000   \n",
       "8151  0.098505   0.1520  0.7340  0.005311  0.072152  0.000133  0.015000   \n",
       "8152  0.080616   0.0546  0.8119  0.198297  0.053165  0.026867  0.220000   \n",
       "8153  0.142663   0.0950  0.7339  0.005411  0.179747  0.000233  0.014167   \n",
       "8154  0.005661   0.0020  0.1718  0.148998  0.025316  0.000100  0.005833   \n",
       "8155  0.321558   0.0510  0.0340  0.013327  0.000000  0.001333  0.006667   \n",
       "8156  0.049819   0.0750  0.7290  0.351703  0.026582  0.020267  0.116667   \n",
       "8157  0.311368   0.1710  0.0310  0.012325  0.000000  0.004567  0.006667   \n",
       "8158  0.000000   0.7780  0.0030  0.003006  0.000000  0.000000  0.000833   \n",
       "8159  0.000000   1.0000  0.0000  0.000000  0.000000  0.000000  0.000000   \n",
       "8160  0.000000   0.0000  0.7610  0.761523  0.001266  0.000000  0.000000   \n",
       "8161  0.046196   0.1950  0.1618  0.082265  0.000000  0.001500  0.002250   \n",
       "8162  0.127944   0.0210  0.6370  0.359719  0.351899  0.003267  0.038333   \n",
       "8163  0.060009   0.0240  0.7820  0.007014  0.077215  0.000000  0.003333   \n",
       "8164  0.000000   0.0000  0.1538  0.000000  0.001266  0.000000  0.005000   \n",
       "8165  0.003397   0.0003  0.4610  0.453908  0.010127  0.000000  0.003333   \n",
       "8166  0.004642   0.0020  0.4438  0.378257  0.032911  0.000033  0.002417   \n",
       "8167  0.000906   0.0001  0.7160  0.245792  0.000000  0.000033  0.000417   \n",
       "8168  0.114130   0.0300  0.7442  0.007014  0.127848  0.000000  0.002250   \n",
       "8169  0.018116   0.0010  0.8604  0.029058  0.011392  0.000000  0.000000   \n",
       "8170  0.009171   0.0090  0.8466  0.009018  0.010127  0.000000  0.000417   \n",
       "8171  0.850996   0.0185  0.1379  0.000000  0.007595  0.000000  0.000000   \n",
       "8172  0.185688   0.0030  0.0000  0.000000  0.000000  0.000500  0.010000   \n",
       "8173  0.209466   0.2510  0.0000  0.000000  0.000000  0.001567  0.034167   \n",
       "8174  0.232563   0.0084  0.0541  0.000000  0.000000  0.000067  0.009333   \n",
       "8175  0.000000   0.0000  0.7314  0.733467  0.000000  0.000000  0.000000   \n",
       "8176  0.182292   0.0140  0.0200  0.000000  0.000000  0.001000  0.010833   \n",
       "8177  0.224185   0.0050  0.0000  0.000000  0.000000  0.001000  0.010000   \n",
       "\n",
       "      VitB12_mcg   VitC_mg   VitE_mg  Folate_mcg  Niacin_mg  Riboflavin_mg  \\\n",
       "0     0.001719    0.000000  0.015529  0.000510    0.000329   0.001943        \n",
       "1     0.001315    0.000000  0.015529  0.000510    0.000329   0.001943        \n",
       "2     0.000101    0.000000  0.018742  0.000000    0.000024   0.000286        \n",
       "3     0.012337    0.000000  0.001673  0.006121    0.007969   0.021829        \n",
       "4     0.012741    0.000000  0.001740  0.003401    0.000925   0.020057        \n",
       "5     0.016685    0.000000  0.001606  0.011053    0.002980   0.029714        \n",
       "6     0.013146    0.000000  0.001406  0.010542    0.004941   0.027886        \n",
       "7     0.002730    0.000000  0.000000  0.003061    0.001412   0.025714        \n",
       "8     0.008899    0.000000  0.005221  0.004421    0.000306   0.024800        \n",
       "9     0.008393    0.000000  0.000000  0.003061    0.000627   0.016743        \n",
       "10    0.008393    0.000000  0.001874  0.003061    0.000729   0.021429        \n",
       "11    0.004348    0.000000  0.000535  0.002040    0.000776   0.009314        \n",
       "12    0.005359    0.000583  0.000268  0.001870    0.001176   0.008114        \n",
       "13    0.004652    0.000000  0.000067  0.001530    0.001129   0.012914        \n",
       "14    0.004753    0.000000  0.000535  0.001360    0.000808   0.014343        \n",
       "15    0.006371    0.000000  0.000067  0.002040    0.001004   0.009429        \n",
       "16    0.002528    0.000000  0.001941  0.001870    0.001137   0.007143        \n",
       "17    0.015573    0.000000  0.001606  0.002721    0.000643   0.022229        \n",
       "18    0.017090    0.000000  0.001205  0.005441    0.007773   0.048229        \n",
       "19    0.016989    0.000000  0.001807  0.001020    0.001176   0.011657        \n",
       "20    0.024472    0.000000  0.000000  0.000850    0.006376   0.078971        \n",
       "21    0.015573    0.000000  0.001606  0.003571    0.000494   0.019086        \n",
       "22    0.016180    0.000000  0.001874  0.001700    0.000831   0.015943        \n",
       "23    0.010517    0.000000  0.001539  0.009862    0.001239   0.028743        \n",
       "24    0.008393    0.000000  0.001740  0.003061    0.000729   0.022286        \n",
       "25    0.023056    0.000000  0.001272  0.001190    0.000816   0.016171        \n",
       "26    0.007382    0.000000  0.001406  0.001360    0.000737   0.015429        \n",
       "27    0.008292    0.000000  0.000937  0.001530    0.000824   0.017314        \n",
       "28    0.018404    0.000000  0.002878  0.004591    0.001129   0.019886        \n",
       "29    0.014865    0.000000  0.001740  0.002040    0.000808   0.018286        \n",
       "...        ...         ...       ...       ...         ...        ...        \n",
       "8148  0.000000    0.104167  0.000870  0.000850    0.197961   0.107429        \n",
       "8149  0.000000    0.009125  0.001673  0.002891    0.004235   0.003429        \n",
       "8150  0.000000    0.005125  0.000134  0.000680    0.001020   0.001143        \n",
       "8151  0.000607    0.000083  0.023628  0.002721    0.003294   0.016000        \n",
       "8152  0.097785    0.000000  0.008166  0.190444    0.139608   0.071429        \n",
       "8153  0.000000    0.000000  0.033534  0.002891    0.016235   0.006286        \n",
       "8154  0.000000    0.005292  0.005288  0.001020    0.002196   0.002286        \n",
       "8155  0.016989    0.000000  0.000469  0.001020    0.000706   0.020571        \n",
       "8156  0.000000    0.000000  0.005087  0.029587    0.105882   0.062857        \n",
       "8157  0.009303    0.000000  0.001004  0.001530    0.000941   0.019429        \n",
       "8158  0.000000    0.000000  0.078916  0.000000    0.000078   0.003429        \n",
       "8159  0.000000    0.000000  0.098929  0.000000    0.000000   0.000000        \n",
       "8160  0.000000    0.000000  0.000000  0.000000    0.000000   0.001143        \n",
       "8161  0.007180    0.000000  0.014391  0.001360    0.000471   0.005143        \n",
       "8162  0.000000    0.036042  0.037149  0.018194    0.036392   0.028571        \n",
       "8163  0.000101    0.000000  0.000134  0.001020    0.003137   0.005143        \n",
       "8164  0.000000    0.014083  0.000000  0.000000    0.001569   0.001143        \n",
       "8165  0.000000    0.000000  0.000000  0.000170    0.001098   0.001143        \n",
       "8166  0.000000    0.000292  0.001539  0.000170    0.000714   0.001943        \n",
       "8167  0.000000    0.001750  0.000134  0.000850    0.000204   0.000971        \n",
       "8168  0.000000    0.000000  0.000134  0.000000    0.004275   0.006000        \n",
       "8169  0.000000    0.000000  0.000335  0.000000    0.000000   0.000000        \n",
       "8170  0.000506    0.000000  0.000535  0.000170    0.000110   0.001200        \n",
       "8171  0.000000    0.000000  0.000000  0.000000    0.000000   0.000000        \n",
       "8172  0.004045    0.000000  0.006693  0.002551    0.009412   0.014286        \n",
       "8173  0.121347    0.000000  0.015930  0.002551    0.025882   0.010857        \n",
       "8174  0.021741    0.000000  0.000000  0.003401    0.008439   0.001371        \n",
       "8175  0.000000    0.000000  0.000000  0.000000    0.000784   0.003429        \n",
       "8176  0.005056    0.000000  0.033467  0.001020    0.010980   0.006857        \n",
       "8177  0.010112    0.000000  0.003347  0.002551    0.008627   0.008571        \n",
       "\n",
       "      Thiamin_mg  Calcium_mg  Copper_mcg   Iron_mg  Magnesium_mg  \\\n",
       "0     0.000214    0.005540    0.000000    0.000162  0.002561       \n",
       "1     0.000214    0.005540    0.001063    0.001294  0.002561       \n",
       "2     0.000043    0.000923    0.000066    0.000000  0.000000       \n",
       "3     0.001241    0.121884    0.002658    0.002508  0.029449       \n",
       "4     0.000599    0.155586    0.001595    0.003479  0.030730       \n",
       "5     0.002995    0.042475    0.001262    0.004045  0.025608       \n",
       "6     0.001198    0.089566    0.001395    0.002670  0.025608       \n",
       "7     0.001326    0.155355    0.001595    0.005178  0.028169       \n",
       "8     0.001155    0.155817    0.003721    0.001294  0.034571       \n",
       "9     0.001968    0.148430    0.002791    0.001699  0.026889       \n",
       "10    0.000642    0.158126    0.002791    0.006149  0.033291       \n",
       "11    0.001155    0.019160    0.001927    0.000566  0.010243       \n",
       "12    0.001412    0.012235    0.002658    0.001294  0.008963       \n",
       "13    0.000984    0.019852    0.001993    0.001214  0.014085       \n",
       "14    0.000856    0.025623    0.002193    0.001052  0.011524       \n",
       "15    0.000898    0.014081    0.001860    0.001133  0.006402       \n",
       "16    0.000856    0.022622    0.001262    0.003074  0.011524       \n",
       "17    0.001583    0.168744    0.002392    0.003560  0.038412       \n",
       "18    0.006588    0.113804    0.002126    0.005259  0.024328       \n",
       "19    0.000898    0.126962    0.001661    0.001861  0.017926       \n",
       "20    0.013476    0.092336    0.005316    0.004207  0.089629       \n",
       "21    0.001283    0.161588    0.002392    0.001942  0.037132       \n",
       "22    0.002567    0.233380    0.002126    0.001375  0.046095       \n",
       "23    0.003422    0.114728    0.001395    0.001052  0.026889       \n",
       "24    0.000642    0.172207    0.002126    0.005825  0.034571       \n",
       "25    0.001283    0.116574    0.000731    0.003560  0.025608       \n",
       "26    0.000684    0.132733    0.001462    0.001618  0.026889       \n",
       "27    0.000770    0.180517    0.001661    0.001780  0.029449       \n",
       "28    0.002524    0.165282    0.002259    0.001861  0.037132       \n",
       "29    0.000556    0.165512    0.002060    0.003317  0.034571       \n",
       "...        ...         ...         ...         ...       ...       \n",
       "8148  0.068449    0.008772    0.025050    0.072816  0.047375       \n",
       "8149  0.000856    0.000923    0.002658    0.002427  0.033291       \n",
       "8150  0.000856    0.000693    0.001993    0.000809  0.010243       \n",
       "8151  0.009412    0.036704    0.007708    0.013188  0.124200       \n",
       "8152  0.055615    0.005309    0.013289    0.281715  0.058899       \n",
       "8153  0.014973    0.002539    0.036213    0.018447  0.193342       \n",
       "8154  0.000428    0.001385    0.002326    0.001375  0.008963       \n",
       "8155  0.000856    0.221837    0.001794    0.001375  0.046095       \n",
       "8156  0.042781    0.009464    0.006645    0.039320  0.034571       \n",
       "8157  0.000856    0.168744    0.001794    0.002023  0.033291       \n",
       "8158  0.000428    0.001616    0.000000    0.001861  0.001280       \n",
       "8159  0.000000    0.000000    0.000000    0.001052  0.000000       \n",
       "8160  0.000000    0.000231    0.002458    0.000890  0.000000       \n",
       "8161  0.000000    0.149815    0.001728    0.005502  0.012804       \n",
       "8162  0.018824    0.135503    0.037940    0.063350  0.250960       \n",
       "8163  0.000856    0.029086    0.055681    0.025162  0.113956       \n",
       "8164  0.000428    0.002770    0.001860    0.002427  0.012804       \n",
       "8165  0.000428    0.001154    0.001528    0.001456  0.007682       \n",
       "8166  0.000984    0.006233    0.007442    0.006472  0.012804       \n",
       "8167  0.000385    0.000462    0.001329    0.000324  0.001280       \n",
       "8168  0.001070    0.011542    0.056744    0.031311  0.140845       \n",
       "8169  0.000000    0.011311    0.002658    0.000405  0.021767       \n",
       "8170  0.000214    0.033010    0.002525    0.003074  0.006402       \n",
       "8171  0.000000    0.032779    0.012093    0.042071  0.032010       \n",
       "8172  0.005989    0.004155    0.016611    0.012136  0.025608       \n",
       "8173  0.000856    0.015235    0.006645    0.011327  0.076825       \n",
       "8174  0.000513    0.002308    0.002193    0.004693  0.047375       \n",
       "8175  0.005561    0.003001    0.001329    0.029126  0.012804       \n",
       "8176  0.000428    0.002308    0.026578    0.028317  0.320102       \n",
       "8177  0.005134    0.027239    0.016611    0.011327  0.025608       \n",
       "\n",
       "      Manganese_mg  Phosphorus_mg  Selenium_mcg   Zinc_mg  \n",
       "0     0.000000      0.003494       0.000522      0.000990  \n",
       "1     0.000012      0.003348       0.000522      0.000550  \n",
       "2     0.000000      0.000437       0.000000      0.000110  \n",
       "3     0.000027      0.056340       0.007564      0.029247  \n",
       "4     0.000037      0.065657       0.007564      0.028587  \n",
       "5     0.000104      0.027369       0.007564      0.026168  \n",
       "6     0.000116      0.050517       0.007564      0.026168  \n",
       "7     0.000064      0.071335       0.007564      0.032325  \n",
       "8     0.000101      0.068860       0.014763      0.037713  \n",
       "9     0.000037      0.067550       0.007564      0.030676  \n",
       "10    0.000037      0.066531       0.007564      0.033755  \n",
       "11    0.000006      0.023147       0.005060      0.004398  \n",
       "12    0.000009      0.016451       0.004017      0.003628  \n",
       "13    0.000067      0.027661       0.004903      0.005168  \n",
       "14    0.000046      0.021837       0.006208      0.005607  \n",
       "15    0.000009      0.019508       0.004695      0.004178  \n",
       "16    0.000034      0.015432       0.001252      0.005607  \n",
       "17    0.000034      0.078032       0.007564      0.041231  \n",
       "18    0.000085      0.049061       0.007825      0.031666  \n",
       "19    0.000043      0.050371       0.007564      0.038483  \n",
       "20    0.000122      0.064638       0.007564      0.012534  \n",
       "21    0.000034      0.079488       0.007564      0.042881  \n",
       "22    0.000052      0.088077       0.007564      0.042881  \n",
       "23    0.000116      0.057214       0.007564      0.023090  \n",
       "24    0.000034      0.064638       0.007564      0.032985  \n",
       "25    0.000091      0.051536       0.008868      0.032106  \n",
       "26    0.000027      0.059980       0.008399      0.027048  \n",
       "27    0.000030      0.067404       0.007512      0.030346  \n",
       "28    0.000125      0.078177       0.013980      0.039692  \n",
       "29    0.000024      0.068132       0.007564      0.030896  \n",
       "...        ...           ...            ...           ...  \n",
       "8148  0.003957      0.036832       0.008503      0.036284  \n",
       "8149  0.000000      0.002912       0.000574      0.000550  \n",
       "8150  0.000000      0.001310       0.000313      0.000550  \n",
       "8151  0.000000      0.046295       0.008190      0.012644  \n",
       "8152  0.003896      0.021692       0.003808      0.055305  \n",
       "8153  0.000000      0.038434       0.004486      0.042111  \n",
       "8154  0.000000      0.001310       0.000209      0.000880  \n",
       "8155  0.000000      0.088077       0.006625      0.042881  \n",
       "8156  0.000000      0.014995       0.007825      0.045080  \n",
       "8157  0.000000      0.076285       0.008190      0.034415  \n",
       "8158  0.000000      0.003640       0.000835      0.001429  \n",
       "8159  0.000000      0.000000       0.000000      0.000220  \n",
       "8160  0.000000      0.000000       0.000261      0.000990  \n",
       "8161  0.000079      0.086767       0.001513      0.002309  \n",
       "8162  0.000000      0.058524       0.007981      0.030456  \n",
       "8163  0.002143      0.241665       0.002034      0.004508  \n",
       "8164  0.000000      0.001601       0.000000      0.000550  \n",
       "8165  0.000000      0.000873       0.000730      0.000330  \n",
       "8166  0.000655      0.001747       0.000209      0.001100  \n",
       "8167  0.000137      0.000291       0.000261      0.000220  \n",
       "8168  0.002704      0.025331       0.002660      0.016383  \n",
       "8169  0.000000      0.001747       0.000469      0.002089  \n",
       "8170  0.000125      0.344737       0.000417      0.001100  \n",
       "8171  0.000000      0.037851       0.020709      0.009346  \n",
       "8172  0.000000      0.021400       0.007355      0.010995  \n",
       "8173  0.000000      0.036978       0.038289      0.012095  \n",
       "8174  0.000088      0.062018       0.011320      0.017042  \n",
       "8175  0.000000      0.001165       0.000365      0.002089  \n",
       "8176  0.000000      0.039598       0.014293      0.010995  \n",
       "8177  0.000000      0.026205       0.008764      0.010995  \n",
       "\n",
       "[8178 rows x 22 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop the Energy_kcal\n",
    "X=food_data_exp.drop(columns=['Energy_kcal'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.24119569  0.67799128 -0.19622227 ...  0.03757411 -0.00227135\n",
      "   0.00339145]\n",
      " [-0.24111747  0.67800279 -0.19606962 ...  0.03774329 -0.00219693\n",
      "   0.00337136]\n",
      " [-0.2490355   0.85978977 -0.21582281 ...  0.04602481 -0.0025539\n",
      "   0.00820173]\n",
      " ...\n",
      " [ 0.71008478 -0.06983089 -0.2225746  ... -0.04309256  0.01028418\n",
      "   0.00275507]\n",
      " [-0.19088559 -0.08110443  0.11613298 ... -0.13640969  0.03034918\n",
      "  -0.10331369]\n",
      " [-0.23537052 -0.10734434  0.05031379 ... -0.02461725  0.00099321\n",
      "  -0.00634902]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8178, 8)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6. PCA and LDA for Dimensionality reduction \n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# 1. PCA\n",
    "pca = PCA(n_components=0.95)# ensure to keep 95% of the information of dataset after dimensiona reduction\n",
    "pca.fit(X)\n",
    "X_PCA=pca.transform(X)\n",
    "print(X_PCA[:])\n",
    "X_PCA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.69431520e-01,  2.38764764e-01,  5.93256336e+00, ...,\n",
       "        -2.81361872e-01,  4.79995895e-01, -2.09348892e-01],\n",
       "       [-3.60494664e-01,  2.50970326e-01,  5.92923037e+00, ...,\n",
       "        -2.81168290e-01,  4.69525098e-01, -2.21969265e-01],\n",
       "       [-4.63888507e-01, -1.98291285e-01,  7.39714874e+00, ...,\n",
       "        -3.57843696e-01,  4.75873453e-01, -4.22909265e-01],\n",
       "       ...,\n",
       "       [ 3.15957742e+00,  1.23532759e-01, -9.22658936e-01, ...,\n",
       "         2.06619067e+00, -4.11459282e+00, -1.09976202e+00],\n",
       "       [-4.10906056e-01,  2.42426085e+00, -5.23277238e-03, ...,\n",
       "        -4.76615426e-01, -2.30388276e+00,  1.15477717e+00],\n",
       "       [-1.62144783e+00,  8.31325227e-01, -6.81068141e-01, ...,\n",
       "         5.97527217e-01,  4.46301082e-01,  8.87808330e-02]])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "X_LDA=LDA(n_components=8).fit_transform(X, food_data_target)#Parameter n_components is the dimensionality after dimension reduction\n",
    "X_LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number transactions X_train dataset:  (5724, 22)\n",
      "Number transactions y_train dataset:  (5724,)\n",
      "Number transactions X_test dataset:  (2454, 22)\n",
      "Number transactions y_test dataset:  (2454,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "#The dataset here is the one after PCA:X_PCA; Dataset without dimension reduction: X; Dataset with LDA:X_LDA\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_PCA, food_data_target, test_size=0.3, random_state=0)\n",
    "X_train_lda, X_test_lda, y_train_lda, y_test_lda = train_test_split(X_LDA, food_data_target, test_size=0.3, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, food_data_target, test_size=0.3, random_state=0)\n",
    "\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15800, 22)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = SMOTE(random_state=2)\n",
    "X_train_pca_res, y_train_pca_res = sm.fit_sample(X_train_pca, y_train_pca.ravel())\n",
    "y_train_pca_res = pd.Series(y_train_pca_res)\n",
    "X_train_pca_res = pd.DataFrame(X_train_pca_res)\n",
    "X_train_pca_res.shape\n",
    "\n",
    "X_train_lda_res, y_train_lda_res = sm.fit_sample(X_train_lda, y_train_lda.ravel())\n",
    "y_train_lda_res = pd.Series(y_train_lda_res)\n",
    "X_train_lda_res = pd.DataFrame(X_train_lda_res)\n",
    "X_train_lda_res.shape\n",
    "\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\n",
    "y_train_res = pd.Series(y_train_res)\n",
    "X_train_res = pd.DataFrame(X_train_res)\n",
    "X_train_res.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before --> After OverSampling: (Vegetables and Vegetable Products) 579 --> 632\n",
      "Before --> After OverSampling: (Dairy and Egg Products) 172 --> 632\n",
      "Before --> After OverSampling: (Spices and Herbs) 40 --> 632\n",
      "Before --> After OverSampling: (Soups, Sauces, and Gravies) 314 --> 632\n",
      "Before --> After OverSampling: (American Indian/Alaska Native Foods) 111 --> 632\n",
      "Before --> After OverSampling: (Lamb, Veal, and Game Products) 288 --> 632\n",
      "Before --> After OverSampling: (Snacks) 112 --> 632\n",
      "Before --> After OverSampling: (Legumes and Legume Products) 243 --> 632\n",
      "Before --> After OverSampling: (Sweets) 220 --> 632\n",
      "Before --> After OverSampling: (Breakfast Cereals) 243 --> 632\n",
      "Before --> After OverSampling: (Restaurant Foods) 75 --> 632\n",
      "Before --> After OverSampling: (Fast Foods) 236 --> 632\n",
      "Before --> After OverSampling: (Poultry Products) 257 --> 632\n",
      "Before --> After OverSampling: (Baby Foods) 246 --> 632\n",
      "Before --> After OverSampling: (Beef Products) 632 --> 632\n",
      "Before --> After OverSampling: (Cereal Grains and Pasta) 120 --> 632\n",
      "Before --> After OverSampling: (Baked Products) 501 --> 632\n",
      "Before --> After OverSampling: (Fats and Oils) 161 --> 632\n",
      "Before --> After OverSampling: (Beverages) 219 --> 632\n",
      "Before --> After OverSampling: (Meals, Entrees, and Side Dishes) 73 --> 632\n",
      "Before --> After OverSampling: (Fruits and Fruit Juices) 236 --> 632\n",
      "Before --> After OverSampling: (Nut and Seed Products) 86 --> 632\n",
      "Before --> After OverSampling: (Pork Products) 218 --> 632\n",
      "Before --> After OverSampling: (Sausages and Luncheon Meats) 173 --> 632\n",
      "Before --> After OverSampling: (Finfish and Shellfish Products) 169 --> 632\n",
      "\n",
      "\n",
      "Before --> After OverSampling: (Vegetables and Vegetable Products) 579 --> 632\n",
      "Before --> After OverSampling: (Dairy and Egg Products) 172 --> 632\n",
      "Before --> After OverSampling: (Spices and Herbs) 40 --> 632\n",
      "Before --> After OverSampling: (Soups, Sauces, and Gravies) 314 --> 632\n",
      "Before --> After OverSampling: (American Indian/Alaska Native Foods) 111 --> 632\n",
      "Before --> After OverSampling: (Lamb, Veal, and Game Products) 288 --> 632\n",
      "Before --> After OverSampling: (Snacks) 112 --> 632\n",
      "Before --> After OverSampling: (Legumes and Legume Products) 243 --> 632\n",
      "Before --> After OverSampling: (Sweets) 220 --> 632\n",
      "Before --> After OverSampling: (Breakfast Cereals) 243 --> 632\n",
      "Before --> After OverSampling: (Restaurant Foods) 75 --> 632\n",
      "Before --> After OverSampling: (Fast Foods) 236 --> 632\n",
      "Before --> After OverSampling: (Poultry Products) 257 --> 632\n",
      "Before --> After OverSampling: (Baby Foods) 246 --> 632\n",
      "Before --> After OverSampling: (Beef Products) 632 --> 632\n",
      "Before --> After OverSampling: (Cereal Grains and Pasta) 120 --> 632\n",
      "Before --> After OverSampling: (Baked Products) 501 --> 632\n",
      "Before --> After OverSampling: (Fats and Oils) 161 --> 632\n",
      "Before --> After OverSampling: (Beverages) 219 --> 632\n",
      "Before --> After OverSampling: (Meals, Entrees, and Side Dishes) 73 --> 632\n",
      "Before --> After OverSampling: (Fruits and Fruit Juices) 236 --> 632\n",
      "Before --> After OverSampling: (Nut and Seed Products) 86 --> 632\n",
      "Before --> After OverSampling: (Pork Products) 218 --> 632\n",
      "Before --> After OverSampling: (Sausages and Luncheon Meats) 173 --> 632\n",
      "Before --> After OverSampling: (Finfish and Shellfish Products) 169 --> 632\n",
      "\n",
      "\n",
      "Before --> After OverSampling: (Vegetables and Vegetable Products) 579 --> 632\n",
      "Before --> After OverSampling: (Dairy and Egg Products) 172 --> 632\n",
      "Before --> After OverSampling: (Spices and Herbs) 40 --> 632\n",
      "Before --> After OverSampling: (Soups, Sauces, and Gravies) 314 --> 632\n",
      "Before --> After OverSampling: (American Indian/Alaska Native Foods) 111 --> 632\n",
      "Before --> After OverSampling: (Lamb, Veal, and Game Products) 288 --> 632\n",
      "Before --> After OverSampling: (Snacks) 112 --> 632\n",
      "Before --> After OverSampling: (Legumes and Legume Products) 243 --> 632\n",
      "Before --> After OverSampling: (Sweets) 220 --> 632\n",
      "Before --> After OverSampling: (Breakfast Cereals) 243 --> 632\n",
      "Before --> After OverSampling: (Restaurant Foods) 75 --> 632\n",
      "Before --> After OverSampling: (Fast Foods) 236 --> 632\n",
      "Before --> After OverSampling: (Poultry Products) 257 --> 632\n",
      "Before --> After OverSampling: (Baby Foods) 246 --> 632\n",
      "Before --> After OverSampling: (Beef Products) 632 --> 632\n",
      "Before --> After OverSampling: (Cereal Grains and Pasta) 120 --> 632\n",
      "Before --> After OverSampling: (Baked Products) 501 --> 632\n",
      "Before --> After OverSampling: (Fats and Oils) 161 --> 632\n",
      "Before --> After OverSampling: (Beverages) 219 --> 632\n",
      "Before --> After OverSampling: (Meals, Entrees, and Side Dishes) 73 --> 632\n",
      "Before --> After OverSampling: (Fruits and Fruit Juices) 236 --> 632\n",
      "Before --> After OverSampling: (Nut and Seed Products) 86 --> 632\n",
      "Before --> After OverSampling: (Pork Products) 218 --> 632\n",
      "Before --> After OverSampling: (Sausages and Luncheon Meats) 173 --> 632\n",
      "Before --> After OverSampling: (Finfish and Shellfish Products) 169 --> 632\n"
     ]
    }
   ],
   "source": [
    "for cat in set(y_train_res):\n",
    "    print(f\"Before --> After OverSampling: ({cat}) {sum(y_train==cat)} --> {sum(y_train_res==cat)}\")\n",
    "print('\\n')\n",
    "for cat in set(y_train_lda_res):\n",
    "    print(f\"Before --> After OverSampling: ({cat}) {sum(y_train==cat)} --> {sum(y_train_lda_res==cat)}\")\n",
    "print('\\n')\n",
    "for cat in set(y_train_pca_res):\n",
    "    print(f\"Before --> After OverSampling: ({cat}) {sum(y_train_pca==cat)} --> {sum(y_train_pca_res==cat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#auxiliary method to draw a confusion matrix with a high number of features. we just use the pandas dataframe here since it facilitates formating \n",
    "\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
    "\n",
    "def create_confusion_matrix(y_true, y_pred):\n",
    "    labels_short = [x[:5] for x in unique_labels(y_true, y_pred)]\n",
    "    cm = pd.DataFrame(confusion_matrix(y_test, y_pred), columns=labels_short, index=labels_short)\n",
    "    s1 = [sum(cm.loc[l,:]) for l in labels_short]\n",
    "    s2 = [sum(cm.loc[:,l]) for l in labels_short]\n",
    "    s2.append(sum(s1))\n",
    "    cm = cm.assign(pred_sum=s1)\n",
    "    cm = cm.transpose()\n",
    "    cm = cm.assign(actual_sum=s2)\n",
    "    cm = cm.transpose()\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best dummy classifier is stratified, accuracy: 0.042379788101059496\n"
     ]
    }
   ],
   "source": [
    "#testing sci-kit learns dummy classifiers. As the class sizes have been balanced, a majority classifier will obviously show a very low accuracy\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "types = [\"stratified\", \"most_frequent\", \"prior\", \"uniform\"]\n",
    "dummies = {}\n",
    "for t in types:\n",
    "    d = DummyClassifier(t)\n",
    "    d.fit(X_train_res, y_train_res)\n",
    "    dummies[t] = accuracy_score(y_test, d.predict(X_test))\n",
    "m = max(dummies, key=dummies.get)\n",
    "print(f\"best dummy classifier is {m}, accuracy: {dummies[m]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best dummy classifier is stratified, accuracy: 0.04319478402607987\n"
     ]
    }
   ],
   "source": [
    "#testing sci-kit learns dummy classifiers. As the class sizes have been balanced, a majority classifier will obviously show a very low accuracy\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "types = [\"stratified\", \"most_frequent\", \"prior\", \"uniform\"]\n",
    "dummies = {}\n",
    "for t in types:\n",
    "    d = DummyClassifier(t)\n",
    "    d.fit(X_train_pca_res, y_train_pca_res)\n",
    "    dummies[t] = accuracy_score(y_test_pca, d.predict(X_test_pca))\n",
    "m = max(dummies, key=dummies.get)\n",
    "print(f\"best dummy classifier is {m}, accuracy: {dummies[m]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best dummy classifier is uniform, accuracy: 0.04482477587612062\n"
     ]
    }
   ],
   "source": [
    "#testing sci-kit learns dummy classifiers. As the class sizes have been balanced, a majority classifier will obviously show a very low accuracy\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "types = [\"stratified\", \"most_frequent\", \"prior\", \"uniform\"]\n",
    "dummies = {}\n",
    "for t in types:\n",
    "    d = DummyClassifier(t)\n",
    "    d.fit(X_train_pca_res, y_train_lda_res)\n",
    "    dummies[t] = accuracy_score(y_test_lda, d.predict(X_test_lda))\n",
    "m = max(dummies, key=dummies.get)\n",
    "print(f\"best dummy classifier is {m}, accuracy: {dummies[m]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.00      0.00      0.00        47\n",
      "                         Baby Foods       0.00      0.00      0.00       112\n",
      "                     Baked Products       0.00      0.00      0.00       229\n",
      "                      Beef Products       0.74      0.89      0.81       286\n",
      "                          Beverages       0.00      0.00      0.00        90\n",
      "                  Breakfast Cereals       0.81      0.56      0.66       115\n",
      "            Cereal Grains and Pasta       0.00      0.00      0.00        50\n",
      "             Dairy and Egg Products       0.00      0.00      0.00        86\n",
      "                         Fast Foods       0.00      0.00      0.00       114\n",
      "                      Fats and Oils       0.90      0.69      0.78        55\n",
      "     Finfish and Shellfish Products       0.20      0.79      0.32        70\n",
      "            Fruits and Fruit Juices       0.14      0.93      0.24        87\n",
      "      Lamb, Veal, and Game Products       0.00      0.00      0.00       106\n",
      "        Legumes and Legume Products       0.18      0.02      0.03       108\n",
      "    Meals, Entrees, and Side Dishes       0.00      0.00      0.00        34\n",
      "              Nut and Seed Products       0.76      0.60      0.67        47\n",
      "                      Pork Products       0.84      0.75      0.79        99\n",
      "                   Poultry Products       0.00      0.00      0.00       111\n",
      "                   Restaurant Foods       0.06      0.94      0.11        32\n",
      "        Sausages and Luncheon Meats       0.67      0.03      0.05        71\n",
      "                             Snacks       0.09      0.87      0.17        39\n",
      "         Soups, Sauces, and Gravies       0.00      0.00      0.00       118\n",
      "                   Spices and Herbs       0.23      0.50      0.31        24\n",
      "                             Sweets       0.69      0.42      0.53        97\n",
      "  Vegetables and Vegetable Products       0.00      0.00      0.00       227\n",
      "\n",
      "                          micro avg       0.29      0.29      0.29      2454\n",
      "                          macro avg       0.25      0.32      0.22      2454\n",
      "                       weighted avg       0.26      0.29      0.24      2454\n",
      "\n",
      "0.291361043194784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marian/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#we use a decision tree with a maximum depth of 4 instead.\n",
    "from sklearn import tree\n",
    "decision_tree = tree.DecisionTreeClassifier(max_depth=4, criterion='gini')\n",
    "decision_tree.fit(X_train_res, y_train_res)\n",
    "pred = decision_tree.predict(X_test)\n",
    "print(classification_report(y_test, pred))\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.00      0.00      0.00        47\n",
      "                         Baby Foods       0.00      0.00      0.00       112\n",
      "                     Baked Products       0.46      0.91      0.61       229\n",
      "                      Beef Products       0.00      0.00      0.00       286\n",
      "                          Beverages       0.00      0.00      0.00        90\n",
      "                  Breakfast Cereals       0.88      0.45      0.60       115\n",
      "            Cereal Grains and Pasta       0.00      0.00      0.00        50\n",
      "             Dairy and Egg Products       0.94      0.19      0.31        86\n",
      "                         Fast Foods       0.00      0.00      0.00       114\n",
      "                      Fats and Oils       0.95      0.75      0.84        55\n",
      "     Finfish and Shellfish Products       0.43      0.79      0.56        70\n",
      "            Fruits and Fruit Juices       0.00      0.00      0.00        87\n",
      "      Lamb, Veal, and Game Products       0.21      0.51      0.30       106\n",
      "        Legumes and Legume Products       0.45      0.05      0.08       108\n",
      "    Meals, Entrees, and Side Dishes       0.00      0.00      0.00        34\n",
      "              Nut and Seed Products       0.82      0.57      0.68        47\n",
      "                      Pork Products       0.25      0.85      0.39        99\n",
      "                   Poultry Products       0.00      0.00      0.00       111\n",
      "                   Restaurant Foods       0.07      0.94      0.13        32\n",
      "        Sausages and Luncheon Meats       0.00      0.00      0.00        71\n",
      "                             Snacks       0.00      0.00      0.00        39\n",
      "         Soups, Sauces, and Gravies       0.17      0.87      0.28       118\n",
      "                   Spices and Herbs       0.30      0.54      0.39        24\n",
      "                             Sweets       0.00      0.00      0.00        97\n",
      "  Vegetables and Vegetable Products       0.00      0.00      0.00       227\n",
      "\n",
      "                          micro avg       0.28      0.28      0.28      2454\n",
      "                          macro avg       0.24      0.30      0.21      2454\n",
      "                       weighted avg       0.22      0.28      0.19      2454\n",
      "\n",
      "0.280358598207009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marian/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#we use a decision tree with a maximum depth of 4 instead.\n",
    "from sklearn import tree\n",
    "decision_tree = tree.DecisionTreeClassifier(max_depth=4, criterion='gini')\n",
    "decision_tree.fit(X_train_pca_res, y_train_pca_res)\n",
    "pred = decision_tree.predict(X_test_pca)\n",
    "print(classification_report(y_test, pred))\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.09      0.11      0.10        47\n",
      "                         Baby Foods       0.00      0.00      0.00       112\n",
      "                     Baked Products       0.00      0.00      0.00       229\n",
      "                      Beef Products       0.69      0.83      0.75       286\n",
      "                          Beverages       0.00      0.00      0.00        90\n",
      "                  Breakfast Cereals       0.82      0.66      0.73       115\n",
      "            Cereal Grains and Pasta       0.00      0.00      0.00        50\n",
      "             Dairy and Egg Products       0.97      0.35      0.51        86\n",
      "                         Fast Foods       0.00      0.00      0.00       114\n",
      "                      Fats and Oils       0.98      0.80      0.88        55\n",
      "     Finfish and Shellfish Products       0.56      0.49      0.52        70\n",
      "            Fruits and Fruit Juices       0.08      0.99      0.15        87\n",
      "      Lamb, Veal, and Game Products       0.39      0.42      0.40       106\n",
      "        Legumes and Legume Products       0.00      0.00      0.00       108\n",
      "    Meals, Entrees, and Side Dishes       0.00      0.00      0.00        34\n",
      "              Nut and Seed Products       0.96      0.47      0.63        47\n",
      "                      Pork Products       0.36      0.59      0.45        99\n",
      "                   Poultry Products       0.00      0.00      0.00       111\n",
      "                   Restaurant Foods       0.00      0.00      0.00        32\n",
      "        Sausages and Luncheon Meats       0.38      0.59      0.46        71\n",
      "                             Snacks       0.10      0.72      0.17        39\n",
      "         Soups, Sauces, and Gravies       0.00      0.00      0.00       118\n",
      "                   Spices and Herbs       0.36      0.62      0.45        24\n",
      "                             Sweets       0.00      0.00      0.00        97\n",
      "  Vegetables and Vegetable Products       0.00      0.00      0.00       227\n",
      "\n",
      "                          micro avg       0.29      0.29      0.29      2454\n",
      "                          macro avg       0.27      0.30      0.25      2454\n",
      "                       weighted avg       0.26      0.29      0.25      2454\n",
      "\n",
      "0.293398533007335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marian/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#we use a decision tree with a maximum depth of 4 instead.\n",
    "from sklearn import tree\n",
    "decision_tree = tree.DecisionTreeClassifier(max_depth=4, criterion='gini')\n",
    "decision_tree.fit(X_train_lda_res, y_train_lda_res)\n",
    "pred = decision_tree.predict(X_test_lda)\n",
    "print(classification_report(y_test, pred))\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max f1:('distance', 3)\n",
      "\n",
      "knn with ('distance', 2):     f1 = 0.7459231994684616\n",
      "knn with ('distance', 3):     f1 = 0.7515706457085918\n",
      "knn with ('distance', 4):     f1 = 0.7487231610559784\n",
      "knn with ('distance', 5):     f1 = 0.7410908847623916\n",
      "knn with ('distance', 6):     f1 = 0.7363494608140347\n",
      "knn with ('distance', 7):     f1 = 0.7363880540441191\n",
      "knn with ('distance', 8):     f1 = 0.7353489275818582\n",
      "knn with ('distance', 9):     f1 = 0.7355746137213117\n",
      "knn with ('uniform', 2):     f1 = 0.7377743622686513\n",
      "knn with ('uniform', 3):     f1 = 0.740763780178733\n",
      "knn with ('uniform', 4):     f1 = 0.7303881148727365\n",
      "knn with ('uniform', 5):     f1 = 0.726445400327713\n",
      "knn with ('uniform', 6):     f1 = 0.719566187958902\n",
      "knn with ('uniform', 7):     f1 = 0.7196477466958909\n",
      "knn with ('uniform', 8):     f1 = 0.708987517864966\n",
      "knn with ('uniform', 9):     f1 = 0.709125655690394\n"
     ]
    }
   ],
   "source": [
    "seed = 2\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "results_knn = defaultdict(list)\n",
    "#storing information for the various knn classifiers in a dictionary\n",
    "for w in ['distance', 'uniform']:\n",
    "    for n_neighbors in range(2, 10):\n",
    "        knn_estimator = KNeighborsClassifier(n_neighbors, weights=w)\n",
    "        knn_estimator.fit(X_train_res, y_train_res)\n",
    "        pred = knn_estimator.predict(X_test)\n",
    "        results_knn[(w, n_neighbors)].append(accuracy_score(y_test, pred))\n",
    "        results_knn[(w, n_neighbors)].append(f1_score(y_test, pred, average='weighted'))\n",
    "        results_knn[(w, n_neighbors)].append(classification_report(y_test, pred))\n",
    "        results_knn[(w, n_neighbors)].append(create_confusion_matrix(y_test, pred))\n",
    "\n",
    "print(f'max f1:{max(results_knn, key=lambda x: results_knn[x][1])}\\n')\n",
    "for k, v in results_knn.items():\n",
    "    print(f\"knn with {k}:     f1 = {v[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.42      0.43      0.42        47\n",
      "                         Baby Foods       0.75      0.74      0.74       112\n",
      "                     Baked Products       0.95      0.81      0.88       229\n",
      "                      Beef Products       0.94      0.90      0.92       286\n",
      "                          Beverages       0.80      0.78      0.79        90\n",
      "                  Breakfast Cereals       0.87      0.92      0.89       115\n",
      "            Cereal Grains and Pasta       0.60      0.78      0.68        50\n",
      "             Dairy and Egg Products       0.84      0.72      0.77        86\n",
      "                         Fast Foods       0.79      0.74      0.76       114\n",
      "                      Fats and Oils       0.81      0.93      0.86        55\n",
      "     Finfish and Shellfish Products       0.82      0.87      0.85        70\n",
      "            Fruits and Fruit Juices       0.66      0.66      0.66        87\n",
      "      Lamb, Veal, and Game Products       0.73      0.76      0.75       106\n",
      "        Legumes and Legume Products       0.88      0.79      0.83       108\n",
      "    Meals, Entrees, and Side Dishes       0.67      0.59      0.62        34\n",
      "              Nut and Seed Products       0.87      0.83      0.85        47\n",
      "                      Pork Products       0.88      0.84      0.86        99\n",
      "                   Poultry Products       0.78      0.92      0.84       111\n",
      "                   Restaurant Foods       0.34      0.75      0.47        32\n",
      "        Sausages and Luncheon Meats       0.77      0.72      0.74        71\n",
      "                             Snacks       0.57      0.72      0.64        39\n",
      "         Soups, Sauces, and Gravies       0.80      0.84      0.82       118\n",
      "                   Spices and Herbs       0.52      0.58      0.55        24\n",
      "                             Sweets       0.77      0.77      0.77        97\n",
      "  Vegetables and Vegetable Products       0.86      0.78      0.82       227\n",
      "\n",
      "                          micro avg       0.80      0.80      0.80      2454\n",
      "                          macro avg       0.75      0.77      0.75      2454\n",
      "                       weighted avg       0.81      0.80      0.80      2454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(results_knn[('distance', 3)][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max f1:('distance', 3)\n",
      "\n",
      "knn with ('distance', 2):     f1 = 0.6748501993780736\n",
      "knn with ('distance', 3):     f1 = 0.6762813088736472\n",
      "knn with ('distance', 4):     f1 = 0.6721295940004833\n",
      "knn with ('distance', 5):     f1 = 0.6655626228165223\n",
      "knn with ('distance', 6):     f1 = 0.6652899183267637\n",
      "knn with ('distance', 7):     f1 = 0.6689578921439525\n",
      "knn with ('distance', 8):     f1 = 0.6665377402516824\n",
      "knn with ('distance', 9):     f1 = 0.6645860024460934\n",
      "knn with ('uniform', 2):     f1 = 0.6641915773553352\n",
      "knn with ('uniform', 3):     f1 = 0.666439333879476\n",
      "knn with ('uniform', 4):     f1 = 0.6491703565310949\n",
      "knn with ('uniform', 5):     f1 = 0.6442713353374034\n",
      "knn with ('uniform', 6):     f1 = 0.6381712260038106\n",
      "knn with ('uniform', 7):     f1 = 0.6475655198741969\n",
      "knn with ('uniform', 8):     f1 = 0.6365480747356375\n",
      "knn with ('uniform', 9):     f1 = 0.6366410313653267\n"
     ]
    }
   ],
   "source": [
    "results_knn = defaultdict(list)\n",
    "#storing information for the various knn classifiers in a dictionary\n",
    "for w in ['distance', 'uniform']:\n",
    "    for n_neighbors in range(2, 10):\n",
    "        knn_estimator = KNeighborsClassifier(n_neighbors, weights=w)\n",
    "        knn_estimator.fit(X_train_pca_res, y_train_pca_res)\n",
    "        pred = knn_estimator.predict(X_test_pca)\n",
    "        results_knn[(w, n_neighbors)].append(accuracy_score(y_test, pred))\n",
    "        results_knn[(w, n_neighbors)].append(f1_score(y_test, pred, average='weighted'))\n",
    "        results_knn[(w, n_neighbors)].append(classification_report(y_test, pred))\n",
    "        results_knn[(w, n_neighbors)].append(create_confusion_matrix(y_test, pred))\n",
    "\n",
    "print(f'max f1:{max(results_knn, key=lambda x: results_knn[x][1])}\\n')\n",
    "for k, v in results_knn.items():\n",
    "    print(f\"knn with {k}:     f1 = {v[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.26      0.30      0.28        47\n",
      "                         Baby Foods       0.67      0.69      0.68       112\n",
      "                     Baked Products       0.94      0.79      0.86       229\n",
      "                      Beef Products       0.84      0.73      0.78       286\n",
      "                          Beverages       0.72      0.70      0.71        90\n",
      "                  Breakfast Cereals       0.84      0.93      0.88       115\n",
      "            Cereal Grains and Pasta       0.54      0.68      0.60        50\n",
      "             Dairy and Egg Products       0.78      0.66      0.72        86\n",
      "                         Fast Foods       0.76      0.68      0.72       114\n",
      "                      Fats and Oils       0.76      0.91      0.83        55\n",
      "     Finfish and Shellfish Products       0.66      0.69      0.67        70\n",
      "            Fruits and Fruit Juices       0.60      0.62      0.61        87\n",
      "      Lamb, Veal, and Game Products       0.43      0.57      0.49       106\n",
      "        Legumes and Legume Products       0.83      0.75      0.79       108\n",
      "    Meals, Entrees, and Side Dishes       0.50      0.56      0.53        34\n",
      "              Nut and Seed Products       0.76      0.83      0.80        47\n",
      "                      Pork Products       0.62      0.62      0.62        99\n",
      "                   Poultry Products       0.62      0.69      0.65       111\n",
      "                   Restaurant Foods       0.34      0.72      0.46        32\n",
      "        Sausages and Luncheon Meats       0.74      0.72      0.73        71\n",
      "                             Snacks       0.58      0.67      0.62        39\n",
      "         Soups, Sauces, and Gravies       0.80      0.80      0.80       118\n",
      "                   Spices and Herbs       0.52      0.54      0.53        24\n",
      "                             Sweets       0.80      0.75      0.78        97\n",
      "  Vegetables and Vegetable Products       0.84      0.74      0.79       227\n",
      "\n",
      "                          micro avg       0.72      0.72      0.72      2454\n",
      "                          macro avg       0.67      0.69      0.68      2454\n",
      "                       weighted avg       0.74      0.72      0.72      2454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(results_knn[('distance', 3)][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max f1:('distance', 5)\n",
      "\n",
      "knn with ('distance', 2):     f1 = 0.7175863039242053\n",
      "knn with ('distance', 3):     f1 = 0.7270687247144086\n",
      "knn with ('distance', 4):     f1 = 0.726327469337024\n",
      "knn with ('distance', 5):     f1 = 0.7302288543094505\n",
      "knn with ('distance', 6):     f1 = 0.7295860636693962\n",
      "knn with ('distance', 7):     f1 = 0.722966538699103\n",
      "knn with ('distance', 8):     f1 = 0.7221814505332067\n",
      "knn with ('distance', 9):     f1 = 0.7114236526797951\n",
      "knn with ('uniform', 2):     f1 = 0.7148674316645705\n",
      "knn with ('uniform', 3):     f1 = 0.7207956348690924\n",
      "knn with ('uniform', 4):     f1 = 0.7157753552227842\n",
      "knn with ('uniform', 5):     f1 = 0.7163987166445384\n",
      "knn with ('uniform', 6):     f1 = 0.7046348960997649\n",
      "knn with ('uniform', 7):     f1 = 0.7037268584240566\n",
      "knn with ('uniform', 8):     f1 = 0.6966419608314439\n",
      "knn with ('uniform', 9):     f1 = 0.692338068992714\n"
     ]
    }
   ],
   "source": [
    "results_knn = defaultdict(list)\n",
    "#storing information for the various knn classifiers in a dictionary\n",
    "for w in ['distance', 'uniform']:\n",
    "    for n_neighbors in range(2, 10):\n",
    "        knn_estimator = KNeighborsClassifier(n_neighbors, weights=w)\n",
    "        knn_estimator.fit(X_train_lda_res, y_train_lda_res)\n",
    "        pred = knn_estimator.predict(X_test_lda)\n",
    "        results_knn[(w, n_neighbors)].append(accuracy_score(y_test, pred))\n",
    "        results_knn[(w, n_neighbors)].append(f1_score(y_test, pred, average='weighted'))\n",
    "        results_knn[(w, n_neighbors)].append(classification_report(y_test, pred))\n",
    "        results_knn[(w, n_neighbors)].append(create_confusion_matrix(y_test, pred))\n",
    "\n",
    "print(f'max f1:{max(results_knn, key=lambda x: results_knn[x][1])}\\n')\n",
    "for k, v in results_knn.items():\n",
    "    print(f\"knn with {k}:     f1 = {v[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.30      0.30      0.30        47\n",
      "                         Baby Foods       0.77      0.73      0.75       112\n",
      "                     Baked Products       0.95      0.81      0.88       229\n",
      "                      Beef Products       0.91      0.89      0.90       286\n",
      "                          Beverages       0.70      0.72      0.71        90\n",
      "                  Breakfast Cereals       0.87      0.91      0.89       115\n",
      "            Cereal Grains and Pasta       0.56      0.82      0.67        50\n",
      "             Dairy and Egg Products       0.83      0.81      0.82        86\n",
      "                         Fast Foods       0.82      0.78      0.80       114\n",
      "                      Fats and Oils       0.82      0.93      0.87        55\n",
      "     Finfish and Shellfish Products       0.81      0.60      0.69        70\n",
      "            Fruits and Fruit Juices       0.67      0.77      0.72        87\n",
      "      Lamb, Veal, and Game Products       0.60      0.77      0.67       106\n",
      "        Legumes and Legume Products       0.78      0.74      0.76       108\n",
      "    Meals, Entrees, and Side Dishes       0.50      0.62      0.55        34\n",
      "              Nut and Seed Products       0.80      0.85      0.82        47\n",
      "                      Pork Products       0.79      0.86      0.82        99\n",
      "                   Poultry Products       0.76      0.68      0.71       111\n",
      "                   Restaurant Foods       0.45      0.78      0.57        32\n",
      "        Sausages and Luncheon Meats       0.76      0.70      0.73        71\n",
      "                             Snacks       0.61      0.69      0.65        39\n",
      "         Soups, Sauces, and Gravies       0.81      0.78      0.80       118\n",
      "                   Spices and Herbs       0.52      0.62      0.57        24\n",
      "                             Sweets       0.79      0.75      0.77        97\n",
      "  Vegetables and Vegetable Products       0.90      0.77      0.83       227\n",
      "\n",
      "                          micro avg       0.78      0.78      0.78      2454\n",
      "                          macro avg       0.72      0.75      0.73      2454\n",
      "                       weighted avg       0.79      0.78      0.78      2454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(results_knn[('distance', 5)][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37571312143439284\n",
      "                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.07      0.04      0.05        47\n",
      "                         Baby Foods       0.14      0.02      0.03       112\n",
      "                     Baked Products       0.80      0.16      0.26       229\n",
      "                      Beef Products       0.66      0.52      0.58       286\n",
      "                          Beverages       0.10      0.08      0.09        90\n",
      "                  Breakfast Cereals       0.81      0.77      0.79       115\n",
      "            Cereal Grains and Pasta       0.23      0.60      0.33        50\n",
      "             Dairy and Egg Products       0.75      0.10      0.18        86\n",
      "                         Fast Foods       0.77      0.45      0.57       114\n",
      "                      Fats and Oils       0.60      0.80      0.69        55\n",
      "     Finfish and Shellfish Products       0.24      0.74      0.36        70\n",
      "            Fruits and Fruit Juices       0.35      0.16      0.22        87\n",
      "      Lamb, Veal, and Game Products       0.52      0.16      0.24       106\n",
      "        Legumes and Legume Products       0.33      0.03      0.05       108\n",
      "    Meals, Entrees, and Side Dishes       0.09      0.35      0.14        34\n",
      "              Nut and Seed Products       0.56      0.49      0.52        47\n",
      "                      Pork Products       0.46      0.26      0.34        99\n",
      "                   Poultry Products       0.38      0.41      0.40       111\n",
      "                   Restaurant Foods       0.21      0.19      0.20        32\n",
      "        Sausages and Luncheon Meats       0.29      0.66      0.40        71\n",
      "                             Snacks       0.22      0.36      0.27        39\n",
      "         Soups, Sauces, and Gravies       0.23      0.83      0.36       118\n",
      "                   Spices and Herbs       0.33      0.54      0.41        24\n",
      "                             Sweets       0.31      0.54      0.39        97\n",
      "  Vegetables and Vegetable Products       0.58      0.36      0.44       227\n",
      "\n",
      "                          micro avg       0.38      0.38      0.38      2454\n",
      "                          macro avg       0.40      0.38      0.33      2454\n",
      "                       weighted avg       0.48      0.38      0.36      2454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "nearest_centroid = NearestCentroid()\n",
    "nearest_centroid.fit(X_train_res, y_train_res)\n",
    "pred = nearest_centroid.predict(X_test)\n",
    "print(accuracy_score(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.343520782396088\n",
      "                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.06      0.04      0.05        47\n",
      "                         Baby Foods       0.00      0.00      0.00       112\n",
      "                     Baked Products       0.79      0.14      0.24       229\n",
      "                      Beef Products       0.51      0.47      0.49       286\n",
      "                          Beverages       0.06      0.04      0.05        90\n",
      "                  Breakfast Cereals       0.81      0.76      0.78       115\n",
      "            Cereal Grains and Pasta       0.23      0.60      0.33        50\n",
      "             Dairy and Egg Products       0.75      0.07      0.13        86\n",
      "                         Fast Foods       0.76      0.45      0.56       114\n",
      "                      Fats and Oils       0.60      0.80      0.69        55\n",
      "     Finfish and Shellfish Products       0.24      0.76      0.36        70\n",
      "            Fruits and Fruit Juices       0.36      0.16      0.22        87\n",
      "      Lamb, Veal, and Game Products       0.17      0.01      0.02       106\n",
      "        Legumes and Legume Products       0.33      0.02      0.04       108\n",
      "    Meals, Entrees, and Side Dishes       0.09      0.35      0.14        34\n",
      "              Nut and Seed Products       0.56      0.49      0.52        47\n",
      "                      Pork Products       0.20      0.14      0.17        99\n",
      "                   Poultry Products       0.26      0.23      0.24       111\n",
      "                   Restaurant Foods       0.21      0.19      0.20        32\n",
      "        Sausages and Luncheon Meats       0.29      0.68      0.41        71\n",
      "                             Snacks       0.22      0.36      0.27        39\n",
      "         Soups, Sauces, and Gravies       0.23      0.83      0.36       118\n",
      "                   Spices and Herbs       0.28      0.54      0.37        24\n",
      "                             Sweets       0.31      0.54      0.39        97\n",
      "  Vegetables and Vegetable Products       0.55      0.33      0.42       227\n",
      "\n",
      "                          micro avg       0.34      0.34      0.34      2454\n",
      "                          macro avg       0.35      0.36      0.30      2454\n",
      "                       weighted avg       0.42      0.34      0.32      2454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nearest_centroid = NearestCentroid()\n",
    "nearest_centroid.fit(X_train_pca_res, y_train_pca_res)\n",
    "pred = nearest_centroid.predict(X_test_pca)\n",
    "print(accuracy_score(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4621026894865526\n",
      "                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.10      0.11      0.11        47\n",
      "                         Baby Foods       0.24      0.07      0.11       112\n",
      "                     Baked Products       0.81      0.38      0.51       229\n",
      "                      Beef Products       0.62      0.60      0.61       286\n",
      "                          Beverages       0.31      0.24      0.27        90\n",
      "                  Breakfast Cereals       0.92      0.59      0.72       115\n",
      "            Cereal Grains and Pasta       0.25      0.62      0.35        50\n",
      "             Dairy and Egg Products       0.75      0.50      0.60        86\n",
      "                         Fast Foods       0.88      0.49      0.63       114\n",
      "                      Fats and Oils       0.66      0.82      0.73        55\n",
      "     Finfish and Shellfish Products       0.41      0.64      0.50        70\n",
      "            Fruits and Fruit Juices       0.50      0.36      0.42        87\n",
      "      Lamb, Veal, and Game Products       0.41      0.26      0.32       106\n",
      "        Legumes and Legume Products       0.70      0.13      0.22       108\n",
      "    Meals, Entrees, and Side Dishes       0.10      0.38      0.15        34\n",
      "              Nut and Seed Products       0.52      0.68      0.59        47\n",
      "                      Pork Products       0.55      0.30      0.39        99\n",
      "                   Poultry Products       0.25      0.31      0.28       111\n",
      "                   Restaurant Foods       0.14      0.09      0.11        32\n",
      "        Sausages and Luncheon Meats       0.37      0.63      0.47        71\n",
      "                             Snacks       0.24      0.33      0.28        39\n",
      "         Soups, Sauces, and Gravies       0.32      0.83      0.47       118\n",
      "                   Spices and Herbs       0.58      0.62      0.60        24\n",
      "                             Sweets       0.35      0.51      0.41        97\n",
      "  Vegetables and Vegetable Products       0.69      0.65      0.67       227\n",
      "\n",
      "                          micro avg       0.46      0.46      0.46      2454\n",
      "                          macro avg       0.47      0.45      0.42      2454\n",
      "                       weighted avg       0.54      0.46      0.46      2454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nearest_centroid = NearestCentroid()\n",
    "nearest_centroid.fit(X_train_lda_res, y_train_lda_res)\n",
    "pred = nearest_centroid.predict(X_test_lda)\n",
    "print(accuracy_score(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marian/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/marian/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/marian/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/marian/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/marian/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/marian/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/marian/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/marian/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max f1:('entropy', 23)\n",
      "\n",
      "dc with max_depth=('gini', 5):    acc=0.3480032599837001    f1 = 0.31596403062989087 \n",
      "dc with max_depth=('gini', 6):    acc=0.506519967400163    f1 = 0.4803975330069294 \n",
      "dc with max_depth=('gini', 7):    acc=0.5786471067644662    f1 = 0.5945359332873915 \n",
      "dc with max_depth=('gini', 8):    acc=0.6234718826405868    f1 = 0.6364691753896834 \n",
      "dc with max_depth=('gini', 9):    acc=0.6605541972290139    f1 = 0.6705586477184339 \n",
      "dc with max_depth=('gini', 10):    acc=0.6882640586797066    f1 = 0.6960655163187813 \n",
      "dc with max_depth=('gini', 11):    acc=0.7147514262428688    f1 = 0.720218218900956 \n",
      "dc with max_depth=('gini', 12):    acc=0.728198859005705    f1 = 0.7337467150785685 \n",
      "dc with max_depth=('gini', 13):    acc=0.73920130399348    f1 = 0.7438804695156356 \n",
      "dc with max_depth=('gini', 14):    acc=0.7473512632436837    f1 = 0.7521476928278541 \n",
      "dc with max_depth=('gini', 15):    acc=0.7514262428687857    f1 = 0.7549771308124161 \n",
      "dc with max_depth=('gini', 16):    acc=0.7502037489812551    f1 = 0.7536316687940392 \n",
      "dc with max_depth=('gini', 17):    acc=0.7542787286063569    f1 = 0.7570844576129091 \n",
      "dc with max_depth=('gini', 18):    acc=0.7481662591687042    f1 = 0.7508085326418458 \n",
      "dc with max_depth=('gini', 19):    acc=0.7534637326813366    f1 = 0.7562213900039987 \n",
      "dc with max_depth=('gini', 20):    acc=0.7420537897310513    f1 = 0.7461065565409798 \n",
      "dc with max_depth=('gini', 21):    acc=0.7518337408312958    f1 = 0.7545010548149483 \n",
      "dc with max_depth=('gini', 22):    acc=0.7506112469437652    f1 = 0.7536878010836394 \n",
      "dc with max_depth=('gini', 23):    acc=0.7493887530562348    f1 = 0.7533805909854815 \n",
      "dc with max_depth=('gini', 24):    acc=0.7514262428687857    f1 = 0.7535320445289243 \n",
      "dc with max_depth=('gini', 25):    acc=0.7510187449062755    f1 = 0.7542214973080698 \n",
      "dc with max_depth=('gini', 26):    acc=0.752241238793806    f1 = 0.755615986133829 \n",
      "dc with max_depth=('gini', 27):    acc=0.7489812550937245    f1 = 0.7509767976981635 \n",
      "dc with max_depth=('gini', 28):    acc=0.7510187449062755    f1 = 0.752952379644937 \n",
      "dc with max_depth=('gini', 29):    acc=0.7526487367563163    f1 = 0.756946636595459 \n",
      "dc with max_depth=('gini', 30):    acc=0.747758761206194    f1 = 0.7513625496280053 \n",
      "dc with max_depth=('gini', 31):    acc=0.7453137734311328    f1 = 0.7481236701639878 \n",
      "dc with max_depth=('gini', 32):    acc=0.7538712306438468    f1 = 0.7558769738377089 \n",
      "dc with max_depth=('gini', 33):    acc=0.7514262428687857    f1 = 0.7552932251281294 \n",
      "dc with max_depth=('gini', 34):    acc=0.7518337408312958    f1 = 0.7559865400332878 \n",
      "dc with max_depth=('gini', 35):    acc=0.752241238793806    f1 = 0.7556727520090719 \n",
      "dc with max_depth=('gini', 36):    acc=0.7559087204563977    f1 = 0.7596201052235607 \n",
      "dc with max_depth=('gini', 37):    acc=0.7542787286063569    f1 = 0.7583154592727129 \n",
      "dc with max_depth=('gini', 38):    acc=0.7567237163814181    f1 = 0.7592307483566955 \n",
      "dc with max_depth=('gini', 39):    acc=0.7457212713936431    f1 = 0.7498080930572073 \n",
      "dc with max_depth=('entropy', 5):    acc=0.486960065199674    f1 = 0.45985257334354684 \n",
      "dc with max_depth=('entropy', 6):    acc=0.5403422982885085    f1 = 0.5378835678779925 \n",
      "dc with max_depth=('entropy', 7):    acc=0.6418092909535452    f1 = 0.6507675983222566 \n",
      "dc with max_depth=('entropy', 8):    acc=0.6801140994295028    f1 = 0.6892286495445561 \n",
      "dc with max_depth=('entropy', 9):    acc=0.706601466992665    f1 = 0.7160803430139764 \n",
      "dc with max_depth=('entropy', 10):    acc=0.7212713936430318    f1 = 0.7288128518111053 \n",
      "dc with max_depth=('entropy', 11):    acc=0.7526487367563163    f1 = 0.759141697712336 \n",
      "dc with max_depth=('entropy', 12):    acc=0.7628361858190709    f1 = 0.765713280326924 \n",
      "dc with max_depth=('entropy', 13):    acc=0.7689486552567237    f1 = 0.7709373647456742 \n",
      "dc with max_depth=('entropy', 14):    acc=0.7762836185819071    f1 = 0.778690150980167 \n",
      "dc with max_depth=('entropy', 15):    acc=0.7811735941320294    f1 = 0.7826845827319868 \n",
      "dc with max_depth=('entropy', 16):    acc=0.7766911165444172    f1 = 0.7784701844653006 \n",
      "dc with max_depth=('entropy', 17):    acc=0.7766911165444172    f1 = 0.7779961667309124 \n",
      "dc with max_depth=('entropy', 18):    acc=0.7819885900570497    f1 = 0.7830246243189365 \n",
      "dc with max_depth=('entropy', 19):    acc=0.7779136104319478    f1 = 0.7792709588344539 \n",
      "dc with max_depth=('entropy', 20):    acc=0.7832110839445803    f1 = 0.7846663157657168 \n",
      "dc with max_depth=('entropy', 21):    acc=0.7762836185819071    f1 = 0.777780649857177 \n",
      "dc with max_depth=('entropy', 22):    acc=0.7832110839445803    f1 = 0.7846629379372122 \n",
      "dc with max_depth=('entropy', 23):    acc=0.7876935615321924    f1 = 0.789117408734985 \n",
      "dc with max_depth=('entropy', 24):    acc=0.7787286063569682    f1 = 0.780780686921774 \n",
      "dc with max_depth=('entropy', 25):    acc=0.78239608801956    f1 = 0.7838143510382828 \n",
      "dc with max_depth=('entropy', 26):    acc=0.7799511002444988    f1 = 0.7821456882710595 \n",
      "dc with max_depth=('entropy', 27):    acc=0.7766911165444172    f1 = 0.7787461981065741 \n",
      "dc with max_depth=('entropy', 28):    acc=0.7762836185819071    f1 = 0.7776528964226224 \n",
      "dc with max_depth=('entropy', 29):    acc=0.7811735941320294    f1 = 0.7824651327318911 \n",
      "dc with max_depth=('entropy', 30):    acc=0.7819885900570497    f1 = 0.7839903593118343 \n",
      "dc with max_depth=('entropy', 31):    acc=0.7815810920945395    f1 = 0.7830289531710387 \n",
      "dc with max_depth=('entropy', 32):    acc=0.7726161369193154    f1 = 0.7744225530614358 \n",
      "dc with max_depth=('entropy', 33):    acc=0.773838630806846    f1 = 0.7758292229292546 \n",
      "dc with max_depth=('entropy', 34):    acc=0.7795436022819886    f1 = 0.780312533221665 \n",
      "dc with max_depth=('entropy', 35):    acc=0.7811735941320294    f1 = 0.7833120643052517 \n",
      "dc with max_depth=('entropy', 36):    acc=0.7787286063569682    f1 = 0.7808744794938333 \n",
      "dc with max_depth=('entropy', 37):    acc=0.7799511002444988    f1 = 0.7824449148348168 \n",
      "dc with max_depth=('entropy', 38):    acc=0.7795436022819886    f1 = 0.7811388179729329 \n",
      "dc with max_depth=('entropy', 39):    acc=0.7766911165444172    f1 = 0.777874583492796 \n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "results_dc = defaultdict(list)\n",
    "for c in ['gini', 'entropy']:\n",
    "    for depth in range(5, 40):\n",
    "        decision_tree = tree.DecisionTreeClassifier(max_depth=depth, criterion=c)\n",
    "        decision_tree.fit(X_train_res, y_train_res)\n",
    "        prediction = decision_tree.predict(X_test)\n",
    "\n",
    "        results_dc[(c, depth)].append(accuracy_score(y_test, prediction))\n",
    "        results_dc[(c, depth)].append(f1_score(y_test, prediction, average='weighted'))\n",
    "        results_dc[(c, depth)].append(classification_report(y_test, prediction))\n",
    "        results_dc[(c, depth)].append(create_confusion_matrix(y_test, prediction))\n",
    "        \n",
    "print(f'max f1:{max(results_dc, key=lambda x: results_dc[x][1])}\\n')\n",
    "for k, v in results_dc.items():\n",
    "    print(f\"dc with max_depth={k}:    acc={v[0]}    f1 = {v[1]} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.40      0.47      0.43        47\n",
      "                         Baby Foods       0.72      0.71      0.71       112\n",
      "                     Baked Products       0.93      0.80      0.86       229\n",
      "                      Beef Products       0.94      0.93      0.94       286\n",
      "                          Beverages       0.73      0.71      0.72        90\n",
      "                  Breakfast Cereals       0.82      0.86      0.84       115\n",
      "            Cereal Grains and Pasta       0.81      0.86      0.83        50\n",
      "             Dairy and Egg Products       0.80      0.85      0.82        86\n",
      "                         Fast Foods       0.76      0.67      0.71       114\n",
      "                      Fats and Oils       0.78      0.84      0.81        55\n",
      "     Finfish and Shellfish Products       0.82      0.90      0.86        70\n",
      "            Fruits and Fruit Juices       0.70      0.71      0.71        87\n",
      "      Lamb, Veal, and Game Products       0.73      0.86      0.79       106\n",
      "        Legumes and Legume Products       0.74      0.76      0.75       108\n",
      "    Meals, Entrees, and Side Dishes       0.51      0.62      0.56        34\n",
      "              Nut and Seed Products       0.80      0.74      0.77        47\n",
      "                      Pork Products       0.85      0.89      0.87        99\n",
      "                   Poultry Products       0.88      0.83      0.86       111\n",
      "                   Restaurant Foods       0.56      0.69      0.62        32\n",
      "        Sausages and Luncheon Meats       0.70      0.65      0.67        71\n",
      "                             Snacks       0.56      0.64      0.60        39\n",
      "         Soups, Sauces, and Gravies       0.69      0.70      0.69       118\n",
      "                   Spices and Herbs       0.57      0.54      0.55        24\n",
      "                             Sweets       0.70      0.68      0.69        97\n",
      "  Vegetables and Vegetable Products       0.89      0.84      0.86       227\n",
      "\n",
      "                          micro avg       0.79      0.79      0.79      2454\n",
      "                          macro avg       0.74      0.75      0.74      2454\n",
      "                       weighted avg       0.79      0.79      0.79      2454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(results_dc[('entropy', 23)][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marian/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/marian/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/marian/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/marian/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/marian/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/marian/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/marian/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/marian/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/marian/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/marian/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/marian/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/marian/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/marian/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/marian/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max f1:('entropy', 25)\n",
      "\n",
      "dc with max_depth=('gini', 5):    acc=0.39160554197229014    f1 = 0.33883650288778433 \n",
      "dc with max_depth=('gini', 6):    acc=0.34963325183374083    f1 = 0.3270099186669835 \n",
      "dc with max_depth=('gini', 7):    acc=0.46454767726161367    f1 = 0.46268458728070083 \n",
      "dc with max_depth=('gini', 8):    acc=0.5321923390383048    f1 = 0.5438928907801286 \n",
      "dc with max_depth=('gini', 9):    acc=0.5639771801140995    f1 = 0.5735573937930073 \n",
      "dc with max_depth=('gini', 10):    acc=0.5896495517522412    f1 = 0.5993892864932732 \n",
      "dc with max_depth=('gini', 11):    acc=0.634881825590872    f1 = 0.6393583946802736 \n",
      "dc with max_depth=('gini', 12):    acc=0.6479217603911981    f1 = 0.6580971407358465 \n",
      "dc with max_depth=('gini', 13):    acc=0.6572942135289324    f1 = 0.6630850088549683 \n",
      "dc with max_depth=('gini', 14):    acc=0.6589242053789731    f1 = 0.6648664799783675 \n",
      "dc with max_depth=('gini', 15):    acc=0.6658516707416463    f1 = 0.6722560587311321 \n",
      "dc with max_depth=('gini', 16):    acc=0.6703341483292583    f1 = 0.6763654304303571 \n",
      "dc with max_depth=('gini', 17):    acc=0.6711491442542787    f1 = 0.6773090594552109 \n",
      "dc with max_depth=('gini', 18):    acc=0.6723716381418093    f1 = 0.6777785654396081 \n",
      "dc with max_depth=('gini', 19):    acc=0.6715566422167889    f1 = 0.6767319200269305 \n",
      "dc with max_depth=('gini', 20):    acc=0.6707416462917686    f1 = 0.6764612652671466 \n",
      "dc with max_depth=('gini', 21):    acc=0.676039119804401    f1 = 0.6811459039788172 \n",
      "dc with max_depth=('gini', 22):    acc=0.6756316218418907    f1 = 0.6804874749826787 \n",
      "dc with max_depth=('gini', 23):    acc=0.6744091279543603    f1 = 0.680027075807764 \n",
      "dc with max_depth=('gini', 24):    acc=0.6715566422167889    f1 = 0.6770818011952662 \n",
      "dc with max_depth=('gini', 25):    acc=0.6744091279543603    f1 = 0.679649344531598 \n",
      "dc with max_depth=('gini', 26):    acc=0.6748166259168704    f1 = 0.6799494639733196 \n",
      "dc with max_depth=('gini', 27):    acc=0.6784841075794621    f1 = 0.6839449927496534 \n",
      "dc with max_depth=('gini', 28):    acc=0.6752241238793806    f1 = 0.6809760666255283 \n",
      "dc with max_depth=('gini', 29):    acc=0.6699266503667481    f1 = 0.6750781705653163 \n",
      "dc with max_depth=('gini', 30):    acc=0.6735941320293398    f1 = 0.678513145805968 \n",
      "dc with max_depth=('gini', 31):    acc=0.6744091279543603    f1 = 0.6790191821494097 \n",
      "dc with max_depth=('gini', 32):    acc=0.6735941320293398    f1 = 0.678913112060965 \n",
      "dc with max_depth=('gini', 33):    acc=0.676039119804401    f1 = 0.6819786538053729 \n",
      "dc with max_depth=('gini', 34):    acc=0.6764466177669112    f1 = 0.6809927530722085 \n",
      "dc with max_depth=('gini', 35):    acc=0.6731866340668297    f1 = 0.6799494382608815 \n",
      "dc with max_depth=('gini', 36):    acc=0.6764466177669112    f1 = 0.681625119016097 \n",
      "dc with max_depth=('gini', 37):    acc=0.6748166259168704    f1 = 0.6799438559361313 \n",
      "dc with max_depth=('gini', 38):    acc=0.6740016299918501    f1 = 0.6799492862156278 \n",
      "dc with max_depth=('gini', 39):    acc=0.6715566422167889    f1 = 0.6773142752168015 \n",
      "dc with max_depth=('entropy', 5):    acc=0.40097799511002447    f1 = 0.3676606121169403 \n",
      "dc with max_depth=('entropy', 6):    acc=0.4849225753871231    f1 = 0.4814792455503332 \n",
      "dc with max_depth=('entropy', 7):    acc=0.541157294213529    f1 = 0.5491551792344423 \n",
      "dc with max_depth=('entropy', 8):    acc=0.5794621026894865    f1 = 0.5855680045729131 \n",
      "dc with max_depth=('entropy', 9):    acc=0.6059494702526488    f1 = 0.6160740474438282 \n",
      "dc with max_depth=('entropy', 10):    acc=0.6356968215158925    f1 = 0.6428973223224322 \n",
      "dc with max_depth=('entropy', 11):    acc=0.6556642216788916    f1 = 0.6633720660587031 \n",
      "dc with max_depth=('entropy', 12):    acc=0.6703341483292583    f1 = 0.6745137988081453 \n",
      "dc with max_depth=('entropy', 13):    acc=0.6650366748166259    f1 = 0.6730751842904499 \n",
      "dc with max_depth=('entropy', 14):    acc=0.684596577017115    f1 = 0.6892871879726727 \n",
      "dc with max_depth=('entropy', 15):    acc=0.6788916055419723    f1 = 0.6835812087636061 \n",
      "dc with max_depth=('entropy', 16):    acc=0.6813365933170334    f1 = 0.6869090373507417 \n",
      "dc with max_depth=('entropy', 17):    acc=0.6809290953545232    f1 = 0.6856271742965612 \n",
      "dc with max_depth=('entropy', 18):    acc=0.6752241238793806    f1 = 0.6813677287907022 \n",
      "dc with max_depth=('entropy', 19):    acc=0.6841890790546047    f1 = 0.6902806125458024 \n",
      "dc with max_depth=('entropy', 20):    acc=0.6833740831295844    f1 = 0.6895831168115555 \n",
      "dc with max_depth=('entropy', 21):    acc=0.6780766096169519    f1 = 0.6841615615108823 \n",
      "dc with max_depth=('entropy', 22):    acc=0.6825590872045639    f1 = 0.688055940790128 \n",
      "dc with max_depth=('entropy', 23):    acc=0.6837815810920945    f1 = 0.6899952791330687 \n",
      "dc with max_depth=('entropy', 24):    acc=0.6862265688671557    f1 = 0.6911219585417244 \n",
      "dc with max_depth=('entropy', 25):    acc=0.6898940505297474    f1 = 0.6945989514287191 \n",
      "dc with max_depth=('entropy', 26):    acc=0.6809290953545232    f1 = 0.6875404836857614 \n",
      "dc with max_depth=('entropy', 27):    acc=0.6809290953545232    f1 = 0.6863967165761127 \n",
      "dc with max_depth=('entropy', 28):    acc=0.6772616136919315    f1 = 0.6824118621409001 \n",
      "dc with max_depth=('entropy', 29):    acc=0.6817440912795436    f1 = 0.6867127444751376 \n",
      "dc with max_depth=('entropy', 30):    acc=0.6817440912795436    f1 = 0.6875724707605654 \n",
      "dc with max_depth=('entropy', 31):    acc=0.6825590872045639    f1 = 0.6878987087918756 \n",
      "dc with max_depth=('entropy', 32):    acc=0.6866340668296659    f1 = 0.6916779472859972 \n",
      "dc with max_depth=('entropy', 33):    acc=0.6788916055419723    f1 = 0.6841461408790073 \n",
      "dc with max_depth=('entropy', 34):    acc=0.6821515892420538    f1 = 0.6875316171669226 \n",
      "dc with max_depth=('entropy', 35):    acc=0.6858190709046454    f1 = 0.6918834866267931 \n",
      "dc with max_depth=('entropy', 36):    acc=0.6813365933170334    f1 = 0.6874312468983378 \n",
      "dc with max_depth=('entropy', 37):    acc=0.6772616136919315    f1 = 0.683443188453631 \n",
      "dc with max_depth=('entropy', 38):    acc=0.6878565607171964    f1 = 0.6930948082302781 \n",
      "dc with max_depth=('entropy', 39):    acc=0.6813365933170334    f1 = 0.6863005014481499 \n"
     ]
    }
   ],
   "source": [
    "results_dc = defaultdict(list)\n",
    "for c in ['gini', 'entropy']:\n",
    "    for depth in range(5, 40):\n",
    "        decision_tree = tree.DecisionTreeClassifier(max_depth=depth, criterion=c)\n",
    "        decision_tree.fit(X_train_pca_res, y_train_pca_res)\n",
    "        prediction = decision_tree.predict(X_test_pca)\n",
    "\n",
    "        results_dc[(c, depth)].append(accuracy_score(y_test, prediction))\n",
    "        results_dc[(c, depth)].append(f1_score(y_test, prediction, average='weighted'))\n",
    "        results_dc[(c, depth)].append(classification_report(y_test, prediction))\n",
    "        results_dc[(c, depth)].append(create_confusion_matrix(y_test, prediction))\n",
    "print(f'max f1:{max(results_dc, key=lambda x: results_dc[x][1])}\\n')\n",
    "\n",
    "for k, v in results_dc.items():\n",
    "    print(f\"dc with max_depth={k}:    acc={v[0]}    f1 = {v[1]} \")        \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.26      0.38      0.31        47\n",
      "                         Baby Foods       0.59      0.56      0.58       112\n",
      "                     Baked Products       0.84      0.71      0.77       229\n",
      "                      Beef Products       0.90      0.83      0.86       286\n",
      "                          Beverages       0.59      0.60      0.60        90\n",
      "                  Breakfast Cereals       0.82      0.77      0.79       115\n",
      "            Cereal Grains and Pasta       0.68      0.78      0.73        50\n",
      "             Dairy and Egg Products       0.61      0.66      0.63        86\n",
      "                         Fast Foods       0.67      0.64      0.65       114\n",
      "                      Fats and Oils       0.89      0.91      0.90        55\n",
      "     Finfish and Shellfish Products       0.66      0.73      0.69        70\n",
      "            Fruits and Fruit Juices       0.60      0.59      0.59        87\n",
      "      Lamb, Veal, and Game Products       0.53      0.66      0.59       106\n",
      "        Legumes and Legume Products       0.79      0.69      0.74       108\n",
      "    Meals, Entrees, and Side Dishes       0.53      0.53      0.53        34\n",
      "              Nut and Seed Products       0.69      0.79      0.73        47\n",
      "                      Pork Products       0.70      0.61      0.65        99\n",
      "                   Poultry Products       0.66      0.62      0.64       111\n",
      "                   Restaurant Foods       0.39      0.66      0.49        32\n",
      "        Sausages and Luncheon Meats       0.62      0.61      0.61        71\n",
      "                             Snacks       0.47      0.59      0.52        39\n",
      "         Soups, Sauces, and Gravies       0.66      0.66      0.66       118\n",
      "                   Spices and Herbs       0.38      0.54      0.45        24\n",
      "                             Sweets       0.74      0.58      0.65        97\n",
      "  Vegetables and Vegetable Products       0.78      0.82      0.80       227\n",
      "\n",
      "                          micro avg       0.69      0.69      0.69      2454\n",
      "                          macro avg       0.64      0.66      0.65      2454\n",
      "                       weighted avg       0.71      0.69      0.69      2454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(results_dc[('entropy', 25)][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marian/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/marian/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/marian/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/marian/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/marian/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/marian/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max f1:('entropy', 26)\n",
      "\n",
      "dc with max_depth=('gini', 5):    acc=0.3215158924205379    f1 = 0.2840713099106443 \n",
      "dc with max_depth=('gini', 6):    acc=0.44947025264873675    f1 = 0.455317760207429 \n",
      "dc with max_depth=('gini', 7):    acc=0.5154849225753871    f1 = 0.5215922890683822 \n",
      "dc with max_depth=('gini', 8):    acc=0.5493072534637327    f1 = 0.551603110773019 \n",
      "dc with max_depth=('gini', 9):    acc=0.5819070904645477    f1 = 0.5865350329110495 \n",
      "dc with max_depth=('gini', 10):    acc=0.6096169519152405    f1 = 0.6212141551838052 \n",
      "dc with max_depth=('gini', 11):    acc=0.612876935615322    f1 = 0.6261476833431956 \n",
      "dc with max_depth=('gini', 12):    acc=0.6332518337408313    f1 = 0.6416803860557583 \n",
      "dc with max_depth=('gini', 13):    acc=0.649959250203749    f1 = 0.6568793825494981 \n",
      "dc with max_depth=('gini', 14):    acc=0.6397718011409943    f1 = 0.6464327826042419 \n",
      "dc with max_depth=('gini', 15):    acc=0.6495517522412388    f1 = 0.6549263904549955 \n",
      "dc with max_depth=('gini', 16):    acc=0.6528117359413202    f1 = 0.6569162002318859 \n",
      "dc with max_depth=('gini', 17):    acc=0.6605541972290139    f1 = 0.6639412454730788 \n",
      "dc with max_depth=('gini', 18):    acc=0.6621841890790546    f1 = 0.6668725331276452 \n",
      "dc with max_depth=('gini', 19):    acc=0.6642216788916055    f1 = 0.668603988957282 \n",
      "dc with max_depth=('gini', 20):    acc=0.6642216788916055    f1 = 0.6696334409087725 \n",
      "dc with max_depth=('gini', 21):    acc=0.6674816625916871    f1 = 0.6717213677115664 \n",
      "dc with max_depth=('gini', 22):    acc=0.6674816625916871    f1 = 0.6716442682069127 \n",
      "dc with max_depth=('gini', 23):    acc=0.6658516707416463    f1 = 0.6712894120081526 \n",
      "dc with max_depth=('gini', 24):    acc=0.6674816625916871    f1 = 0.6716315365442544 \n",
      "dc with max_depth=('gini', 25):    acc=0.6662591687041565    f1 = 0.670564248476098 \n",
      "dc with max_depth=('gini', 26):    acc=0.6703341483292583    f1 = 0.6743792101156995 \n",
      "dc with max_depth=('gini', 27):    acc=0.669519152404238    f1 = 0.6746172017257223 \n",
      "dc with max_depth=('gini', 28):    acc=0.6707416462917686    f1 = 0.6763851135586457 \n",
      "dc with max_depth=('gini', 29):    acc=0.6662591687041565    f1 = 0.6716603704382722 \n",
      "dc with max_depth=('gini', 30):    acc=0.6735941320293398    f1 = 0.6784327617815381 \n",
      "dc with max_depth=('gini', 31):    acc=0.6719641401792991    f1 = 0.6768073560182246 \n",
      "dc with max_depth=('gini', 32):    acc=0.6650366748166259    f1 = 0.6701835686615727 \n",
      "dc with max_depth=('gini', 33):    acc=0.6642216788916055    f1 = 0.6699281381680238 \n",
      "dc with max_depth=('gini', 34):    acc=0.6707416462917686    f1 = 0.6750972131217657 \n",
      "dc with max_depth=('gini', 35):    acc=0.6699266503667481    f1 = 0.6750906765552133 \n",
      "dc with max_depth=('gini', 36):    acc=0.6674816625916871    f1 = 0.6723817844257641 \n",
      "dc with max_depth=('gini', 37):    acc=0.6662591687041565    f1 = 0.670929024692102 \n",
      "dc with max_depth=('gini', 38):    acc=0.6691116544417278    f1 = 0.6742473036393299 \n",
      "dc with max_depth=('gini', 39):    acc=0.6723716381418093    f1 = 0.6767348052048542 \n",
      "dc with max_depth=('entropy', 5):    acc=0.4127954360228199    f1 = 0.40645318839962913 \n",
      "dc with max_depth=('entropy', 6):    acc=0.4873675631621842    f1 = 0.49657186324531527 \n",
      "dc with max_depth=('entropy', 7):    acc=0.5281173594132029    f1 = 0.5415453312510182 \n",
      "dc with max_depth=('entropy', 8):    acc=0.5823145884270579    f1 = 0.5973957673716189 \n",
      "dc with max_depth=('entropy', 9):    acc=0.5945395273023635    f1 = 0.6043451487226799 \n",
      "dc with max_depth=('entropy', 10):    acc=0.6206193969030155    f1 = 0.6288524840833043 \n",
      "dc with max_depth=('entropy', 11):    acc=0.6397718011409943    f1 = 0.6487847151081009 \n",
      "dc with max_depth=('entropy', 12):    acc=0.6515892420537898    f1 = 0.6620011866040926 \n",
      "dc with max_depth=('entropy', 13):    acc=0.6768541157294213    f1 = 0.6833430155689261 \n",
      "dc with max_depth=('entropy', 14):    acc=0.6744091279543603    f1 = 0.681825442599718 \n",
      "dc with max_depth=('entropy', 15):    acc=0.6682966585167074    f1 = 0.6772009099384688 \n",
      "dc with max_depth=('entropy', 16):    acc=0.6687041564792175    f1 = 0.6768075323715117 \n",
      "dc with max_depth=('entropy', 17):    acc=0.6670741646291769    f1 = 0.6737584390510433 \n",
      "dc with max_depth=('entropy', 18):    acc=0.6744091279543603    f1 = 0.6813230802789225 \n",
      "dc with max_depth=('entropy', 19):    acc=0.6784841075794621    f1 = 0.6866138404305545 \n",
      "dc with max_depth=('entropy', 20):    acc=0.6788916055419723    f1 = 0.6865359993473369 \n",
      "dc with max_depth=('entropy', 21):    acc=0.6780766096169519    f1 = 0.6856635495285555 \n",
      "dc with max_depth=('entropy', 22):    acc=0.6780766096169519    f1 = 0.6859999821793936 \n",
      "dc with max_depth=('entropy', 23):    acc=0.6666666666666666    f1 = 0.6741882661169345 \n",
      "dc with max_depth=('entropy', 24):    acc=0.6756316218418907    f1 = 0.6845319463746357 \n",
      "dc with max_depth=('entropy', 25):    acc=0.6699266503667481    f1 = 0.6776642602080439 \n",
      "dc with max_depth=('entropy', 26):    acc=0.6813365933170334    f1 = 0.688396757854945 \n",
      "dc with max_depth=('entropy', 27):    acc=0.6764466177669112    f1 = 0.6831761712396127 \n",
      "dc with max_depth=('entropy', 28):    acc=0.6670741646291769    f1 = 0.6749378043064873 \n",
      "dc with max_depth=('entropy', 29):    acc=0.6707416462917686    f1 = 0.6788691171427025 \n",
      "dc with max_depth=('entropy', 30):    acc=0.6711491442542787    f1 = 0.6790737314928261 \n",
      "dc with max_depth=('entropy', 31):    acc=0.6752241238793806    f1 = 0.6832361122743794 \n",
      "dc with max_depth=('entropy', 32):    acc=0.6699266503667481    f1 = 0.6782526696210183 \n",
      "dc with max_depth=('entropy', 33):    acc=0.6707416462917686    f1 = 0.6776294403621768 \n",
      "dc with max_depth=('entropy', 34):    acc=0.6723716381418093    f1 = 0.6789771075803347 \n",
      "dc with max_depth=('entropy', 35):    acc=0.6711491442542787    f1 = 0.6786241082663897 \n",
      "dc with max_depth=('entropy', 36):    acc=0.6699266503667481    f1 = 0.6768670310979544 \n",
      "dc with max_depth=('entropy', 37):    acc=0.6768541157294213    f1 = 0.6846635915282211 \n",
      "dc with max_depth=('entropy', 38):    acc=0.6735941320293398    f1 = 0.681282474926038 \n",
      "dc with max_depth=('entropy', 39):    acc=0.6780766096169519    f1 = 0.6851254004341061 \n"
     ]
    }
   ],
   "source": [
    "results_dc = defaultdict(list)\n",
    "for c in ['gini', 'entropy']:\n",
    "    for depth in range(5, 40):\n",
    "        decision_tree = tree.DecisionTreeClassifier(max_depth=depth, criterion=c)\n",
    "        decision_tree.fit(X_train_lda_res, y_train_lda_res)\n",
    "        prediction = decision_tree.predict(X_test_lda)\n",
    "\n",
    "        results_dc[(c, depth)].append(accuracy_score(y_test, prediction))\n",
    "        results_dc[(c, depth)].append(f1_score(y_test, prediction, average='weighted'))\n",
    "        results_dc[(c, depth)].append(classification_report(y_test, prediction))\n",
    "        results_dc[(c, depth)].append(create_confusion_matrix(y_test, prediction))\n",
    "print(f'max f1:{max(results_dc, key=lambda x: results_dc[x][1])}\\n')\n",
    "\n",
    "for k, v in results_dc.items():\n",
    "    print(f\"dc with max_depth={k}:    acc={v[0]}    f1 = {v[1]} \")      \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.14      0.23      0.18        47\n",
      "                         Baby Foods       0.61      0.57      0.59       112\n",
      "                     Baked Products       0.85      0.72      0.78       229\n",
      "                      Beef Products       0.91      0.86      0.88       286\n",
      "                          Beverages       0.54      0.63      0.58        90\n",
      "                  Breakfast Cereals       0.83      0.83      0.83       115\n",
      "            Cereal Grains and Pasta       0.54      0.64      0.59        50\n",
      "             Dairy and Egg Products       0.77      0.69      0.72        86\n",
      "                         Fast Foods       0.62      0.62      0.62       114\n",
      "                      Fats and Oils       0.83      0.91      0.87        55\n",
      "     Finfish and Shellfish Products       0.61      0.61      0.61        70\n",
      "            Fruits and Fruit Juices       0.61      0.62      0.61        87\n",
      "      Lamb, Veal, and Game Products       0.57      0.69      0.63       106\n",
      "        Legumes and Legume Products       0.71      0.60      0.65       108\n",
      "    Meals, Entrees, and Side Dishes       0.30      0.38      0.33        34\n",
      "              Nut and Seed Products       0.75      0.77      0.76        47\n",
      "                      Pork Products       0.82      0.74      0.78        99\n",
      "                   Poultry Products       0.62      0.62      0.62       111\n",
      "                   Restaurant Foods       0.33      0.44      0.38        32\n",
      "        Sausages and Luncheon Meats       0.61      0.65      0.63        71\n",
      "                             Snacks       0.48      0.54      0.51        39\n",
      "         Soups, Sauces, and Gravies       0.60      0.57      0.58       118\n",
      "                   Spices and Herbs       0.50      0.67      0.57        24\n",
      "                             Sweets       0.71      0.67      0.69        97\n",
      "  Vegetables and Vegetable Products       0.80      0.73      0.76       227\n",
      "\n",
      "                          micro avg       0.68      0.68      0.68      2454\n",
      "                          macro avg       0.63      0.64      0.63      2454\n",
      "                       weighted avg       0.70      0.68      0.69      2454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(results_dc[('entropy', 26)][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes accuracy: 0.4649551752241239\n",
      "                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.35      0.17      0.23        47\n",
      "                         Baby Foods       0.16      0.03      0.05       112\n",
      "                     Baked Products       0.82      0.64      0.72       229\n",
      "                      Beef Products       0.77      0.70      0.73       286\n",
      "                          Beverages       0.57      0.04      0.08        90\n",
      "                  Breakfast Cereals       0.77      0.65      0.70       115\n",
      "            Cereal Grains and Pasta       0.27      0.62      0.37        50\n",
      "             Dairy and Egg Products       0.68      0.50      0.58        86\n",
      "                         Fast Foods       0.69      0.59      0.64       114\n",
      "                      Fats and Oils       0.38      0.87      0.52        55\n",
      "     Finfish and Shellfish Products       0.81      0.54      0.65        70\n",
      "            Fruits and Fruit Juices       0.25      0.83      0.38        87\n",
      "      Lamb, Veal, and Game Products       0.55      0.34      0.42       106\n",
      "        Legumes and Legume Products       0.89      0.16      0.27       108\n",
      "    Meals, Entrees, and Side Dishes       0.14      0.26      0.18        34\n",
      "              Nut and Seed Products       0.44      0.77      0.56        47\n",
      "                      Pork Products       0.28      0.87      0.42        99\n",
      "                   Poultry Products       0.62      0.14      0.22       111\n",
      "                   Restaurant Foods       0.42      0.69      0.52        32\n",
      "        Sausages and Luncheon Meats       0.48      0.31      0.38        71\n",
      "                             Snacks       0.12      0.13      0.13        39\n",
      "         Soups, Sauces, and Gravies       0.22      0.44      0.29       118\n",
      "                   Spices and Herbs       0.48      0.58      0.53        24\n",
      "                             Sweets       0.43      0.35      0.39        97\n",
      "  Vegetables and Vegetable Products       0.72      0.25      0.37       227\n",
      "\n",
      "                          micro avg       0.46      0.46      0.46      2454\n",
      "                          macro avg       0.49      0.46      0.41      2454\n",
      "                       weighted avg       0.57      0.46      0.46      2454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "naive_bayes.fit(X_train_res, y_train_res)\n",
    "pred = naive_bayes.predict(X_test)\n",
    "print(f\"naive bayes accuracy: {accuracy_score(y_test, pred)}\")\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "#again, American/Indian foods with considerably low scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes accuracy: 0.38264058679706603\n",
      "                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.24      0.09      0.12        47\n",
      "                         Baby Foods       0.00      0.00      0.00       112\n",
      "                     Baked Products       0.87      0.61      0.72       229\n",
      "                      Beef Products       0.66      0.39      0.49       286\n",
      "                          Beverages       0.25      0.01      0.02        90\n",
      "                  Breakfast Cereals       0.75      0.67      0.71       115\n",
      "            Cereal Grains and Pasta       0.27      0.58      0.37        50\n",
      "             Dairy and Egg Products       0.77      0.35      0.48        86\n",
      "                         Fast Foods       0.64      0.46      0.53       114\n",
      "                      Fats and Oils       0.66      0.84      0.74        55\n",
      "     Finfish and Shellfish Products       0.64      0.56      0.60        70\n",
      "            Fruits and Fruit Juices       0.32      0.38      0.35        87\n",
      "      Lamb, Veal, and Game Products       0.14      0.02      0.03       106\n",
      "        Legumes and Legume Products       0.44      0.06      0.11       108\n",
      "    Meals, Entrees, and Side Dishes       0.11      0.26      0.16        34\n",
      "              Nut and Seed Products       0.66      0.66      0.66        47\n",
      "                      Pork Products       0.20      0.72      0.31        99\n",
      "                   Poultry Products       0.21      0.06      0.10       111\n",
      "                   Restaurant Foods       0.16      0.31      0.21        32\n",
      "        Sausages and Luncheon Meats       0.37      0.61      0.46        71\n",
      "                             Snacks       0.28      0.26      0.27        39\n",
      "         Soups, Sauces, and Gravies       0.18      0.80      0.29       118\n",
      "                   Spices and Herbs       0.25      0.58      0.35        24\n",
      "                             Sweets       0.56      0.49      0.52        97\n",
      "  Vegetables and Vegetable Products       0.35      0.14      0.20       227\n",
      "\n",
      "                          micro avg       0.38      0.38      0.38      2454\n",
      "                          macro avg       0.40      0.40      0.35      2454\n",
      "                       weighted avg       0.45      0.38      0.37      2454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_bayes = GaussianNB()\n",
    "naive_bayes.fit(X_train_pca_res, y_train_pca_res)\n",
    "pred = naive_bayes.predict(X_test_pca)\n",
    "print(f\"naive bayes accuracy: {accuracy_score(y_test, pred)}\")\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes accuracy: 0.4242053789731051\n",
      "                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.31      0.21      0.25        47\n",
      "                         Baby Foods       0.00      0.00      0.00       112\n",
      "                     Baked Products       0.85      0.57      0.68       229\n",
      "                      Beef Products       0.85      0.59      0.70       286\n",
      "                          Beverages       0.00      0.00      0.00        90\n",
      "                  Breakfast Cereals       0.74      0.56      0.64       115\n",
      "            Cereal Grains and Pasta       0.28      0.58      0.38        50\n",
      "             Dairy and Egg Products       0.80      0.43      0.56        86\n",
      "                         Fast Foods       0.64      0.34      0.45       114\n",
      "                      Fats and Oils       0.62      0.85      0.72        55\n",
      "     Finfish and Shellfish Products       0.52      0.49      0.50        70\n",
      "            Fruits and Fruit Juices       0.32      0.24      0.27        87\n",
      "      Lamb, Veal, and Game Products       0.39      0.65      0.49       106\n",
      "        Legumes and Legume Products       0.50      0.10      0.17       108\n",
      "    Meals, Entrees, and Side Dishes       0.08      0.26      0.12        34\n",
      "              Nut and Seed Products       0.52      0.72      0.61        47\n",
      "                      Pork Products       0.40      0.56      0.46        99\n",
      "                   Poultry Products       0.17      0.07      0.10       111\n",
      "                   Restaurant Foods       0.16      0.41      0.23        32\n",
      "        Sausages and Luncheon Meats       0.41      0.63      0.50        71\n",
      "                             Snacks       0.31      0.38      0.34        39\n",
      "         Soups, Sauces, and Gravies       0.19      0.86      0.32       118\n",
      "                   Spices and Herbs       0.43      0.62      0.51        24\n",
      "                             Sweets       0.49      0.44      0.46        97\n",
      "  Vegetables and Vegetable Products       0.47      0.19      0.27       227\n",
      "\n",
      "                          micro avg       0.42      0.42      0.42      2454\n",
      "                          macro avg       0.42      0.43      0.39      2454\n",
      "                       weighted avg       0.49      0.42      0.42      2454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_bayes = GaussianNB()\n",
    "naive_bayes.fit(X_train_lda_res, y_train_lda_res)\n",
    "pred = naive_bayes.predict(X_test_lda)\n",
    "print(f\"naive bayes accuracy: {accuracy_score(y_test, pred)}\")\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "np.random.seed(seed)\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 0\n",
    "def model1():\n",
    "    print(num_nodes)\n",
    "    model = Sequential()\n",
    "    #22 input nodes, 24 hidden nodes\n",
    "    model.add(Dense(num_nodes, input_dim=22, activation='relu'))\n",
    "    model.add(Dense(num_nodes, input_dim=num_nodes, activation='relu'))\n",
    "    #25 output nodes\n",
    "    model.add(Dense(25, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "num_nodes = 0\n",
    "def model2():\n",
    "    print(num_nodes)\n",
    "    model = Sequential()\n",
    "    #22 input nodes, 24 hidden nodes\n",
    "    model.add(Dense(num_nodes, input_dim=8, activation='relu'))\n",
    "    model.add(Dense(num_nodes, input_dim=num_nodes, activation='relu'))\n",
    "    #25 output nodes\n",
    "    model.add(Dense(25, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "num_nodes = 0\n",
    "def model3():\n",
    "    print(num_nodes)\n",
    "    model = Sequential()\n",
    "    #22 input nodes, 24 hidden nodes\n",
    "    model.add(Dense(num_nodes, input_dim=8, activation='relu'))\n",
    "    model.add(Dense(num_nodes, input_dim=num_nodes, activation='relu'))\n",
    "    #25 output nodes\n",
    "    model.add(Dense(25, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Epoch 1/50\n",
      "15800/15800 [==============================] - 15s 918us/step - loss: 2.3658 - acc: 0.2794\n",
      "Epoch 2/50\n",
      "15800/15800 [==============================] - 10s 639us/step - loss: 1.8933 - acc: 0.4330\n",
      "Epoch 3/50\n",
      "15800/15800 [==============================] - 13s 830us/step - loss: 1.7278 - acc: 0.4783\n",
      "Epoch 4/50\n",
      "15800/15800 [==============================] - 9s 600us/step - loss: 1.6090 - acc: 0.5122\n",
      "Epoch 5/50\n",
      "15800/15800 [==============================] - 12s 777us/step - loss: 1.5230 - acc: 0.5369\n",
      "Epoch 6/50\n",
      "15800/15800 [==============================] - 11s 704us/step - loss: 1.4546 - acc: 0.5625\n",
      "Epoch 7/50\n",
      "15800/15800 [==============================] - 13s 795us/step - loss: 1.3975 - acc: 0.5846\n",
      "Epoch 8/50\n",
      "15800/15800 [==============================] - 12s 770us/step - loss: 1.3482 - acc: 0.5961\n",
      "Epoch 9/50\n",
      "15800/15800 [==============================] - 11s 717us/step - loss: 1.3036 - acc: 0.6085\n",
      "Epoch 10/50\n",
      "15800/15800 [==============================] - 11s 679us/step - loss: 1.2615 - acc: 0.6248\n",
      "Epoch 11/50\n",
      "15800/15800 [==============================] - 10s 628us/step - loss: 1.2250 - acc: 0.6289\n",
      "Epoch 12/50\n",
      "15800/15800 [==============================] - 10s 640us/step - loss: 1.1914 - acc: 0.6394\n",
      "Epoch 13/50\n",
      "15800/15800 [==============================] - 10s 636us/step - loss: 1.1628 - acc: 0.6487\n",
      "Epoch 14/50\n",
      "15800/15800 [==============================] - 11s 676us/step - loss: 1.1378 - acc: 0.6550\n",
      "Epoch 15/50\n",
      "15800/15800 [==============================] - 13s 819us/step - loss: 1.1131 - acc: 0.6651\n",
      "Epoch 16/50\n",
      "15800/15800 [==============================] - 11s 712us/step - loss: 1.0934 - acc: 0.6676\n",
      "Epoch 17/50\n",
      "15800/15800 [==============================] - 14s 862us/step - loss: 1.0747 - acc: 0.6735\n",
      "Epoch 18/50\n",
      "15800/15800 [==============================] - 14s 877us/step - loss: 1.0576 - acc: 0.6782\n",
      "Epoch 19/50\n",
      "15800/15800 [==============================] - 14s 883us/step - loss: 1.0419 - acc: 0.6822\n",
      "Epoch 20/50\n",
      "15800/15800 [==============================] - 14s 882us/step - loss: 1.0289 - acc: 0.6904\n",
      "Epoch 21/50\n",
      "15800/15800 [==============================] - 14s 902us/step - loss: 1.0148 - acc: 0.6939\n",
      "Epoch 22/50\n",
      "15800/15800 [==============================] - 13s 835us/step - loss: 1.0016 - acc: 0.7005\n",
      "Epoch 23/50\n",
      "15800/15800 [==============================] - 14s 866us/step - loss: 0.9884 - acc: 0.7004\n",
      "Epoch 24/50\n",
      "15800/15800 [==============================] - 13s 831us/step - loss: 0.9753 - acc: 0.7073\n",
      "Epoch 25/50\n",
      "15800/15800 [==============================] - 15s 928us/step - loss: 0.9620 - acc: 0.7119\n",
      "Epoch 26/50\n",
      "15800/15800 [==============================] - 15s 920us/step - loss: 0.9511 - acc: 0.7128\n",
      "Epoch 27/50\n",
      "15800/15800 [==============================] - 14s 884us/step - loss: 0.9396 - acc: 0.7161\n",
      "Epoch 28/50\n",
      "15800/15800 [==============================] - 13s 852us/step - loss: 0.9298 - acc: 0.7216\n",
      "Epoch 29/50\n",
      "15800/15800 [==============================] - 14s 860us/step - loss: 0.9191 - acc: 0.7220\n",
      "Epoch 30/50\n",
      "15800/15800 [==============================] - 14s 862us/step - loss: 0.9084 - acc: 0.7272\n",
      "Epoch 31/50\n",
      "15800/15800 [==============================] - 14s 876us/step - loss: 0.9007 - acc: 0.7304\n",
      "Epoch 32/50\n",
      "15800/15800 [==============================] - 14s 866us/step - loss: 0.8935 - acc: 0.7308\n",
      "Epoch 33/50\n",
      "15800/15800 [==============================] - 15s 953us/step - loss: 0.8823 - acc: 0.7356\n",
      "Epoch 34/50\n",
      "15800/15800 [==============================] - 15s 971us/step - loss: 0.8779 - acc: 0.7358\n",
      "Epoch 35/50\n",
      "15800/15800 [==============================] - 11s 668us/step - loss: 0.8694 - acc: 0.7381\n",
      "Epoch 36/50\n",
      "15800/15800 [==============================] - 14s 881us/step - loss: 0.8632 - acc: 0.7419\n",
      "Epoch 37/50\n",
      "15800/15800 [==============================] - 12s 736us/step - loss: 0.8551 - acc: 0.7420\n",
      "Epoch 38/50\n",
      "15800/15800 [==============================] - 10s 644us/step - loss: 0.8495 - acc: 0.7441\n",
      "Epoch 39/50\n",
      "15800/15800 [==============================] - 11s 666us/step - loss: 0.8429 - acc: 0.7480\n",
      "Epoch 40/50\n",
      "15800/15800 [==============================] - 10s 614us/step - loss: 0.8373 - acc: 0.7492\n",
      "Epoch 41/50\n",
      "15800/15800 [==============================] - 10s 627us/step - loss: 0.8339 - acc: 0.7508\n",
      "Epoch 42/50\n",
      "15800/15800 [==============================] - 10s 640us/step - loss: 0.8255 - acc: 0.7538\n",
      "Epoch 43/50\n",
      "15800/15800 [==============================] - 10s 664us/step - loss: 0.8205 - acc: 0.7549\n",
      "Epoch 44/50\n",
      "15800/15800 [==============================] - 10s 660us/step - loss: 0.8164 - acc: 0.7547\n",
      "Epoch 45/50\n",
      "15800/15800 [==============================] - 11s 682us/step - loss: 0.8108 - acc: 0.7584\n",
      "Epoch 46/50\n",
      "15800/15800 [==============================] - 11s 684us/step - loss: 0.8061 - acc: 0.7593\n",
      "Epoch 47/50\n",
      "15800/15800 [==============================] - 10s 609us/step - loss: 0.8032 - acc: 0.7591\n",
      "Epoch 48/50\n",
      "15800/15800 [==============================] - 10s 631us/step - loss: 0.8004 - acc: 0.7622\n",
      "Epoch 49/50\n",
      "15800/15800 [==============================] - 12s 777us/step - loss: 0.7946 - acc: 0.7604\n",
      "Epoch 50/50\n",
      "15800/15800 [==============================] - 10s 662us/step - loss: 0.7906 - acc: 0.7629\n",
      "2454/2454 [==============================] - 1s 542us/step\n",
      "32\n",
      "Epoch 1/50\n",
      "15800/15800 [==============================] - 13s 805us/step - loss: 2.1387 - acc: 0.3477\n",
      "Epoch 2/50\n",
      "15800/15800 [==============================] - 11s 712us/step - loss: 1.6465 - acc: 0.4990\n",
      "Epoch 3/50\n",
      "15800/15800 [==============================] - 11s 711us/step - loss: 1.4486 - acc: 0.5648\n",
      "Epoch 4/50\n",
      "15800/15800 [==============================] - 10s 618us/step - loss: 1.3356 - acc: 0.6009\n",
      "Epoch 5/50\n",
      "15800/15800 [==============================] - 11s 716us/step - loss: 1.2568 - acc: 0.6315\n",
      "Epoch 6/50\n",
      "15800/15800 [==============================] - 14s 899us/step - loss: 1.1928 - acc: 0.6501\n",
      "Epoch 7/50\n",
      "15800/15800 [==============================] - 15s 919us/step - loss: 1.1410 - acc: 0.6630\n",
      "Epoch 8/50\n",
      "15800/15800 [==============================] - 10s 624us/step - loss: 1.0937 - acc: 0.6764\n",
      "Epoch 9/50\n",
      "15800/15800 [==============================] - 11s 719us/step - loss: 1.0539 - acc: 0.6880\n",
      "Epoch 10/50\n",
      "15800/15800 [==============================] - 13s 821us/step - loss: 1.0167 - acc: 0.6961\n",
      "Epoch 11/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.9827 - acc: 0.7077\n",
      "Epoch 12/50\n",
      "15800/15800 [==============================] - 12s 755us/step - loss: 0.9522 - acc: 0.7156\n",
      "Epoch 13/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.9232 - acc: 0.7251\n",
      "Epoch 14/50\n",
      "15800/15800 [==============================] - 11s 723us/step - loss: 0.8980 - acc: 0.7320\n",
      "Epoch 15/50\n",
      "15800/15800 [==============================] - 11s 695us/step - loss: 0.8761 - acc: 0.7381\n",
      "Epoch 16/50\n",
      "15800/15800 [==============================] - 12s 762us/step - loss: 0.8557 - acc: 0.7453\n",
      "Epoch 17/50\n",
      "15800/15800 [==============================] - 16s 988us/step - loss: 0.8355 - acc: 0.7491\n",
      "Epoch 18/50\n",
      "15800/15800 [==============================] - 12s 782us/step - loss: 0.8161 - acc: 0.7556\n",
      "Epoch 19/50\n",
      "15800/15800 [==============================] - 16s 991us/step - loss: 0.8002 - acc: 0.7577\n",
      "Epoch 20/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.7849 - acc: 0.7615\n",
      "Epoch 21/50\n",
      "15800/15800 [==============================] - 15s 977us/step - loss: 0.7705 - acc: 0.7653\n",
      "Epoch 22/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.7576 - acc: 0.7682\n",
      "Epoch 23/50\n",
      "15800/15800 [==============================] - 15s 938us/step - loss: 0.7453 - acc: 0.7720\n",
      "Epoch 24/50\n",
      "15800/15800 [==============================] - 13s 828us/step - loss: 0.7311 - acc: 0.7765\n",
      "Epoch 25/50\n",
      "15800/15800 [==============================] - 14s 867us/step - loss: 0.7228 - acc: 0.7803\n",
      "Epoch 26/50\n",
      "15800/15800 [==============================] - 13s 801us/step - loss: 0.7098 - acc: 0.7824\n",
      "Epoch 27/50\n",
      "15800/15800 [==============================] - 11s 702us/step - loss: 0.7003 - acc: 0.7828\n",
      "Epoch 28/50\n",
      "15800/15800 [==============================] - 14s 906us/step - loss: 0.6910 - acc: 0.7864\n",
      "Epoch 29/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.6812 - acc: 0.7920\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15800/15800 [==============================] - 11s 718us/step - loss: 0.6708 - acc: 0.7951\n",
      "Epoch 31/50\n",
      "15800/15800 [==============================] - 11s 697us/step - loss: 0.6655 - acc: 0.7951\n",
      "Epoch 32/50\n",
      "15800/15800 [==============================] - 12s 763us/step - loss: 0.6584 - acc: 0.7956\n",
      "Epoch 33/50\n",
      "15800/15800 [==============================] - 12s 781us/step - loss: 0.6477 - acc: 0.7992\n",
      "Epoch 34/50\n",
      "15800/15800 [==============================] - 11s 686us/step - loss: 0.6437 - acc: 0.7990\n",
      "Epoch 35/50\n",
      "15800/15800 [==============================] - 14s 901us/step - loss: 0.6367 - acc: 0.8025\n",
      "Epoch 36/50\n",
      "15800/15800 [==============================] - 12s 753us/step - loss: 0.6244 - acc: 0.8065\n",
      "Epoch 37/50\n",
      "15800/15800 [==============================] - 12s 739us/step - loss: 0.6197 - acc: 0.8066\n",
      "Epoch 38/50\n",
      "15800/15800 [==============================] - 12s 772us/step - loss: 0.6148 - acc: 0.8095\n",
      "Epoch 39/50\n",
      "15800/15800 [==============================] - 10s 662us/step - loss: 0.6089 - acc: 0.8104\n",
      "Epoch 40/50\n",
      "15800/15800 [==============================] - 11s 685us/step - loss: 0.6027 - acc: 0.8143\n",
      "Epoch 41/50\n",
      "15800/15800 [==============================] - 12s 733us/step - loss: 0.5988 - acc: 0.8131\n",
      "Epoch 42/50\n",
      "15800/15800 [==============================] - 11s 712us/step - loss: 0.5905 - acc: 0.8153\n",
      "Epoch 43/50\n",
      "15800/15800 [==============================] - 11s 676us/step - loss: 0.5857 - acc: 0.8193\n",
      "Epoch 44/50\n",
      "15800/15800 [==============================] - 10s 633us/step - loss: 0.5782 - acc: 0.8199\n",
      "Epoch 45/50\n",
      "15800/15800 [==============================] - 12s 728us/step - loss: 0.5743 - acc: 0.8213\n",
      "Epoch 46/50\n",
      "15800/15800 [==============================] - 11s 725us/step - loss: 0.5702 - acc: 0.8211\n",
      "Epoch 47/50\n",
      "15800/15800 [==============================] - 11s 692us/step - loss: 0.5640 - acc: 0.8239\n",
      "Epoch 48/50\n",
      "15800/15800 [==============================] - 12s 739us/step - loss: 0.5575 - acc: 0.8244\n",
      "Epoch 49/50\n",
      "15800/15800 [==============================] - 11s 703us/step - loss: 0.5571 - acc: 0.8259\n",
      "Epoch 50/50\n",
      "15800/15800 [==============================] - 13s 851us/step - loss: 0.5495 - acc: 0.8291\n",
      "2454/2454 [==============================] - 1s 500us/step\n",
      "48\n",
      "Epoch 1/50\n",
      "15800/15800 [==============================] - 13s 815us/step - loss: 2.0400 - acc: 0.3861\n",
      "Epoch 2/50\n",
      "15800/15800 [==============================] - 10s 648us/step - loss: 1.5790 - acc: 0.5141\n",
      "Epoch 3/50\n",
      "15800/15800 [==============================] - 11s 720us/step - loss: 1.3992 - acc: 0.5716\n",
      "Epoch 4/50\n",
      "15800/15800 [==============================] - 13s 805us/step - loss: 1.2801 - acc: 0.6116\n",
      "Epoch 5/50\n",
      "15800/15800 [==============================] - 12s 757us/step - loss: 1.1811 - acc: 0.6505\n",
      "Epoch 6/50\n",
      "15800/15800 [==============================] - 12s 755us/step - loss: 1.1030 - acc: 0.6740\n",
      "Epoch 7/50\n",
      "15800/15800 [==============================] - 11s 679us/step - loss: 1.0424 - acc: 0.6898\n",
      "Epoch 8/50\n",
      "15800/15800 [==============================] - 10s 606us/step - loss: 0.9900 - acc: 0.7034\n",
      "Epoch 9/50\n",
      "15800/15800 [==============================] - 12s 729us/step - loss: 0.9445 - acc: 0.7207\n",
      "Epoch 10/50\n",
      "15800/15800 [==============================] - 11s 724us/step - loss: 0.9091 - acc: 0.7301\n",
      "Epoch 11/50\n",
      "15800/15800 [==============================] - 13s 801us/step - loss: 0.8758 - acc: 0.7382\n",
      "Epoch 12/50\n",
      "15800/15800 [==============================] - 10s 644us/step - loss: 0.8468 - acc: 0.7444\n",
      "Epoch 13/50\n",
      "15800/15800 [==============================] - 10s 626us/step - loss: 0.8191 - acc: 0.7525\n",
      "Epoch 14/50\n",
      "15800/15800 [==============================] - 9s 599us/step - loss: 0.7959 - acc: 0.7606\n",
      "Epoch 15/50\n",
      "15800/15800 [==============================] - 9s 590us/step - loss: 0.7707 - acc: 0.7672\n",
      "Epoch 16/50\n",
      "15800/15800 [==============================] - 10s 602us/step - loss: 0.7494 - acc: 0.7711\n",
      "Epoch 17/50\n",
      "15800/15800 [==============================] - 11s 689us/step - loss: 0.7297 - acc: 0.7791\n",
      "Epoch 18/50\n",
      "15800/15800 [==============================] - 10s 631us/step - loss: 0.7107 - acc: 0.7846\n",
      "Epoch 19/50\n",
      "15800/15800 [==============================] - 11s 715us/step - loss: 0.6929 - acc: 0.7861\n",
      "Epoch 20/50\n",
      "15800/15800 [==============================] - 12s 775us/step - loss: 0.6763 - acc: 0.7944\n",
      "Epoch 21/50\n",
      "15800/15800 [==============================] - 13s 813us/step - loss: 0.6627 - acc: 0.7967\n",
      "Epoch 22/50\n",
      "15800/15800 [==============================] - 11s 705us/step - loss: 0.6456 - acc: 0.8046\n",
      "Epoch 23/50\n",
      "15800/15800 [==============================] - 11s 699us/step - loss: 0.6329 - acc: 0.8056\n",
      "Epoch 24/50\n",
      "15800/15800 [==============================] - 12s 768us/step - loss: 0.6215 - acc: 0.8098\n",
      "Epoch 25/50\n",
      "15800/15800 [==============================] - 11s 683us/step - loss: 0.6035 - acc: 0.8129\n",
      "Epoch 26/50\n",
      "15800/15800 [==============================] - 12s 735us/step - loss: 0.5983 - acc: 0.8153\n",
      "Epoch 27/50\n",
      "15800/15800 [==============================] - 10s 639us/step - loss: 0.5827 - acc: 0.8209\n",
      "Epoch 28/50\n",
      "15800/15800 [==============================] - 13s 792us/step - loss: 0.5740 - acc: 0.8256\n",
      "Epoch 29/50\n",
      "15800/15800 [==============================] - 11s 681us/step - loss: 0.5599 - acc: 0.8302\n",
      "Epoch 30/50\n",
      "15800/15800 [==============================] - 10s 635us/step - loss: 0.5521 - acc: 0.8308\n",
      "Epoch 31/50\n",
      "15800/15800 [==============================] - 11s 687us/step - loss: 0.5448 - acc: 0.8322\n",
      "Epoch 32/50\n",
      "15800/15800 [==============================] - 12s 760us/step - loss: 0.5344 - acc: 0.8359\n",
      "Epoch 33/50\n",
      "15800/15800 [==============================] - 13s 825us/step - loss: 0.5254 - acc: 0.8383\n",
      "Epoch 34/50\n",
      "15800/15800 [==============================] - 11s 700us/step - loss: 0.5164 - acc: 0.8439\n",
      "Epoch 35/50\n",
      "15800/15800 [==============================] - 11s 707us/step - loss: 0.5093 - acc: 0.8431\n",
      "Epoch 36/50\n",
      "15800/15800 [==============================] - 12s 776us/step - loss: 0.4999 - acc: 0.8472\n",
      "Epoch 37/50\n",
      "15800/15800 [==============================] - 13s 799us/step - loss: 0.4923 - acc: 0.8480\n",
      "Epoch 38/50\n",
      "15800/15800 [==============================] - 11s 722us/step - loss: 0.4838 - acc: 0.8559\n",
      "Epoch 39/50\n",
      "15800/15800 [==============================] - 12s 775us/step - loss: 0.4780 - acc: 0.8536\n",
      "Epoch 40/50\n",
      "15800/15800 [==============================] - 10s 664us/step - loss: 0.4718 - acc: 0.8570\n",
      "Epoch 41/50\n",
      "15800/15800 [==============================] - 11s 699us/step - loss: 0.4639 - acc: 0.8591\n",
      "Epoch 42/50\n",
      "15800/15800 [==============================] - 11s 706us/step - loss: 0.4570 - acc: 0.8608\n",
      "Epoch 43/50\n",
      "15800/15800 [==============================] - 11s 667us/step - loss: 0.4502 - acc: 0.8620\n",
      "Epoch 44/50\n",
      "15800/15800 [==============================] - 10s 626us/step - loss: 0.4444 - acc: 0.8673\n",
      "Epoch 45/50\n",
      "15800/15800 [==============================] - 13s 805us/step - loss: 0.4378 - acc: 0.8678\n",
      "Epoch 46/50\n",
      "15800/15800 [==============================] - 10s 664us/step - loss: 0.4313 - acc: 0.8681\n",
      "Epoch 47/50\n",
      "15800/15800 [==============================] - 11s 668us/step - loss: 0.4236 - acc: 0.8689\n",
      "Epoch 48/50\n",
      "15800/15800 [==============================] - 11s 704us/step - loss: 0.4198 - acc: 0.8720\n",
      "Epoch 49/50\n",
      "15800/15800 [==============================] - 10s 648us/step - loss: 0.4129 - acc: 0.8748\n",
      "Epoch 50/50\n",
      "15800/15800 [==============================] - 13s 793us/step - loss: 0.4131 - acc: 0.8747\n",
      "2454/2454 [==============================] - 2s 782us/step\n",
      "64\n",
      "Epoch 1/50\n",
      "15800/15800 [==============================] - 13s 796us/step - loss: 2.0176 - acc: 0.3863\n",
      "Epoch 2/50\n",
      "15800/15800 [==============================] - 10s 625us/step - loss: 1.5280 - acc: 0.5329\n",
      "Epoch 3/50\n",
      "15800/15800 [==============================] - 9s 600us/step - loss: 1.3272 - acc: 0.5997\n",
      "Epoch 4/50\n",
      "15800/15800 [==============================] - 10s 664us/step - loss: 1.2015 - acc: 0.6432\n",
      "Epoch 5/50\n",
      "15800/15800 [==============================] - 10s 618us/step - loss: 1.1117 - acc: 0.6638\n",
      "Epoch 6/50\n",
      "15800/15800 [==============================] - 11s 680us/step - loss: 1.0414 - acc: 0.6849\n",
      "Epoch 7/50\n",
      "15800/15800 [==============================] - 10s 621us/step - loss: 0.9772 - acc: 0.7078\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15800/15800 [==============================] - 10s 651us/step - loss: 0.9281 - acc: 0.7185\n",
      "Epoch 9/50\n",
      "15800/15800 [==============================] - 10s 635us/step - loss: 0.8795 - acc: 0.7370\n",
      "Epoch 10/50\n",
      "15800/15800 [==============================] - 13s 795us/step - loss: 0.8386 - acc: 0.7430\n",
      "Epoch 11/50\n",
      "15800/15800 [==============================] - 12s 749us/step - loss: 0.7989 - acc: 0.7577\n",
      "Epoch 12/50\n",
      "15800/15800 [==============================] - 13s 817us/step - loss: 0.7670 - acc: 0.7656\n",
      "Epoch 13/50\n",
      "15800/15800 [==============================] - 11s 698us/step - loss: 0.7319 - acc: 0.7767\n",
      "Epoch 14/50\n",
      "15800/15800 [==============================] - 10s 622us/step - loss: 0.7050 - acc: 0.7818\n",
      "Epoch 15/50\n",
      "15800/15800 [==============================] - 11s 686us/step - loss: 0.6776 - acc: 0.7903\n",
      "Epoch 16/50\n",
      "15800/15800 [==============================] - 10s 640us/step - loss: 0.6550 - acc: 0.7953\n",
      "Epoch 17/50\n",
      "15800/15800 [==============================] - 12s 765us/step - loss: 0.6348 - acc: 0.8002\n",
      "Epoch 18/50\n",
      "15800/15800 [==============================] - 10s 643us/step - loss: 0.6141 - acc: 0.8082\n",
      "Epoch 19/50\n",
      "15800/15800 [==============================] - 13s 817us/step - loss: 0.5928 - acc: 0.8154\n",
      "Epoch 20/50\n",
      "15800/15800 [==============================] - 12s 771us/step - loss: 0.5774 - acc: 0.8203\n",
      "Epoch 21/50\n",
      "15800/15800 [==============================] - 12s 766us/step - loss: 0.5614 - acc: 0.8232\n",
      "Epoch 22/50\n",
      "15800/15800 [==============================] - 12s 730us/step - loss: 0.5461 - acc: 0.8275\n",
      "Epoch 23/50\n",
      "15800/15800 [==============================] - 12s 742us/step - loss: 0.5297 - acc: 0.8337\n",
      "Epoch 24/50\n",
      "15800/15800 [==============================] - 12s 774us/step - loss: 0.5183 - acc: 0.8373\n",
      "Epoch 25/50\n",
      "15800/15800 [==============================] - 11s 675us/step - loss: 0.5036 - acc: 0.8396\n",
      "Epoch 26/50\n",
      "15800/15800 [==============================] - 12s 761us/step - loss: 0.4922 - acc: 0.8454\n",
      "Epoch 27/50\n",
      "15800/15800 [==============================] - 12s 767us/step - loss: 0.4797 - acc: 0.8470\n",
      "Epoch 28/50\n",
      "15800/15800 [==============================] - 12s 747us/step - loss: 0.4646 - acc: 0.8511\n",
      "Epoch 29/50\n",
      "15800/15800 [==============================] - 11s 696us/step - loss: 0.4580 - acc: 0.8537\n",
      "Epoch 30/50\n",
      "15800/15800 [==============================] - 10s 623us/step - loss: 0.4453 - acc: 0.8578\n",
      "Epoch 31/50\n",
      "15800/15800 [==============================] - 12s 740us/step - loss: 0.4354 - acc: 0.8612\n",
      "Epoch 32/50\n",
      "15800/15800 [==============================] - 11s 726us/step - loss: 0.4249 - acc: 0.8658\n",
      "Epoch 33/50\n",
      "15800/15800 [==============================] - 11s 722us/step - loss: 0.4208 - acc: 0.8659\n",
      "Epoch 34/50\n",
      "15800/15800 [==============================] - 11s 720us/step - loss: 0.4099 - acc: 0.8702\n",
      "Epoch 35/50\n",
      "15800/15800 [==============================] - 11s 687us/step - loss: 0.3987 - acc: 0.8717\n",
      "Epoch 36/50\n",
      "15800/15800 [==============================] - 11s 670us/step - loss: 0.3909 - acc: 0.8750\n",
      "Epoch 37/50\n",
      "15800/15800 [==============================] - 13s 793us/step - loss: 0.3855 - acc: 0.8794\n",
      "Epoch 38/50\n",
      "15800/15800 [==============================] - 11s 706us/step - loss: 0.3763 - acc: 0.8808\n",
      "Epoch 39/50\n",
      "15800/15800 [==============================] - 11s 721us/step - loss: 0.3698 - acc: 0.8839\n",
      "Epoch 40/50\n",
      "15800/15800 [==============================] - 13s 802us/step - loss: 0.3599 - acc: 0.8873\n",
      "Epoch 41/50\n",
      "15800/15800 [==============================] - 11s 726us/step - loss: 0.3534 - acc: 0.8892\n",
      "Epoch 42/50\n",
      "15800/15800 [==============================] - 12s 742us/step - loss: 0.3513 - acc: 0.8897\n",
      "Epoch 43/50\n",
      "15800/15800 [==============================] - 11s 722us/step - loss: 0.3409 - acc: 0.8938\n",
      "Epoch 44/50\n",
      "15800/15800 [==============================] - 10s 632us/step - loss: 0.3406 - acc: 0.8935\n",
      "Epoch 45/50\n",
      "15800/15800 [==============================] - 11s 677us/step - loss: 0.3311 - acc: 0.8963\n",
      "Epoch 46/50\n",
      "15800/15800 [==============================] - 12s 770us/step - loss: 0.3257 - acc: 0.8960\n",
      "Epoch 47/50\n",
      "15800/15800 [==============================] - 11s 706us/step - loss: 0.3195 - acc: 0.8973\n",
      "Epoch 48/50\n",
      "15800/15800 [==============================] - 12s 735us/step - loss: 0.3137 - acc: 0.9006\n",
      "Epoch 49/50\n",
      "15800/15800 [==============================] - 15s 924us/step - loss: 0.3102 - acc: 0.9041\n",
      "Epoch 50/50\n",
      "15800/15800 [==============================] - 13s 813us/step - loss: 0.3030 - acc: 0.9049\n",
      "2454/2454 [==============================] - 2s 1ms/step\n",
      "80\n",
      "Epoch 1/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 1.9357 - acc: 0.4069\n",
      "Epoch 2/50\n",
      "15800/15800 [==============================] - 11s 705us/step - loss: 1.4230 - acc: 0.5611\n",
      "Epoch 3/50\n",
      "15800/15800 [==============================] - 13s 798us/step - loss: 1.2249 - acc: 0.6292\n",
      "Epoch 4/50\n",
      "15800/15800 [==============================] - 11s 703us/step - loss: 1.0952 - acc: 0.6716\n",
      "Epoch 5/50\n",
      "15800/15800 [==============================] - 11s 678us/step - loss: 1.0040 - acc: 0.7018\n",
      "Epoch 6/50\n",
      "15800/15800 [==============================] - 14s 862us/step - loss: 0.9331 - acc: 0.7215\n",
      "Epoch 7/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.8723 - acc: 0.7398\n",
      "Epoch 8/50\n",
      "15800/15800 [==============================] - 11s 703us/step - loss: 0.8254 - acc: 0.7543\n",
      "Epoch 9/50\n",
      "15800/15800 [==============================] - 11s 670us/step - loss: 0.7836 - acc: 0.7680\n",
      "Epoch 10/50\n",
      "15800/15800 [==============================] - 14s 873us/step - loss: 0.7426 - acc: 0.7787\n",
      "Epoch 11/50\n",
      "15800/15800 [==============================] - 11s 714us/step - loss: 0.7058 - acc: 0.7868\n",
      "Epoch 12/50\n",
      "15800/15800 [==============================] - 11s 678us/step - loss: 0.6760 - acc: 0.7937\n",
      "Epoch 13/50\n",
      "15800/15800 [==============================] - 12s 774us/step - loss: 0.6460 - acc: 0.8047\n",
      "Epoch 14/50\n",
      "15800/15800 [==============================] - 12s 736us/step - loss: 0.6185 - acc: 0.8085\n",
      "Epoch 15/50\n",
      "15800/15800 [==============================] - 11s 689us/step - loss: 0.5935 - acc: 0.8172\n",
      "Epoch 16/50\n",
      "15800/15800 [==============================] - 10s 650us/step - loss: 0.5714 - acc: 0.8251\n",
      "Epoch 17/50\n",
      "15800/15800 [==============================] - 10s 643us/step - loss: 0.5497 - acc: 0.8297\n",
      "Epoch 18/50\n",
      "15800/15800 [==============================] - 10s 635us/step - loss: 0.5310 - acc: 0.8366\n",
      "Epoch 19/50\n",
      "15800/15800 [==============================] - 11s 684us/step - loss: 0.5124 - acc: 0.8424\n",
      "Epoch 20/50\n",
      "15800/15800 [==============================] - 11s 699us/step - loss: 0.4936 - acc: 0.8423\n",
      "Epoch 21/50\n",
      "15800/15800 [==============================] - 11s 682us/step - loss: 0.4772 - acc: 0.8528\n",
      "Epoch 22/50\n",
      "15800/15800 [==============================] - 11s 684us/step - loss: 0.4659 - acc: 0.8547\n",
      "Epoch 23/50\n",
      "15800/15800 [==============================] - 10s 660us/step - loss: 0.4459 - acc: 0.8594\n",
      "Epoch 24/50\n",
      "15800/15800 [==============================] - 10s 652us/step - loss: 0.4319 - acc: 0.8631\n",
      "Epoch 25/50\n",
      "15800/15800 [==============================] - 10s 641us/step - loss: 0.4181 - acc: 0.8709\n",
      "Epoch 26/50\n",
      "15800/15800 [==============================] - 10s 663us/step - loss: 0.4072 - acc: 0.8720\n",
      "Epoch 27/50\n",
      "15800/15800 [==============================] - 11s 682us/step - loss: 0.3978 - acc: 0.8758\n",
      "Epoch 28/50\n",
      "15800/15800 [==============================] - 10s 626us/step - loss: 0.3862 - acc: 0.8786\n",
      "Epoch 29/50\n",
      "15800/15800 [==============================] - 10s 618us/step - loss: 0.3745 - acc: 0.8830\n",
      "Epoch 30/50\n",
      "15800/15800 [==============================] - 10s 662us/step - loss: 0.3653 - acc: 0.8862\n",
      "Epoch 31/50\n",
      "15800/15800 [==============================] - 10s 627us/step - loss: 0.3543 - acc: 0.8913\n",
      "Epoch 32/50\n",
      "15800/15800 [==============================] - 11s 699us/step - loss: 0.3481 - acc: 0.8896\n",
      "Epoch 33/50\n",
      "15800/15800 [==============================] - 10s 640us/step - loss: 0.3379 - acc: 0.8943\n",
      "Epoch 34/50\n",
      "15800/15800 [==============================] - 10s 622us/step - loss: 0.3306 - acc: 0.8971\n",
      "Epoch 35/50\n",
      "15800/15800 [==============================] - 10s 654us/step - loss: 0.3250 - acc: 0.8979\n",
      "Epoch 36/50\n",
      "15800/15800 [==============================] - 10s 601us/step - loss: 0.3162 - acc: 0.9006\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15800/15800 [==============================] - 10s 615us/step - loss: 0.3096 - acc: 0.9033\n",
      "Epoch 38/50\n",
      "15800/15800 [==============================] - 10s 640us/step - loss: 0.3013 - acc: 0.9062\n",
      "Epoch 39/50\n",
      "15800/15800 [==============================] - 10s 660us/step - loss: 0.2987 - acc: 0.9068\n",
      "Epoch 40/50\n",
      "15800/15800 [==============================] - 11s 671us/step - loss: 0.2942 - acc: 0.9072\n",
      "Epoch 41/50\n",
      "15800/15800 [==============================] - 10s 661us/step - loss: 0.2824 - acc: 0.9118\n",
      "Epoch 42/50\n",
      "15800/15800 [==============================] - 10s 635us/step - loss: 0.2813 - acc: 0.9083\n",
      "Epoch 43/50\n",
      "15800/15800 [==============================] - 11s 715us/step - loss: 0.2740 - acc: 0.9140\n",
      "Epoch 44/50\n",
      "15800/15800 [==============================] - 11s 679us/step - loss: 0.2701 - acc: 0.9165\n",
      "Epoch 45/50\n",
      "15800/15800 [==============================] - 11s 669us/step - loss: 0.2637 - acc: 0.9177\n",
      "Epoch 46/50\n",
      "15800/15800 [==============================] - 10s 621us/step - loss: 0.2584 - acc: 0.9194\n",
      "Epoch 47/50\n",
      "15800/15800 [==============================] - 12s 761us/step - loss: 0.2556 - acc: 0.9182\n",
      "Epoch 48/50\n",
      "15800/15800 [==============================] - 11s 666us/step - loss: 0.2511 - acc: 0.9211\n",
      "Epoch 49/50\n",
      "15800/15800 [==============================] - 10s 655us/step - loss: 0.2422 - acc: 0.9226\n",
      "Epoch 50/50\n",
      "15800/15800 [==============================] - 11s 686us/step - loss: 0.2411 - acc: 0.9241\n",
      "2454/2454 [==============================] - 1s 551us/step\n",
      "96\n",
      "Epoch 1/50\n",
      "15800/15800 [==============================] - 15s 919us/step - loss: 1.8687 - acc: 0.4262\n",
      "Epoch 2/50\n",
      "15800/15800 [==============================] - 13s 800us/step - loss: 1.3688 - acc: 0.5763\n",
      "Epoch 3/50\n",
      "15800/15800 [==============================] - 11s 672us/step - loss: 1.1782 - acc: 0.6378\n",
      "Epoch 4/50\n",
      "15800/15800 [==============================] - 11s 710us/step - loss: 1.0605 - acc: 0.6715\n",
      "Epoch 5/50\n",
      "15800/15800 [==============================] - 11s 666us/step - loss: 0.9755 - acc: 0.6984\n",
      "Epoch 6/50\n",
      "15800/15800 [==============================] - 13s 824us/step - loss: 0.8998 - acc: 0.7232\n",
      "Epoch 7/50\n",
      "15800/15800 [==============================] - 15s 933us/step - loss: 0.8364 - acc: 0.7431\n",
      "Epoch 8/50\n",
      "15800/15800 [==============================] - 11s 677us/step - loss: 0.7800 - acc: 0.7605\n",
      "Epoch 9/50\n",
      "15800/15800 [==============================] - 11s 704us/step - loss: 0.7288 - acc: 0.7739\n",
      "Epoch 10/50\n",
      "15800/15800 [==============================] - 12s 739us/step - loss: 0.6855 - acc: 0.7883\n",
      "Epoch 11/50\n",
      "15800/15800 [==============================] - 11s 711us/step - loss: 0.6486 - acc: 0.7956\n",
      "Epoch 12/50\n",
      "15800/15800 [==============================] - 11s 705us/step - loss: 0.6147 - acc: 0.8089\n",
      "Epoch 13/50\n",
      "15800/15800 [==============================] - 12s 756us/step - loss: 0.5860 - acc: 0.8168\n",
      "Epoch 14/50\n",
      "15800/15800 [==============================] - 12s 768us/step - loss: 0.5589 - acc: 0.8233\n",
      "Epoch 15/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.5348 - acc: 0.8316\n",
      "Epoch 16/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.5112 - acc: 0.8416\n",
      "Epoch 17/50\n",
      "15800/15800 [==============================] - 14s 857us/step - loss: 0.4896 - acc: 0.8469\n",
      "Epoch 18/50\n",
      "15800/15800 [==============================] - 14s 880us/step - loss: 0.4718 - acc: 0.8513\n",
      "Epoch 19/50\n",
      "15800/15800 [==============================] - 12s 767us/step - loss: 0.4558 - acc: 0.8568\n",
      "Epoch 20/50\n",
      "15800/15800 [==============================] - 12s 740us/step - loss: 0.4355 - acc: 0.8634\n",
      "Epoch 21/50\n",
      "15800/15800 [==============================] - 13s 839us/step - loss: 0.4219 - acc: 0.8672\n",
      "Epoch 22/50\n",
      "15800/15800 [==============================] - 13s 818us/step - loss: 0.4085 - acc: 0.8687\n",
      "Epoch 23/50\n",
      "15800/15800 [==============================] - 11s 708us/step - loss: 0.3919 - acc: 0.8755\n",
      "Epoch 24/50\n",
      "15800/15800 [==============================] - 15s 942us/step - loss: 0.3797 - acc: 0.8787\n",
      "Epoch 25/50\n",
      "15800/15800 [==============================] - 12s 756us/step - loss: 0.3650 - acc: 0.8848\n",
      "Epoch 26/50\n",
      "15800/15800 [==============================] - 13s 800us/step - loss: 0.3554 - acc: 0.8847\n",
      "Epoch 27/50\n",
      "15800/15800 [==============================] - 14s 868us/step - loss: 0.3415 - acc: 0.8904\n",
      "Epoch 28/50\n",
      "15800/15800 [==============================] - 12s 750us/step - loss: 0.3337 - acc: 0.8942\n",
      "Epoch 29/50\n",
      "15800/15800 [==============================] - 14s 862us/step - loss: 0.3215 - acc: 0.8978\n",
      "Epoch 30/50\n",
      "15800/15800 [==============================] - 13s 827us/step - loss: 0.3141 - acc: 0.8987\n",
      "Epoch 31/50\n",
      "15800/15800 [==============================] - 14s 905us/step - loss: 0.3070 - acc: 0.9037\n",
      "Epoch 32/50\n",
      "15800/15800 [==============================] - 14s 907us/step - loss: 0.2974 - acc: 0.9059\n",
      "Epoch 33/50\n",
      "15800/15800 [==============================] - 15s 971us/step - loss: 0.2880 - acc: 0.9088\n",
      "Epoch 34/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.2819 - acc: 0.9109\n",
      "Epoch 35/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.2736 - acc: 0.9108\n",
      "Epoch 36/50\n",
      "15800/15800 [==============================] - 12s 780us/step - loss: 0.2692 - acc: 0.9128\n",
      "Epoch 37/50\n",
      "15800/15800 [==============================] - 12s 764us/step - loss: 0.2591 - acc: 0.9165\n",
      "Epoch 38/50\n",
      "15800/15800 [==============================] - 12s 766us/step - loss: 0.2528 - acc: 0.9180\n",
      "Epoch 39/50\n",
      "15800/15800 [==============================] - 12s 789us/step - loss: 0.2489 - acc: 0.9232\n",
      "Epoch 40/50\n",
      "15800/15800 [==============================] - 13s 836us/step - loss: 0.2411 - acc: 0.9230\n",
      "Epoch 41/50\n",
      "15800/15800 [==============================] - 11s 697us/step - loss: 0.2385 - acc: 0.9239\n",
      "Epoch 42/50\n",
      "15800/15800 [==============================] - 12s 746us/step - loss: 0.2310 - acc: 0.9266\n",
      "Epoch 43/50\n",
      "15800/15800 [==============================] - 9s 588us/step - loss: 0.2274 - acc: 0.9283\n",
      "Epoch 44/50\n",
      "15800/15800 [==============================] - 11s 666us/step - loss: 0.2202 - acc: 0.9311\n",
      "Epoch 45/50\n",
      "15800/15800 [==============================] - 16s 997us/step - loss: 0.2162 - acc: 0.9328\n",
      "Epoch 46/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.2133 - acc: 0.9330\n",
      "Epoch 47/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.2064 - acc: 0.9337\n",
      "Epoch 48/50\n",
      "15800/15800 [==============================] - 13s 844us/step - loss: 0.2054 - acc: 0.9366\n",
      "Epoch 49/50\n",
      "15800/15800 [==============================] - 14s 888us/step - loss: 0.1982 - acc: 0.9389\n",
      "Epoch 50/50\n",
      "15800/15800 [==============================] - 14s 861us/step - loss: 0.1962 - acc: 0.9395\n",
      "2454/2454 [==============================] - 2s 667us/step\n",
      "112\n",
      "Epoch 1/50\n",
      "15800/15800 [==============================] - 16s 987us/step - loss: 1.8493 - acc: 0.4273\n",
      "Epoch 2/50\n",
      "15800/15800 [==============================] - 14s 913us/step - loss: 1.3586 - acc: 0.5798\n",
      "Epoch 3/50\n",
      "15800/15800 [==============================] - 15s 963us/step - loss: 1.1632 - acc: 0.6434\n",
      "Epoch 4/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 1.0369 - acc: 0.6791\n",
      "Epoch 5/50\n",
      "15800/15800 [==============================] - 14s 906us/step - loss: 0.9394 - acc: 0.7116\n",
      "Epoch 6/50\n",
      "15800/15800 [==============================] - 15s 970us/step - loss: 0.8587 - acc: 0.7397\n",
      "Epoch 7/50\n",
      "15800/15800 [==============================] - 15s 937us/step - loss: 0.7915 - acc: 0.7604\n",
      "Epoch 8/50\n",
      "15800/15800 [==============================] - 14s 911us/step - loss: 0.7348 - acc: 0.7775\n",
      "Epoch 9/50\n",
      "15800/15800 [==============================] - 14s 904us/step - loss: 0.6878 - acc: 0.7937\n",
      "Epoch 10/50\n",
      "15800/15800 [==============================] - 15s 975us/step - loss: 0.6497 - acc: 0.8028\n",
      "Epoch 11/50\n",
      "15800/15800 [==============================] - 15s 964us/step - loss: 0.6096 - acc: 0.8114\n",
      "Epoch 12/50\n",
      "15800/15800 [==============================] - 11s 679us/step - loss: 0.5757 - acc: 0.8202\n",
      "Epoch 13/50\n",
      "15800/15800 [==============================] - 11s 683us/step - loss: 0.5472 - acc: 0.8303\n",
      "Epoch 14/50\n",
      "15800/15800 [==============================] - 12s 747us/step - loss: 0.5218 - acc: 0.8358\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15800/15800 [==============================] - 11s 698us/step - loss: 0.4972 - acc: 0.8441\n",
      "Epoch 16/50\n",
      "15800/15800 [==============================] - 11s 668us/step - loss: 0.4725 - acc: 0.8523\n",
      "Epoch 17/50\n",
      "15800/15800 [==============================] - 11s 665us/step - loss: 0.4563 - acc: 0.8553\n",
      "Epoch 18/50\n",
      "15800/15800 [==============================] - 13s 828us/step - loss: 0.4363 - acc: 0.8613\n",
      "Epoch 19/50\n",
      "15800/15800 [==============================] - 16s 986us/step - loss: 0.4180 - acc: 0.8678\n",
      "Epoch 20/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.4016 - acc: 0.8746\n",
      "Epoch 21/50\n",
      "15800/15800 [==============================] - 15s 959us/step - loss: 0.3848 - acc: 0.8768\n",
      "Epoch 22/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.3749 - acc: 0.8825\n",
      "Epoch 23/50\n",
      "15800/15800 [==============================] - 16s 989us/step - loss: 0.3595 - acc: 0.8871\n",
      "Epoch 24/50\n",
      "15800/15800 [==============================] - 15s 948us/step - loss: 0.3486 - acc: 0.8910\n",
      "Epoch 25/50\n",
      "15800/15800 [==============================] - 16s 991us/step - loss: 0.3359 - acc: 0.8966\n",
      "Epoch 26/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.3277 - acc: 0.8945\n",
      "Epoch 27/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.3180 - acc: 0.8981\n",
      "Epoch 28/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.3069 - acc: 0.9026\n",
      "Epoch 29/50\n",
      "15800/15800 [==============================] - 22s 1ms/step - loss: 0.2996 - acc: 0.9052\n",
      "Epoch 30/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.2913 - acc: 0.9068\n",
      "Epoch 31/50\n",
      "15800/15800 [==============================] - 24s 2ms/step - loss: 0.2864 - acc: 0.9113\n",
      "Epoch 32/50\n",
      "15800/15800 [==============================] - 29s 2ms/step - loss: 0.2746 - acc: 0.9122\n",
      "Epoch 33/50\n",
      "15800/15800 [==============================] - 23s 1ms/step - loss: 0.2685 - acc: 0.9157\n",
      "Epoch 34/50\n",
      "15800/15800 [==============================] - 25s 2ms/step - loss: 0.2564 - acc: 0.9191\n",
      "Epoch 35/50\n",
      "15800/15800 [==============================] - 33s 2ms/step - loss: 0.2541 - acc: 0.9198\n",
      "Epoch 36/50\n",
      "15800/15800 [==============================] - 26s 2ms/step - loss: 0.2461 - acc: 0.9222\n",
      "Epoch 37/50\n",
      "15800/15800 [==============================] - 22s 1ms/step - loss: 0.2463 - acc: 0.9239\n",
      "Epoch 38/50\n",
      "15800/15800 [==============================] - 25s 2ms/step - loss: 0.2348 - acc: 0.9244\n",
      "Epoch 39/50\n",
      "15800/15800 [==============================] - 22s 1ms/step - loss: 0.2287 - acc: 0.9285\n",
      "Epoch 40/50\n",
      "15800/15800 [==============================] - 23s 1ms/step - loss: 0.2219 - acc: 0.9298\n",
      "Epoch 41/50\n",
      "15800/15800 [==============================] - 23s 1ms/step - loss: 0.2164 - acc: 0.9325\n",
      "Epoch 42/50\n",
      "15800/15800 [==============================] - 22s 1ms/step - loss: 0.2153 - acc: 0.9325\n",
      "Epoch 43/50\n",
      "15800/15800 [==============================] - 22s 1ms/step - loss: 0.2081 - acc: 0.9333\n",
      "Epoch 44/50\n",
      "15800/15800 [==============================] - 23s 1ms/step - loss: 0.2034 - acc: 0.9359\n",
      "Epoch 45/50\n",
      "15800/15800 [==============================] - 22s 1ms/step - loss: 0.2003 - acc: 0.9370\n",
      "Epoch 46/50\n",
      "15800/15800 [==============================] - 22s 1ms/step - loss: 0.1973 - acc: 0.9394\n",
      "Epoch 47/50\n",
      "15800/15800 [==============================] - 22s 1ms/step - loss: 0.1933 - acc: 0.9403\n",
      "Epoch 48/50\n",
      "15800/15800 [==============================] - 22s 1ms/step - loss: 0.1884 - acc: 0.9428\n",
      "Epoch 49/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.1858 - acc: 0.9416\n",
      "Epoch 50/50\n",
      "15800/15800 [==============================] - 26s 2ms/step - loss: 0.1788 - acc: 0.9429\n",
      "2454/2454 [==============================] - 3s 1ms/step\n",
      "128\n",
      "Epoch 1/50\n",
      "15800/15800 [==============================] - 28s 2ms/step - loss: 1.8400 - acc: 0.4201\n",
      "Epoch 2/50\n",
      "15800/15800 [==============================] - 27s 2ms/step - loss: 1.3188 - acc: 0.5860\n",
      "Epoch 3/50\n",
      "15800/15800 [==============================] - 28s 2ms/step - loss: 1.1183 - acc: 0.6545\n",
      "Epoch 4/50\n",
      "15800/15800 [==============================] - 24s 2ms/step - loss: 0.9899 - acc: 0.6915\n",
      "Epoch 5/50\n",
      "15800/15800 [==============================] - 23s 1ms/step - loss: 0.8956 - acc: 0.7260\n",
      "Epoch 6/50\n",
      "15800/15800 [==============================] - 26s 2ms/step - loss: 0.8141 - acc: 0.7526\n",
      "Epoch 7/50\n",
      "15800/15800 [==============================] - 28s 2ms/step - loss: 0.7482 - acc: 0.7718\n",
      "Epoch 8/50\n",
      "15800/15800 [==============================] - 31s 2ms/step - loss: 0.6974 - acc: 0.7847\n",
      "Epoch 9/50\n",
      "15800/15800 [==============================] - 31s 2ms/step - loss: 0.6485 - acc: 0.7984\n",
      "Epoch 10/50\n",
      "15800/15800 [==============================] - 37s 2ms/step - loss: 0.6080 - acc: 0.8100\n",
      "Epoch 11/50\n",
      "15800/15800 [==============================] - 32s 2ms/step - loss: 0.5727 - acc: 0.8193\n",
      "Epoch 12/50\n",
      "15800/15800 [==============================] - 22s 1ms/step - loss: 0.5401 - acc: 0.8300\n",
      "Epoch 13/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.5120 - acc: 0.8398\n",
      "Epoch 14/50\n",
      "15800/15800 [==============================] - 23s 1ms/step - loss: 0.4825 - acc: 0.8485\n",
      "Epoch 15/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.4594 - acc: 0.8527\n",
      "Epoch 16/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.4379 - acc: 0.8601\n",
      "Epoch 17/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.4220 - acc: 0.8654\n",
      "Epoch 18/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.3982 - acc: 0.8731\n",
      "Epoch 19/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.3829 - acc: 0.8773\n",
      "Epoch 20/50\n",
      "15800/15800 [==============================] - 28s 2ms/step - loss: 0.3637 - acc: 0.8830\n",
      "Epoch 21/50\n",
      "15800/15800 [==============================] - 24s 2ms/step - loss: 0.3537 - acc: 0.8872\n",
      "Epoch 22/50\n",
      "15800/15800 [==============================] - 26s 2ms/step - loss: 0.3387 - acc: 0.8928\n",
      "Epoch 23/50\n",
      "15800/15800 [==============================] - 25s 2ms/step - loss: 0.3226 - acc: 0.8977\n",
      "Epoch 24/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.3153 - acc: 0.9003\n",
      "Epoch 25/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.3001 - acc: 0.9016\n",
      "Epoch 26/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.2895 - acc: 0.9073\n",
      "Epoch 27/50\n",
      "15800/15800 [==============================] - 26s 2ms/step - loss: 0.2813 - acc: 0.9078\n",
      "Epoch 28/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.2730 - acc: 0.9118\n",
      "Epoch 29/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.2624 - acc: 0.9179\n",
      "Epoch 30/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.2553 - acc: 0.9178\n",
      "Epoch 31/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.2488 - acc: 0.9194\n",
      "Epoch 32/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.2405 - acc: 0.9228\n",
      "Epoch 33/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.2343 - acc: 0.9263\n",
      "Epoch 34/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.2314 - acc: 0.9257\n",
      "Epoch 35/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.2197 - acc: 0.9313\n",
      "Epoch 36/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.2175 - acc: 0.9311\n",
      "Epoch 37/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.2124 - acc: 0.9308\n",
      "Epoch 38/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.2051 - acc: 0.9359\n",
      "Epoch 39/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.2028 - acc: 0.9353\n",
      "Epoch 40/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.1969 - acc: 0.9356\n",
      "Epoch 41/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.1919 - acc: 0.9391\n",
      "Epoch 42/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.1882 - acc: 0.9400\n",
      "Epoch 43/50\n",
      "15800/15800 [==============================] - 25s 2ms/step - loss: 0.1778 - acc: 0.9436\n",
      "Epoch 44/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.1801 - acc: 0.9421\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.1739 - acc: 0.9445\n",
      "Epoch 46/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.1715 - acc: 0.9463\n",
      "Epoch 47/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.1639 - acc: 0.9486\n",
      "Epoch 48/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.1622 - acc: 0.9471\n",
      "Epoch 49/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.1589 - acc: 0.9486\n",
      "Epoch 50/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.1548 - acc: 0.9506\n",
      "2454/2454 [==============================] - 2s 982us/step\n",
      "144\n",
      "Epoch 1/50\n",
      "15800/15800 [==============================] - 24s 2ms/step - loss: 1.8063 - acc: 0.4354\n",
      "Epoch 2/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 1.2857 - acc: 0.5963\n",
      "Epoch 3/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 1.0922 - acc: 0.6613\n",
      "Epoch 4/50\n",
      "15800/15800 [==============================] - 22s 1ms/step - loss: 0.9713 - acc: 0.6970\n",
      "Epoch 5/50\n",
      "15800/15800 [==============================] - 22s 1ms/step - loss: 0.8748 - acc: 0.7335\n",
      "Epoch 6/50\n",
      "15800/15800 [==============================] - 22s 1ms/step - loss: 0.7954 - acc: 0.7560\n",
      "Epoch 7/50\n",
      "15800/15800 [==============================] - 22s 1ms/step - loss: 0.7262 - acc: 0.7790\n",
      "Epoch 8/50\n",
      "15800/15800 [==============================] - 22s 1ms/step - loss: 0.6705 - acc: 0.7959\n",
      "Epoch 9/50\n",
      "15800/15800 [==============================] - 25s 2ms/step - loss: 0.6250 - acc: 0.8066\n",
      "Epoch 10/50\n",
      "15800/15800 [==============================] - 27s 2ms/step - loss: 0.5834 - acc: 0.8199\n",
      "Epoch 11/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.5432 - acc: 0.8324\n",
      "Epoch 12/50\n",
      "15800/15800 [==============================] - 12s 747us/step - loss: 0.5143 - acc: 0.8391\n",
      "Epoch 13/50\n",
      "15800/15800 [==============================] - 15s 958us/step - loss: 0.4881 - acc: 0.8484\n",
      "Epoch 14/50\n",
      "15800/15800 [==============================] - 14s 872us/step - loss: 0.4621 - acc: 0.8560\n",
      "Epoch 15/50\n",
      "15800/15800 [==============================] - 11s 721us/step - loss: 0.4401 - acc: 0.8608\n",
      "Epoch 16/50\n",
      "15800/15800 [==============================] - 12s 729us/step - loss: 0.4183 - acc: 0.8675\n",
      "Epoch 17/50\n",
      "15800/15800 [==============================] - 12s 752us/step - loss: 0.3935 - acc: 0.8754\n",
      "Epoch 18/50\n",
      "15800/15800 [==============================] - 12s 778us/step - loss: 0.3791 - acc: 0.8804\n",
      "Epoch 19/50\n",
      "15800/15800 [==============================] - 12s 762us/step - loss: 0.3604 - acc: 0.8863\n",
      "Epoch 20/50\n",
      "15800/15800 [==============================] - 12s 768us/step - loss: 0.3458 - acc: 0.8898\n",
      "Epoch 21/50\n",
      "15800/15800 [==============================] - 12s 780us/step - loss: 0.3341 - acc: 0.8941\n",
      "Epoch 22/50\n",
      "15800/15800 [==============================] - 12s 760us/step - loss: 0.3213 - acc: 0.8997\n",
      "Epoch 23/50\n",
      "15800/15800 [==============================] - 13s 826us/step - loss: 0.3082 - acc: 0.9021\n",
      "Epoch 24/50\n",
      "15800/15800 [==============================] - 11s 714us/step - loss: 0.2947 - acc: 0.9052\n",
      "Epoch 25/50\n",
      "15800/15800 [==============================] - 11s 698us/step - loss: 0.2846 - acc: 0.9121\n",
      "Epoch 26/50\n",
      "15800/15800 [==============================] - 11s 703us/step - loss: 0.2777 - acc: 0.9131\n",
      "Epoch 27/50\n",
      "15800/15800 [==============================] - 11s 694us/step - loss: 0.2651 - acc: 0.9153\n",
      "Epoch 28/50\n",
      "15800/15800 [==============================] - 12s 774us/step - loss: 0.2564 - acc: 0.9203\n",
      "Epoch 29/50\n",
      "15800/15800 [==============================] - 13s 826us/step - loss: 0.2477 - acc: 0.9227\n",
      "Epoch 30/50\n",
      "15800/15800 [==============================] - 12s 760us/step - loss: 0.2432 - acc: 0.9215\n",
      "Epoch 31/50\n",
      "15800/15800 [==============================] - 12s 735us/step - loss: 0.2326 - acc: 0.9260\n",
      "Epoch 32/50\n",
      "15800/15800 [==============================] - 12s 761us/step - loss: 0.2287 - acc: 0.9277\n",
      "Epoch 33/50\n",
      "15800/15800 [==============================] - 12s 769us/step - loss: 0.2196 - acc: 0.9278\n",
      "Epoch 34/50\n",
      "15800/15800 [==============================] - 11s 720us/step - loss: 0.2161 - acc: 0.9315\n",
      "Epoch 35/50\n",
      "15800/15800 [==============================] - 11s 686us/step - loss: 0.2084 - acc: 0.9354\n",
      "Epoch 36/50\n",
      "15800/15800 [==============================] - 11s 709us/step - loss: 0.2043 - acc: 0.9344\n",
      "Epoch 37/50\n",
      "15800/15800 [==============================] - 12s 762us/step - loss: 0.1968 - acc: 0.9379\n",
      "Epoch 38/50\n",
      "15800/15800 [==============================] - 12s 744us/step - loss: 0.1930 - acc: 0.9387\n",
      "Epoch 39/50\n",
      "15800/15800 [==============================] - 12s 740us/step - loss: 0.1824 - acc: 0.9432\n",
      "Epoch 40/50\n",
      "15800/15800 [==============================] - 12s 747us/step - loss: 0.1842 - acc: 0.9426\n",
      "Epoch 41/50\n",
      "15800/15800 [==============================] - 12s 752us/step - loss: 0.1744 - acc: 0.9463\n",
      "Epoch 42/50\n",
      "15800/15800 [==============================] - 12s 759us/step - loss: 0.1722 - acc: 0.9453\n",
      "Epoch 43/50\n",
      "15800/15800 [==============================] - 12s 775us/step - loss: 0.1688 - acc: 0.9487\n",
      "Epoch 44/50\n",
      "15800/15800 [==============================] - 12s 770us/step - loss: 0.1651 - acc: 0.9494\n",
      "Epoch 45/50\n",
      "15800/15800 [==============================] - 12s 768us/step - loss: 0.1647 - acc: 0.9475\n",
      "Epoch 46/50\n",
      "15800/15800 [==============================] - 12s 781us/step - loss: 0.1544 - acc: 0.9516\n",
      "Epoch 47/50\n",
      "15800/15800 [==============================] - 12s 753us/step - loss: 0.1533 - acc: 0.9528\n",
      "Epoch 48/50\n",
      "15800/15800 [==============================] - 12s 762us/step - loss: 0.1518 - acc: 0.9542\n",
      "Epoch 49/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.1492 - acc: 0.9533\n",
      "Epoch 50/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.1440 - acc: 0.9555\n",
      "2454/2454 [==============================] - 2s 899us/step\n",
      "160\n",
      "Epoch 1/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 1.7875 - acc: 0.4444\n",
      "Epoch 2/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 1.2640 - acc: 0.6059\n",
      "Epoch 3/50\n",
      "15800/15800 [==============================] - 23s 1ms/step - loss: 1.0670 - acc: 0.6698\n",
      "Epoch 4/50\n",
      "15800/15800 [==============================] - 22s 1ms/step - loss: 0.9370 - acc: 0.7150\n",
      "Epoch 5/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.8373 - acc: 0.7472\n",
      "Epoch 6/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.7560 - acc: 0.7669\n",
      "Epoch 7/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.6923 - acc: 0.7889\n",
      "Epoch 8/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.6377 - acc: 0.8047\n",
      "Epoch 9/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.5948 - acc: 0.8134\n",
      "Epoch 10/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.5543 - acc: 0.8288\n",
      "Epoch 11/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.5232 - acc: 0.8389\n",
      "Epoch 12/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.4897 - acc: 0.8459\n",
      "Epoch 13/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.4585 - acc: 0.8575\n",
      "Epoch 14/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.4348 - acc: 0.8631\n",
      "Epoch 15/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.4119 - acc: 0.8693\n",
      "Epoch 16/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.3902 - acc: 0.8754\n",
      "Epoch 17/50\n",
      "15800/15800 [==============================] - 22s 1ms/step - loss: 0.3708 - acc: 0.8827\n",
      "Epoch 18/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.3533 - acc: 0.8881\n",
      "Epoch 19/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.3370 - acc: 0.8934\n",
      "Epoch 20/50\n",
      "15800/15800 [==============================] - 23s 1ms/step - loss: 0.3236 - acc: 0.8986\n",
      "Epoch 21/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.3100 - acc: 0.9037\n",
      "Epoch 22/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.2993 - acc: 0.9062\n",
      "Epoch 23/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.2838 - acc: 0.9110\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.2754 - acc: 0.9147\n",
      "Epoch 25/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.2635 - acc: 0.9189\n",
      "Epoch 26/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.2539 - acc: 0.9191\n",
      "Epoch 27/50\n",
      "15800/15800 [==============================] - 22s 1ms/step - loss: 0.2466 - acc: 0.9208\n",
      "Epoch 28/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.2350 - acc: 0.9243\n",
      "Epoch 29/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.2276 - acc: 0.9276\n",
      "Epoch 30/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.2184 - acc: 0.9323\n",
      "Epoch 31/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.2114 - acc: 0.9319\n",
      "Epoch 32/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.2078 - acc: 0.9345\n",
      "Epoch 33/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.1972 - acc: 0.9363\n",
      "Epoch 34/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.1951 - acc: 0.9388\n",
      "Epoch 35/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.1875 - acc: 0.9403\n",
      "Epoch 36/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.1801 - acc: 0.9416\n",
      "Epoch 37/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.1755 - acc: 0.9433\n",
      "Epoch 38/50\n",
      "15800/15800 [==============================] - 24s 2ms/step - loss: 0.1740 - acc: 0.9455\n",
      "Epoch 39/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.1637 - acc: 0.9477\n",
      "Epoch 40/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.1595 - acc: 0.9516\n",
      "Epoch 41/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.1625 - acc: 0.9512\n",
      "Epoch 42/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.1492 - acc: 0.9523\n",
      "Epoch 43/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.1500 - acc: 0.9532\n",
      "Epoch 44/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.1444 - acc: 0.9562\n",
      "Epoch 45/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.1400 - acc: 0.9561\n",
      "Epoch 46/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.1350 - acc: 0.9557\n",
      "Epoch 47/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.1318 - acc: 0.9597\n",
      "Epoch 48/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.1305 - acc: 0.9587\n",
      "Epoch 49/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.1249 - acc: 0.9608\n",
      "Epoch 50/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.1264 - acc: 0.9606\n",
      "2454/2454 [==============================] - 2s 985us/step\n"
     ]
    }
   ],
   "source": [
    "results_nn_res = defaultdict(list)\n",
    "for i in range(10):\n",
    "    num_nodes += 16\n",
    "    estimator = KerasClassifier(model1, epochs=50, batch_size=5, verbose=1)\n",
    "    estimator.fit(X_train_res, y_train_res) #for model2\n",
    "    pred = estimator.predict(X_test)\n",
    "    results_nn_res[num_nodes].append(accuracy_score(y_test, pred))\n",
    "    #results_nn_res[num_nodes].append(f1_score(y_test, pred))\n",
    "    results_nn_res[num_nodes].append(classification_report(y_test, pred))\n",
    "    results_nn_res[num_nodes].append(create_confusion_matrix(y_test, pred))\n",
    "#print(f'max f1:{min(results_nn_res, key=lambda x: results_nn_res[x][1])}\\n')\n",
    "#for k, v in results_nn_res.items():\n",
    "#    print(f\"nn with {k} nodes in the hidden layer:    acc={v[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Epoch 1/50\n",
      "15800/15800 [==============================] - 25s 2ms/step - loss: 2.3068 - acc: 0.2948\n",
      "Epoch 2/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 1.8595 - acc: 0.4202\n",
      "Epoch 3/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 1.7437 - acc: 0.4422\n",
      "Epoch 4/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 1.6795 - acc: 0.4589\n",
      "Epoch 5/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 1.6353 - acc: 0.4736\n",
      "Epoch 6/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 1.5956 - acc: 0.4854\n",
      "Epoch 7/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 1.5563 - acc: 0.4964\n",
      "Epoch 8/50\n",
      "15800/15800 [==============================] - 13s 836us/step - loss: 1.5234 - acc: 0.5170\n",
      "Epoch 9/50\n",
      "15800/15800 [==============================] - 10s 615us/step - loss: 1.4927 - acc: 0.5256\n",
      "Epoch 10/50\n",
      "15800/15800 [==============================] - 9s 576us/step - loss: 1.4645 - acc: 0.5356\n",
      "Epoch 11/50\n",
      "15800/15800 [==============================] - 9s 601us/step - loss: 1.4404 - acc: 0.5461\n",
      "Epoch 12/50\n",
      "15800/15800 [==============================] - 10s 604us/step - loss: 1.4186 - acc: 0.5538\n",
      "Epoch 13/50\n",
      "15800/15800 [==============================] - 10s 657us/step - loss: 1.3967 - acc: 0.5594\n",
      "Epoch 14/50\n",
      "15800/15800 [==============================] - 10s 628us/step - loss: 1.3747 - acc: 0.5682\n",
      "Epoch 15/50\n",
      "15800/15800 [==============================] - 11s 694us/step - loss: 1.3570 - acc: 0.5746\n",
      "Epoch 16/50\n",
      "15800/15800 [==============================] - 14s 876us/step - loss: 1.3379 - acc: 0.5793\n",
      "Epoch 17/50\n",
      "15800/15800 [==============================] - 10s 654us/step - loss: 1.3223 - acc: 0.5846\n",
      "Epoch 18/50\n",
      "15800/15800 [==============================] - 12s 745us/step - loss: 1.3067 - acc: 0.5897\n",
      "Epoch 19/50\n",
      "15800/15800 [==============================] - 15s 951us/step - loss: 1.2950 - acc: 0.5971\n",
      "Epoch 20/50\n",
      "15800/15800 [==============================] - 12s 734us/step - loss: 1.2815 - acc: 0.5982\n",
      "Epoch 21/50\n",
      "15800/15800 [==============================] - 12s 776us/step - loss: 1.2677 - acc: 0.6038\n",
      "Epoch 22/50\n",
      "15800/15800 [==============================] - 13s 839us/step - loss: 1.2573 - acc: 0.6048\n",
      "Epoch 23/50\n",
      "15800/15800 [==============================] - 13s 815us/step - loss: 1.2472 - acc: 0.6078\n",
      "Epoch 24/50\n",
      "15800/15800 [==============================] - 12s 755us/step - loss: 1.2392 - acc: 0.6103\n",
      "Epoch 25/50\n",
      "15800/15800 [==============================] - 12s 730us/step - loss: 1.2303 - acc: 0.6077\n",
      "Epoch 26/50\n",
      "15800/15800 [==============================] - 12s 747us/step - loss: 1.2230 - acc: 0.6159\n",
      "Epoch 27/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 1.2169 - acc: 0.6191\n",
      "Epoch 28/50\n",
      "15800/15800 [==============================] - 10s 602us/step - loss: 1.2076 - acc: 0.6230\n",
      "Epoch 29/50\n",
      "15800/15800 [==============================] - 10s 625us/step - loss: 1.2023 - acc: 0.6185\n",
      "Epoch 30/50\n",
      "15800/15800 [==============================] - 10s 640us/step - loss: 1.1974 - acc: 0.6227\n",
      "Epoch 31/50\n",
      "15800/15800 [==============================] - 10s 611us/step - loss: 1.1920 - acc: 0.6234\n",
      "Epoch 32/50\n",
      "15800/15800 [==============================] - 10s 602us/step - loss: 1.1848 - acc: 0.6285\n",
      "Epoch 33/50\n",
      "15800/15800 [==============================] - 11s 682us/step - loss: 1.1780 - acc: 0.6241\n",
      "Epoch 34/50\n",
      "15800/15800 [==============================] - 10s 606us/step - loss: 1.1728 - acc: 0.6294\n",
      "Epoch 35/50\n",
      "15800/15800 [==============================] - 9s 582us/step - loss: 1.1696 - acc: 0.6313\n",
      "Epoch 36/50\n",
      "15800/15800 [==============================] - 10s 654us/step - loss: 1.1638 - acc: 0.6323\n",
      "Epoch 37/50\n",
      "15800/15800 [==============================] - 10s 603us/step - loss: 1.1601 - acc: 0.6384\n",
      "Epoch 38/50\n",
      "15800/15800 [==============================] - 13s 809us/step - loss: 1.1559 - acc: 0.6361\n",
      "Epoch 39/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 1.1510 - acc: 0.6356\n",
      "Epoch 40/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 1.1454 - acc: 0.6396\n",
      "Epoch 41/50\n",
      "15800/15800 [==============================] - 11s 717us/step - loss: 1.1400 - acc: 0.6387\n",
      "Epoch 42/50\n",
      "15800/15800 [==============================] - 13s 815us/step - loss: 1.1372 - acc: 0.6410\n",
      "Epoch 43/50\n",
      "15800/15800 [==============================] - 10s 622us/step - loss: 1.1342 - acc: 0.6403\n",
      "Epoch 44/50\n",
      "15800/15800 [==============================] - 10s 634us/step - loss: 1.1284 - acc: 0.6418\n",
      "Epoch 45/50\n",
      "15800/15800 [==============================] - 11s 679us/step - loss: 1.1249 - acc: 0.6444\n",
      "Epoch 46/50\n",
      "15800/15800 [==============================] - 10s 663us/step - loss: 1.1218 - acc: 0.6480\n",
      "Epoch 47/50\n",
      "15800/15800 [==============================] - 10s 603us/step - loss: 1.1186 - acc: 0.6493\n",
      "Epoch 48/50\n",
      "15800/15800 [==============================] - 11s 697us/step - loss: 1.1124 - acc: 0.6478\n",
      "Epoch 49/50\n",
      "15800/15800 [==============================] - 14s 903us/step - loss: 1.1126 - acc: 0.6510\n",
      "Epoch 50/50\n",
      "15800/15800 [==============================] - 14s 904us/step - loss: 1.1059 - acc: 0.6527\n",
      "2454/2454 [==============================] - 1s 548us/step\n",
      "32\n",
      "Epoch 1/50\n",
      "15800/15800 [==============================] - 13s 791us/step - loss: 2.1337 - acc: 0.3470\n",
      "Epoch 2/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 1.7095 - acc: 0.4545\n",
      "Epoch 3/50\n",
      "15800/15800 [==============================] - 10s 658us/step - loss: 1.5750 - acc: 0.4920\n",
      "Epoch 4/50\n",
      "15800/15800 [==============================] - 10s 663us/step - loss: 1.4958 - acc: 0.5158\n",
      "Epoch 5/50\n",
      "15800/15800 [==============================] - 10s 636us/step - loss: 1.4359 - acc: 0.5353\n",
      "Epoch 6/50\n",
      "15800/15800 [==============================] - 10s 615us/step - loss: 1.3872 - acc: 0.5494\n",
      "Epoch 7/50\n",
      "15800/15800 [==============================] - 13s 831us/step - loss: 1.3460 - acc: 0.5604\n",
      "Epoch 8/50\n",
      "15800/15800 [==============================] - 10s 625us/step - loss: 1.3087 - acc: 0.5748\n",
      "Epoch 9/50\n",
      "15800/15800 [==============================] - 14s 905us/step - loss: 1.2770 - acc: 0.5868\n",
      "Epoch 10/50\n",
      "15800/15800 [==============================] - 14s 866us/step - loss: 1.2464 - acc: 0.5979\n",
      "Epoch 11/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 1.2206 - acc: 0.6030\n",
      "Epoch 12/50\n",
      "15800/15800 [==============================] - 12s 743us/step - loss: 1.1949 - acc: 0.6113\n",
      "Epoch 13/50\n",
      "15800/15800 [==============================] - 12s 757us/step - loss: 1.1758 - acc: 0.6239\n",
      "Epoch 14/50\n",
      "15800/15800 [==============================] - 10s 635us/step - loss: 1.1531 - acc: 0.6306\n",
      "Epoch 15/50\n",
      "15800/15800 [==============================] - 10s 634us/step - loss: 1.1348 - acc: 0.6397\n",
      "Epoch 16/50\n",
      "15800/15800 [==============================] - 10s 646us/step - loss: 1.1161 - acc: 0.6458\n",
      "Epoch 17/50\n",
      "15800/15800 [==============================] - 10s 652us/step - loss: 1.1007 - acc: 0.6497\n",
      "Epoch 18/50\n",
      "15800/15800 [==============================] - 10s 643us/step - loss: 1.0847 - acc: 0.6521\n",
      "Epoch 19/50\n",
      "15800/15800 [==============================] - 10s 645us/step - loss: 1.0731 - acc: 0.6599\n",
      "Epoch 20/50\n",
      "15800/15800 [==============================] - 11s 673us/step - loss: 1.0581 - acc: 0.6644\n",
      "Epoch 21/50\n",
      "15800/15800 [==============================] - 10s 634us/step - loss: 1.0494 - acc: 0.6664\n",
      "Epoch 22/50\n",
      "15800/15800 [==============================] - 10s 635us/step - loss: 1.0412 - acc: 0.6695\n",
      "Epoch 23/50\n",
      "15800/15800 [==============================] - 11s 691us/step - loss: 1.0303 - acc: 0.6732\n",
      "Epoch 24/50\n",
      "15800/15800 [==============================] - 15s 928us/step - loss: 1.0198 - acc: 0.6769\n",
      "Epoch 25/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 1.0142 - acc: 0.6782\n",
      "Epoch 26/50\n",
      "15800/15800 [==============================] - 28s 2ms/step - loss: 1.0066 - acc: 0.6797\n",
      "Epoch 27/50\n",
      "15800/15800 [==============================] - 14s 885us/step - loss: 0.9967 - acc: 0.6835\n",
      "Epoch 28/50\n",
      "15800/15800 [==============================] - 15s 933us/step - loss: 0.9901 - acc: 0.6849\n",
      "Epoch 29/50\n",
      "15800/15800 [==============================] - 14s 864us/step - loss: 0.9835 - acc: 0.6872\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15800/15800 [==============================] - 15s 942us/step - loss: 0.9766 - acc: 0.6932\n",
      "Epoch 31/50\n",
      "15800/15800 [==============================] - 10s 658us/step - loss: 0.9685 - acc: 0.6915\n",
      "Epoch 32/50\n",
      "15800/15800 [==============================] - 11s 719us/step - loss: 0.9619 - acc: 0.6956\n",
      "Epoch 33/50\n",
      "15800/15800 [==============================] - 15s 952us/step - loss: 0.9597 - acc: 0.6954\n",
      "Epoch 34/50\n",
      "15800/15800 [==============================] - 10s 637us/step - loss: 0.9510 - acc: 0.6980\n",
      "Epoch 35/50\n",
      "15800/15800 [==============================] - 11s 715us/step - loss: 0.9488 - acc: 0.7032\n",
      "Epoch 36/50\n",
      "15800/15800 [==============================] - 10s 630us/step - loss: 0.9406 - acc: 0.7017\n",
      "Epoch 37/50\n",
      "15800/15800 [==============================] - 10s 650us/step - loss: 0.9361 - acc: 0.7052\n",
      "Epoch 38/50\n",
      "15800/15800 [==============================] - 15s 966us/step - loss: 0.9307 - acc: 0.7073\n",
      "Epoch 39/50\n",
      "15800/15800 [==============================] - 14s 859us/step - loss: 0.9249 - acc: 0.7077\n",
      "Epoch 40/50\n",
      "15800/15800 [==============================] - 11s 707us/step - loss: 0.9187 - acc: 0.7120\n",
      "Epoch 41/50\n",
      "15800/15800 [==============================] - 11s 718us/step - loss: 0.9171 - acc: 0.7119\n",
      "Epoch 42/50\n",
      "15800/15800 [==============================] - 10s 650us/step - loss: 0.9089 - acc: 0.7121\n",
      "Epoch 43/50\n",
      "15800/15800 [==============================] - 10s 655us/step - loss: 0.9051 - acc: 0.7139\n",
      "Epoch 44/50\n",
      "15800/15800 [==============================] - 12s 778us/step - loss: 0.9023 - acc: 0.7135\n",
      "Epoch 45/50\n",
      "15800/15800 [==============================] - 11s 682us/step - loss: 0.8964 - acc: 0.7181\n",
      "Epoch 46/50\n",
      "15800/15800 [==============================] - 13s 836us/step - loss: 0.8934 - acc: 0.7169\n",
      "Epoch 47/50\n",
      "15800/15800 [==============================] - 14s 873us/step - loss: 0.8889 - acc: 0.7197\n",
      "Epoch 48/50\n",
      "15800/15800 [==============================] - 13s 849us/step - loss: 0.8833 - acc: 0.7196\n",
      "Epoch 49/50\n",
      "15800/15800 [==============================] - 13s 791us/step - loss: 0.8794 - acc: 0.7210\n",
      "Epoch 50/50\n",
      "15800/15800 [==============================] - 13s 791us/step - loss: 0.8735 - acc: 0.7251\n",
      "2454/2454 [==============================] - 1s 596us/step\n",
      "48\n",
      "Epoch 1/50\n",
      "15800/15800 [==============================] - 12s 775us/step - loss: 2.0522 - acc: 0.3596\n",
      "Epoch 2/50\n",
      "15800/15800 [==============================] - 10s 616us/step - loss: 1.6063 - acc: 0.4825\n",
      "Epoch 3/50\n",
      "15800/15800 [==============================] - 9s 598us/step - loss: 1.4815 - acc: 0.5174\n",
      "Epoch 4/50\n",
      "15800/15800 [==============================] - 12s 736us/step - loss: 1.4059 - acc: 0.5461\n",
      "Epoch 5/50\n",
      "15800/15800 [==============================] - 10s 632us/step - loss: 1.3463 - acc: 0.5653\n",
      "Epoch 6/50\n",
      "15800/15800 [==============================] - 10s 653us/step - loss: 1.2977 - acc: 0.5853\n",
      "Epoch 7/50\n",
      "15800/15800 [==============================] - 10s 643us/step - loss: 1.2557 - acc: 0.5947\n",
      "Epoch 8/50\n",
      "15800/15800 [==============================] - 12s 759us/step - loss: 1.2146 - acc: 0.6159\n",
      "Epoch 9/50\n",
      "15800/15800 [==============================] - 10s 603us/step - loss: 1.1812 - acc: 0.6247\n",
      "Epoch 10/50\n",
      "15800/15800 [==============================] - 10s 649us/step - loss: 1.1496 - acc: 0.6340\n",
      "Epoch 11/50\n",
      "15800/15800 [==============================] - 10s 607us/step - loss: 1.1214 - acc: 0.6407\n",
      "Epoch 12/50\n",
      "15800/15800 [==============================] - 10s 663us/step - loss: 1.0971 - acc: 0.6485\n",
      "Epoch 13/50\n",
      "15800/15800 [==============================] - 9s 594us/step - loss: 1.0743 - acc: 0.6594\n",
      "Epoch 14/50\n",
      "15800/15800 [==============================] - 10s 631us/step - loss: 1.0515 - acc: 0.6590\n",
      "Epoch 15/50\n",
      "15800/15800 [==============================] - 11s 670us/step - loss: 1.0320 - acc: 0.6686\n",
      "Epoch 16/50\n",
      "15800/15800 [==============================] - 10s 614us/step - loss: 1.0133 - acc: 0.6767\n",
      "Epoch 17/50\n",
      "15800/15800 [==============================] - 10s 645us/step - loss: 0.9974 - acc: 0.6809\n",
      "Epoch 18/50\n",
      "15800/15800 [==============================] - 10s 626us/step - loss: 0.9791 - acc: 0.6844\n",
      "Epoch 19/50\n",
      "15800/15800 [==============================] - 10s 627us/step - loss: 0.9682 - acc: 0.6879\n",
      "Epoch 20/50\n",
      "15800/15800 [==============================] - 9s 600us/step - loss: 0.9542 - acc: 0.6939\n",
      "Epoch 21/50\n",
      "15800/15800 [==============================] - 12s 743us/step - loss: 0.9425 - acc: 0.6961\n",
      "Epoch 22/50\n",
      "15800/15800 [==============================] - 11s 675us/step - loss: 0.9304 - acc: 0.7040\n",
      "Epoch 23/50\n",
      "15800/15800 [==============================] - 10s 629us/step - loss: 0.9193 - acc: 0.7065\n",
      "Epoch 24/50\n",
      "15800/15800 [==============================] - 10s 602us/step - loss: 0.9083 - acc: 0.7113\n",
      "Epoch 25/50\n",
      "15800/15800 [==============================] - 10s 611us/step - loss: 0.8986 - acc: 0.7150\n",
      "Epoch 26/50\n",
      "15800/15800 [==============================] - 13s 802us/step - loss: 0.8906 - acc: 0.7128\n",
      "Epoch 27/50\n",
      "15800/15800 [==============================] - 14s 906us/step - loss: 0.8789 - acc: 0.7173\n",
      "Epoch 28/50\n",
      "15800/15800 [==============================] - 11s 694us/step - loss: 0.8704 - acc: 0.7208\n",
      "Epoch 29/50\n",
      "15800/15800 [==============================] - 12s 761us/step - loss: 0.8606 - acc: 0.7251\n",
      "Epoch 30/50\n",
      "15800/15800 [==============================] - 10s 641us/step - loss: 0.8515 - acc: 0.7280\n",
      "Epoch 31/50\n",
      "15800/15800 [==============================] - 11s 675us/step - loss: 0.8403 - acc: 0.7322\n",
      "Epoch 32/50\n",
      "15800/15800 [==============================] - 11s 695us/step - loss: 0.8355 - acc: 0.7358\n",
      "Epoch 33/50\n",
      "15800/15800 [==============================] - 15s 959us/step - loss: 0.8259 - acc: 0.7356\n",
      "Epoch 34/50\n",
      "15800/15800 [==============================] - 10s 648us/step - loss: 0.8176 - acc: 0.7393\n",
      "Epoch 35/50\n",
      "15800/15800 [==============================] - 10s 625us/step - loss: 0.8118 - acc: 0.7417\n",
      "Epoch 36/50\n",
      "15800/15800 [==============================] - 12s 790us/step - loss: 0.8066 - acc: 0.7385\n",
      "Epoch 37/50\n",
      "15800/15800 [==============================] - 11s 712us/step - loss: 0.7991 - acc: 0.7428\n",
      "Epoch 38/50\n",
      "15800/15800 [==============================] - 11s 679us/step - loss: 0.7921 - acc: 0.7441\n",
      "Epoch 39/50\n",
      "15800/15800 [==============================] - 11s 683us/step - loss: 0.7857 - acc: 0.7498\n",
      "Epoch 40/50\n",
      "15800/15800 [==============================] - 14s 887us/step - loss: 0.7798 - acc: 0.7491\n",
      "Epoch 41/50\n",
      "15800/15800 [==============================] - 11s 713us/step - loss: 0.7713 - acc: 0.7513\n",
      "Epoch 42/50\n",
      "15800/15800 [==============================] - 12s 742us/step - loss: 0.7649 - acc: 0.7527\n",
      "Epoch 43/50\n",
      "15800/15800 [==============================] - 11s 676us/step - loss: 0.7622 - acc: 0.7546\n",
      "Epoch 44/50\n",
      "15800/15800 [==============================] - 11s 698us/step - loss: 0.7519 - acc: 0.7570\n",
      "Epoch 45/50\n",
      "15800/15800 [==============================] - 14s 877us/step - loss: 0.7490 - acc: 0.7591\n",
      "Epoch 46/50\n",
      "15800/15800 [==============================] - 12s 742us/step - loss: 0.7415 - acc: 0.7580\n",
      "Epoch 47/50\n",
      "15800/15800 [==============================] - 12s 756us/step - loss: 0.7390 - acc: 0.7620\n",
      "Epoch 48/50\n",
      "15800/15800 [==============================] - 12s 753us/step - loss: 0.7353 - acc: 0.7626\n",
      "Epoch 49/50\n",
      "15800/15800 [==============================] - 11s 715us/step - loss: 0.7273 - acc: 0.7655\n",
      "Epoch 50/50\n",
      "15800/15800 [==============================] - 10s 655us/step - loss: 0.7216 - acc: 0.7639\n",
      "2454/2454 [==============================] - 2s 839us/step\n",
      "64\n",
      "Epoch 1/50\n",
      "15800/15800 [==============================] - 14s 863us/step - loss: 1.9763 - acc: 0.3827\n",
      "Epoch 2/50\n",
      "15800/15800 [==============================] - 12s 770us/step - loss: 1.5588 - acc: 0.4922\n",
      "Epoch 3/50\n",
      "15800/15800 [==============================] - 14s 884us/step - loss: 1.4297 - acc: 0.5366\n",
      "Epoch 4/50\n",
      "15800/15800 [==============================] - 12s 762us/step - loss: 1.3439 - acc: 0.5653\n",
      "Epoch 5/50\n",
      "15800/15800 [==============================] - 11s 701us/step - loss: 1.2777 - acc: 0.5885\n",
      "Epoch 6/50\n",
      "15800/15800 [==============================] - 13s 813us/step - loss: 1.2194 - acc: 0.6089\n",
      "Epoch 7/50\n",
      "15800/15800 [==============================] - 13s 817us/step - loss: 1.1682 - acc: 0.6252\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15800/15800 [==============================] - 14s 885us/step - loss: 1.1275 - acc: 0.6380\n",
      "Epoch 9/50\n",
      "15800/15800 [==============================] - 12s 747us/step - loss: 1.0935 - acc: 0.6520\n",
      "Epoch 10/50\n",
      "15800/15800 [==============================] - 12s 729us/step - loss: 1.0615 - acc: 0.6613\n",
      "Epoch 11/50\n",
      "15800/15800 [==============================] - 15s 924us/step - loss: 1.0390 - acc: 0.6675\n",
      "Epoch 12/50\n",
      "15800/15800 [==============================] - 13s 836us/step - loss: 1.0145 - acc: 0.6751\n",
      "Epoch 13/50\n",
      "15800/15800 [==============================] - 14s 906us/step - loss: 0.9910 - acc: 0.6839\n",
      "Epoch 14/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.9740 - acc: 0.6916\n",
      "Epoch 15/50\n",
      "15800/15800 [==============================] - 11s 723us/step - loss: 0.9575 - acc: 0.6961\n",
      "Epoch 16/50\n",
      "15800/15800 [==============================] - 12s 754us/step - loss: 0.9349 - acc: 0.7025\n",
      "Epoch 17/50\n",
      "15800/15800 [==============================] - 12s 778us/step - loss: 0.9207 - acc: 0.7049\n",
      "Epoch 18/50\n",
      "15800/15800 [==============================] - 15s 925us/step - loss: 0.9024 - acc: 0.7123\n",
      "Epoch 19/50\n",
      "15800/15800 [==============================] - 14s 896us/step - loss: 0.8869 - acc: 0.7155\n",
      "Epoch 20/50\n",
      "15800/15800 [==============================] - 12s 750us/step - loss: 0.8750 - acc: 0.7202\n",
      "Epoch 21/50\n",
      "15800/15800 [==============================] - 11s 710us/step - loss: 0.8559 - acc: 0.7252\n",
      "Epoch 22/50\n",
      "15800/15800 [==============================] - 13s 807us/step - loss: 0.8446 - acc: 0.7299\n",
      "Epoch 23/50\n",
      "15800/15800 [==============================] - 11s 672us/step - loss: 0.8338 - acc: 0.7356\n",
      "Epoch 24/50\n",
      "15800/15800 [==============================] - 10s 660us/step - loss: 0.8205 - acc: 0.7389\n",
      "Epoch 25/50\n",
      "15800/15800 [==============================] - 11s 671us/step - loss: 0.8060 - acc: 0.7428\n",
      "Epoch 26/50\n",
      "15800/15800 [==============================] - 10s 663us/step - loss: 0.7935 - acc: 0.7492\n",
      "Epoch 27/50\n",
      "15800/15800 [==============================] - 11s 690us/step - loss: 0.7802 - acc: 0.7500\n",
      "Epoch 28/50\n",
      "15800/15800 [==============================] - 10s 644us/step - loss: 0.7724 - acc: 0.7504\n",
      "Epoch 29/50\n",
      "15800/15800 [==============================] - 11s 711us/step - loss: 0.7649 - acc: 0.7550\n",
      "Epoch 30/50\n",
      "15800/15800 [==============================] - 11s 676us/step - loss: 0.7520 - acc: 0.7596\n",
      "Epoch 31/50\n",
      "15800/15800 [==============================] - 12s 748us/step - loss: 0.7430 - acc: 0.7604\n",
      "Epoch 32/50\n",
      "15800/15800 [==============================] - 11s 683us/step - loss: 0.7308 - acc: 0.7653\n",
      "Epoch 33/50\n",
      "15800/15800 [==============================] - 10s 653us/step - loss: 0.7207 - acc: 0.7679\n",
      "Epoch 34/50\n",
      "15800/15800 [==============================] - 11s 690us/step - loss: 0.7116 - acc: 0.7699\n",
      "Epoch 35/50\n",
      "15800/15800 [==============================] - 11s 673us/step - loss: 0.7039 - acc: 0.7744\n",
      "Epoch 36/50\n",
      "15800/15800 [==============================] - 12s 747us/step - loss: 0.6960 - acc: 0.7751\n",
      "Epoch 37/50\n",
      "15800/15800 [==============================] - 11s 693us/step - loss: 0.6898 - acc: 0.7757\n",
      "Epoch 38/50\n",
      "15800/15800 [==============================] - 12s 748us/step - loss: 0.6841 - acc: 0.7780\n",
      "Epoch 39/50\n",
      "15800/15800 [==============================] - 11s 709us/step - loss: 0.6790 - acc: 0.7822\n",
      "Epoch 40/50\n",
      "15800/15800 [==============================] - 11s 698us/step - loss: 0.6683 - acc: 0.7843\n",
      "Epoch 41/50\n",
      "15800/15800 [==============================] - 14s 898us/step - loss: 0.6630 - acc: 0.7844\n",
      "Epoch 42/50\n",
      "15800/15800 [==============================] - 11s 680us/step - loss: 0.6549 - acc: 0.7896\n",
      "Epoch 43/50\n",
      "15800/15800 [==============================] - 11s 699us/step - loss: 0.6486 - acc: 0.7909\n",
      "Epoch 44/50\n",
      "15800/15800 [==============================] - 11s 713us/step - loss: 0.6417 - acc: 0.7939\n",
      "Epoch 45/50\n",
      "15800/15800 [==============================] - 10s 637us/step - loss: 0.6362 - acc: 0.7935\n",
      "Epoch 46/50\n",
      "15800/15800 [==============================] - 11s 718us/step - loss: 0.6314 - acc: 0.7939\n",
      "Epoch 47/50\n",
      "15800/15800 [==============================] - 10s 655us/step - loss: 0.6253 - acc: 0.7994\n",
      "Epoch 48/50\n",
      "15800/15800 [==============================] - 11s 665us/step - loss: 0.6208 - acc: 0.8001\n",
      "Epoch 49/50\n",
      "15800/15800 [==============================] - 10s 657us/step - loss: 0.6157 - acc: 0.7994\n",
      "Epoch 50/50\n",
      "15800/15800 [==============================] - 11s 669us/step - loss: 0.6079 - acc: 0.8046\n",
      "2454/2454 [==============================] - 2s 665us/step\n",
      "80\n",
      "Epoch 1/50\n",
      "15800/15800 [==============================] - 12s 779us/step - loss: 1.9443 - acc: 0.3897\n",
      "Epoch 2/50\n",
      "15800/15800 [==============================] - 14s 915us/step - loss: 1.5293 - acc: 0.5059\n",
      "Epoch 3/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 1.3871 - acc: 0.5466\n",
      "Epoch 4/50\n",
      "15800/15800 [==============================] - 12s 758us/step - loss: 1.2911 - acc: 0.5823\n",
      "Epoch 5/50\n",
      "15800/15800 [==============================] - 14s 857us/step - loss: 1.2177 - acc: 0.6031\n",
      "Epoch 6/50\n",
      "15800/15800 [==============================] - 12s 734us/step - loss: 1.1618 - acc: 0.6244\n",
      "Epoch 7/50\n",
      "15800/15800 [==============================] - 11s 682us/step - loss: 1.1117 - acc: 0.6430\n",
      "Epoch 8/50\n",
      "15800/15800 [==============================] - 12s 732us/step - loss: 1.0745 - acc: 0.6562\n",
      "Epoch 9/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 1.0351 - acc: 0.6701\n",
      "Epoch 10/50\n",
      "15800/15800 [==============================] - 14s 890us/step - loss: 1.0065 - acc: 0.6720\n",
      "Epoch 11/50\n",
      "15800/15800 [==============================] - ETA: 0s - loss: 0.9782 - acc: 0.684 - 15s 978us/step - loss: 0.9787 - acc: 0.6846\n",
      "Epoch 12/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.9504 - acc: 0.6955\n",
      "Epoch 13/50\n",
      "15800/15800 [==============================] - 14s 882us/step - loss: 0.9294 - acc: 0.7004\n",
      "Epoch 14/50\n",
      "15800/15800 [==============================] - 15s 974us/step - loss: 0.9082 - acc: 0.7059\n",
      "Epoch 15/50\n",
      "15800/15800 [==============================] - 15s 980us/step - loss: 0.8851 - acc: 0.7139\n",
      "Epoch 16/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.8652 - acc: 0.7166\n",
      "Epoch 17/50\n",
      "15800/15800 [==============================] - 14s 885us/step - loss: 0.8503 - acc: 0.7225\n",
      "Epoch 18/50\n",
      "15800/15800 [==============================] - 23s 1ms/step - loss: 0.8325 - acc: 0.7240\n",
      "Epoch 19/50\n",
      "15800/15800 [==============================] - 24s 2ms/step - loss: 0.8187 - acc: 0.7318\n",
      "Epoch 20/50\n",
      "15800/15800 [==============================] - 22s 1ms/step - loss: 0.8029 - acc: 0.7375\n",
      "Epoch 21/50\n",
      "15800/15800 [==============================] - ETA: 0s - loss: 0.7918 - acc: 0.740 - 23s 1ms/step - loss: 0.7924 - acc: 0.7406\n",
      "Epoch 22/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.7772 - acc: 0.7482\n",
      "Epoch 23/50\n",
      "15800/15800 [==============================] - 11s 704us/step - loss: 0.7642 - acc: 0.7512\n",
      "Epoch 24/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.7513 - acc: 0.7554\n",
      "Epoch 25/50\n",
      "15800/15800 [==============================] - 16s 993us/step - loss: 0.7359 - acc: 0.7570\n",
      "Epoch 26/50\n",
      "15800/15800 [==============================] - 13s 808us/step - loss: 0.7285 - acc: 0.7604\n",
      "Epoch 27/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.7165 - acc: 0.7653\n",
      "Epoch 28/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.7074 - acc: 0.7663\n",
      "Epoch 29/50\n",
      "15800/15800 [==============================] - 13s 827us/step - loss: 0.6987 - acc: 0.7713\n",
      "Epoch 30/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.6888 - acc: 0.7735\n",
      "Epoch 31/50\n",
      "15800/15800 [==============================] - 12s 767us/step - loss: 0.6821 - acc: 0.7744\n",
      "Epoch 32/50\n",
      "15800/15800 [==============================] - 12s 756us/step - loss: 0.6748 - acc: 0.7744\n",
      "Epoch 33/50\n",
      "15800/15800 [==============================] - 11s 677us/step - loss: 0.6645 - acc: 0.7835\n",
      "Epoch 34/50\n",
      "15800/15800 [==============================] - 14s 904us/step - loss: 0.6583 - acc: 0.7835\n",
      "Epoch 35/50\n",
      "15800/15800 [==============================] - 15s 939us/step - loss: 0.6493 - acc: 0.7846\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15800/15800 [==============================] - 11s 713us/step - loss: 0.6401 - acc: 0.7877\n",
      "Epoch 37/50\n",
      "15800/15800 [==============================] - 13s 843us/step - loss: 0.6372 - acc: 0.7921\n",
      "Epoch 38/50\n",
      "15800/15800 [==============================] - ETA: 0s - loss: 0.6270 - acc: 0.793 - 12s 781us/step - loss: 0.6273 - acc: 0.7934\n",
      "Epoch 39/50\n",
      "15800/15800 [==============================] - 12s 789us/step - loss: 0.6161 - acc: 0.7975\n",
      "Epoch 40/50\n",
      "15800/15800 [==============================] - 12s 761us/step - loss: 0.6140 - acc: 0.7948\n",
      "Epoch 41/50\n",
      "15800/15800 [==============================] - 12s 768us/step - loss: 0.6067 - acc: 0.8013\n",
      "Epoch 42/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.5990 - acc: 0.8014\n",
      "Epoch 43/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.5938 - acc: 0.8041\n",
      "Epoch 44/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.5907 - acc: 0.8053\n",
      "Epoch 45/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.5801 - acc: 0.8080\n",
      "Epoch 46/50\n",
      "15800/15800 [==============================] - 16s 986us/step - loss: 0.5784 - acc: 0.8058\n",
      "Epoch 47/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.5704 - acc: 0.8111\n",
      "Epoch 48/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.5627 - acc: 0.8142\n",
      "Epoch 49/50\n",
      "15800/15800 [==============================] - 14s 865us/step - loss: 0.5603 - acc: 0.8171\n",
      "Epoch 50/50\n",
      "15800/15800 [==============================] - 13s 815us/step - loss: 0.5541 - acc: 0.8158\n",
      "2454/2454 [==============================] - 2s 819us/step\n",
      "96\n",
      "Epoch 1/50\n",
      "15800/15800 [==============================] - 14s 906us/step - loss: 1.8933 - acc: 0.4007\n",
      "Epoch 2/50\n",
      "15800/15800 [==============================] - 12s 791us/step - loss: 1.4977 - acc: 0.5129\n",
      "Epoch 3/50\n",
      "15800/15800 [==============================] - 14s 877us/step - loss: 1.3566 - acc: 0.5591\n",
      "Epoch 4/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 1.2575 - acc: 0.5922\n",
      "Epoch 5/50\n",
      "15800/15800 [==============================] - 14s 891us/step - loss: 1.1789 - acc: 0.6161\n",
      "Epoch 6/50\n",
      "15800/15800 [==============================] - 13s 796us/step - loss: 1.1187 - acc: 0.6352\n",
      "Epoch 7/50\n",
      "15800/15800 [==============================] - 12s 775us/step - loss: 1.0639 - acc: 0.6556\n",
      "Epoch 8/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 1.0224 - acc: 0.6702\n",
      "Epoch 9/50\n",
      "15800/15800 [==============================] - 13s 797us/step - loss: 0.9839 - acc: 0.6818\n",
      "Epoch 10/50\n",
      "15800/15800 [==============================] - 13s 821us/step - loss: 0.9534 - acc: 0.6918\n",
      "Epoch 11/50\n",
      "15800/15800 [==============================] - 13s 849us/step - loss: 0.9185 - acc: 0.7034\n",
      "Epoch 12/50\n",
      "15800/15800 [==============================] - 14s 866us/step - loss: 0.8954 - acc: 0.7124\n",
      "Epoch 13/50\n",
      "15800/15800 [==============================] - 12s 761us/step - loss: 0.8709 - acc: 0.7173\n",
      "Epoch 14/50\n",
      "15800/15800 [==============================] - 14s 906us/step - loss: 0.8505 - acc: 0.7222\n",
      "Epoch 15/50\n",
      "15800/15800 [==============================] - 13s 853us/step - loss: 0.8279 - acc: 0.7314\n",
      "Epoch 16/50\n",
      "15800/15800 [==============================] - 13s 804us/step - loss: 0.8128 - acc: 0.7313\n",
      "Epoch 17/50\n",
      "15800/15800 [==============================] - 15s 923us/step - loss: 0.7911 - acc: 0.7419\n",
      "Epoch 18/50\n",
      "15800/15800 [==============================] - 15s 926us/step - loss: 0.7718 - acc: 0.7447\n",
      "Epoch 19/50\n",
      "15800/15800 [==============================] - 13s 814us/step - loss: 0.7579 - acc: 0.7516\n",
      "Epoch 20/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.7431 - acc: 0.7544\n",
      "Epoch 21/50\n",
      "15800/15800 [==============================] - 13s 829us/step - loss: 0.7281 - acc: 0.7599\n",
      "Epoch 22/50\n",
      "15800/15800 [==============================] - 15s 956us/step - loss: 0.7145 - acc: 0.7628\n",
      "Epoch 23/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.7029 - acc: 0.7673\n",
      "Epoch 24/50\n",
      "15800/15800 [==============================] - 11s 700us/step - loss: 0.6913 - acc: 0.7712\n",
      "Epoch 25/50\n",
      "15800/15800 [==============================] - 12s 751us/step - loss: 0.6776 - acc: 0.7753\n",
      "Epoch 26/50\n",
      "15800/15800 [==============================] - 11s 700us/step - loss: 0.6669 - acc: 0.7758\n",
      "Epoch 27/50\n",
      "15800/15800 [==============================] - 11s 703us/step - loss: 0.6564 - acc: 0.7842\n",
      "Epoch 28/50\n",
      "15800/15800 [==============================] - 11s 695us/step - loss: 0.6456 - acc: 0.7851\n",
      "Epoch 29/50\n",
      "15800/15800 [==============================] - 11s 696us/step - loss: 0.6360 - acc: 0.7885\n",
      "Epoch 30/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.6258 - acc: 0.7915\n",
      "Epoch 31/50\n",
      "15800/15800 [==============================] - 13s 831us/step - loss: 0.6165 - acc: 0.7934\n",
      "Epoch 32/50\n",
      "15800/15800 [==============================] - 13s 795us/step - loss: 0.6082 - acc: 0.7956\n",
      "Epoch 33/50\n",
      "15800/15800 [==============================] - 14s 893us/step - loss: 0.6015 - acc: 0.8008\n",
      "Epoch 34/50\n",
      "15800/15800 [==============================] - 15s 958us/step - loss: 0.5917 - acc: 0.8017\n",
      "Epoch 35/50\n",
      "15800/15800 [==============================] - 12s 739us/step - loss: 0.5842 - acc: 0.8032\n",
      "Epoch 36/50\n",
      "15800/15800 [==============================] - 11s 688us/step - loss: 0.5763 - acc: 0.8057\n",
      "Epoch 37/50\n",
      "15800/15800 [==============================] - 12s 786us/step - loss: 0.5704 - acc: 0.8110\n",
      "Epoch 38/50\n",
      "15800/15800 [==============================] - 12s 736us/step - loss: 0.5619 - acc: 0.8119\n",
      "Epoch 39/50\n",
      "15800/15800 [==============================] - 10s 661us/step - loss: 0.5513 - acc: 0.8144\n",
      "Epoch 40/50\n",
      "15800/15800 [==============================] - 11s 699us/step - loss: 0.5514 - acc: 0.8143\n",
      "Epoch 41/50\n",
      "15800/15800 [==============================] - 11s 696us/step - loss: 0.5386 - acc: 0.8175\n",
      "Epoch 42/50\n",
      "15800/15800 [==============================] - 11s 693us/step - loss: 0.5336 - acc: 0.8218\n",
      "Epoch 43/50\n",
      "15800/15800 [==============================] - 13s 830us/step - loss: 0.5297 - acc: 0.8197\n",
      "Epoch 44/50\n",
      "15800/15800 [==============================] - 16s 984us/step - loss: 0.5212 - acc: 0.8240\n",
      "Epoch 45/50\n",
      "15800/15800 [==============================] - 15s 927us/step - loss: 0.5199 - acc: 0.8245\n",
      "Epoch 46/50\n",
      "15800/15800 [==============================] - 11s 713us/step - loss: 0.5140 - acc: 0.8268\n",
      "Epoch 47/50\n",
      "15800/15800 [==============================] - 11s 677us/step - loss: 0.5064 - acc: 0.8293\n",
      "Epoch 48/50\n",
      "15800/15800 [==============================] - 11s 686us/step - loss: 0.5013 - acc: 0.8318\n",
      "Epoch 49/50\n",
      "15800/15800 [==============================] - 11s 687us/step - loss: 0.4945 - acc: 0.8330\n",
      "Epoch 50/50\n",
      "15800/15800 [==============================] - 11s 710us/step - loss: 0.4912 - acc: 0.8327\n",
      "2454/2454 [==============================] - 2s 732us/step\n",
      "112\n",
      "Epoch 1/50\n",
      "15800/15800 [==============================] - 13s 826us/step - loss: 1.8740 - acc: 0.4031\n",
      "Epoch 2/50\n",
      "15800/15800 [==============================] - 12s 728us/step - loss: 1.4817 - acc: 0.5090\n",
      "Epoch 3/50\n",
      "15800/15800 [==============================] - 13s 793us/step - loss: 1.3411 - acc: 0.5559\n",
      "Epoch 4/50\n",
      "15800/15800 [==============================] - 12s 748us/step - loss: 1.2434 - acc: 0.5916\n",
      "Epoch 5/50\n",
      "15800/15800 [==============================] - 12s 730us/step - loss: 1.1609 - acc: 0.6187\n",
      "Epoch 6/50\n",
      "15800/15800 [==============================] - 12s 728us/step - loss: 1.0920 - acc: 0.6470\n",
      "Epoch 7/50\n",
      "15800/15800 [==============================] - 11s 689us/step - loss: 1.0347 - acc: 0.6649\n",
      "Epoch 8/50\n",
      "15800/15800 [==============================] - 11s 701us/step - loss: 0.9874 - acc: 0.6769\n",
      "Epoch 9/50\n",
      "15800/15800 [==============================] - 11s 693us/step - loss: 0.9477 - acc: 0.6922\n",
      "Epoch 10/50\n",
      "15800/15800 [==============================] - 11s 713us/step - loss: 0.9108 - acc: 0.6999\n",
      "Epoch 11/50\n",
      "15800/15800 [==============================] - 12s 746us/step - loss: 0.8803 - acc: 0.7156\n",
      "Epoch 12/50\n",
      "15800/15800 [==============================] - 12s 773us/step - loss: 0.8509 - acc: 0.7252\n",
      "Epoch 13/50\n",
      "15800/15800 [==============================] - 11s 713us/step - loss: 0.8284 - acc: 0.7292\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15800/15800 [==============================] - 12s 746us/step - loss: 0.8073 - acc: 0.7372\n",
      "Epoch 15/50\n",
      "15800/15800 [==============================] - 11s 668us/step - loss: 0.7833 - acc: 0.7435\n",
      "Epoch 16/50\n",
      "15800/15800 [==============================] - 11s 689us/step - loss: 0.7632 - acc: 0.7515\n",
      "Epoch 17/50\n",
      "15800/15800 [==============================] - 11s 712us/step - loss: 0.7488 - acc: 0.7544\n",
      "Epoch 18/50\n",
      "15800/15800 [==============================] - 12s 732us/step - loss: 0.7250 - acc: 0.7603\n",
      "Epoch 19/50\n",
      "15800/15800 [==============================] - 15s 926us/step - loss: 0.7147 - acc: 0.7659\n",
      "Epoch 20/50\n",
      "15800/15800 [==============================] - 12s 746us/step - loss: 0.6982 - acc: 0.7692\n",
      "Epoch 21/50\n",
      "15800/15800 [==============================] - 11s 708us/step - loss: 0.6862 - acc: 0.7746\n",
      "Epoch 22/50\n",
      "15800/15800 [==============================] - 10s 663us/step - loss: 0.6715 - acc: 0.7814\n",
      "Epoch 23/50\n",
      "15800/15800 [==============================] - 11s 680us/step - loss: 0.6618 - acc: 0.7782\n",
      "Epoch 24/50\n",
      "15800/15800 [==============================] - 12s 746us/step - loss: 0.6468 - acc: 0.7829\n",
      "Epoch 25/50\n",
      "15800/15800 [==============================] - 11s 716us/step - loss: 0.6363 - acc: 0.7891\n",
      "Epoch 26/50\n",
      "15800/15800 [==============================] - 12s 739us/step - loss: 0.6224 - acc: 0.7947\n",
      "Epoch 27/50\n",
      "15800/15800 [==============================] - 11s 707us/step - loss: 0.6107 - acc: 0.7953\n",
      "Epoch 28/50\n",
      "15800/15800 [==============================] - 11s 723us/step - loss: 0.6031 - acc: 0.7987\n",
      "Epoch 29/50\n",
      "15800/15800 [==============================] - 12s 733us/step - loss: 0.5902 - acc: 0.8020\n",
      "Epoch 30/50\n",
      "15800/15800 [==============================] - 16s 983us/step - loss: 0.5850 - acc: 0.8078\n",
      "Epoch 31/50\n",
      "15800/15800 [==============================] - 13s 813us/step - loss: 0.5715 - acc: 0.8109\n",
      "Epoch 32/50\n",
      "15800/15800 [==============================] - 13s 798us/step - loss: 0.5603 - acc: 0.8121\n",
      "Epoch 33/50\n",
      "15800/15800 [==============================] - 12s 757us/step - loss: 0.5577 - acc: 0.8154\n",
      "Epoch 34/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.5438 - acc: 0.8218\n",
      "Epoch 35/50\n",
      "15800/15800 [==============================] - 12s 742us/step - loss: 0.5399 - acc: 0.8191\n",
      "Epoch 36/50\n",
      "15800/15800 [==============================] - 12s 751us/step - loss: 0.5325 - acc: 0.8242\n",
      "Epoch 37/50\n",
      "15800/15800 [==============================] - 11s 697us/step - loss: 0.5235 - acc: 0.8270\n",
      "Epoch 38/50\n",
      "15800/15800 [==============================] - 11s 698us/step - loss: 0.5197 - acc: 0.8266\n",
      "Epoch 39/50\n",
      "15800/15800 [==============================] - 11s 714us/step - loss: 0.5121 - acc: 0.8323\n",
      "Epoch 40/50\n",
      "15800/15800 [==============================] - 11s 674us/step - loss: 0.5061 - acc: 0.8323\n",
      "Epoch 41/50\n",
      "15800/15800 [==============================] - 11s 720us/step - loss: 0.4967 - acc: 0.8353\n",
      "Epoch 42/50\n",
      "15800/15800 [==============================] - 11s 710us/step - loss: 0.4938 - acc: 0.8368\n",
      "Epoch 43/50\n",
      "15800/15800 [==============================] - 11s 727us/step - loss: 0.4830 - acc: 0.8391\n",
      "Epoch 44/50\n",
      "15800/15800 [==============================] - 12s 773us/step - loss: 0.4810 - acc: 0.8415\n",
      "Epoch 45/50\n",
      "15800/15800 [==============================] - 11s 714us/step - loss: 0.4707 - acc: 0.8430\n",
      "Epoch 46/50\n",
      "15800/15800 [==============================] - 11s 698us/step - loss: 0.4654 - acc: 0.8418\n",
      "Epoch 47/50\n",
      "15800/15800 [==============================] - 11s 725us/step - loss: 0.4647 - acc: 0.8449\n",
      "Epoch 48/50\n",
      "15800/15800 [==============================] - 12s 772us/step - loss: 0.4550 - acc: 0.8474\n",
      "Epoch 49/50\n",
      "15800/15800 [==============================] - 11s 727us/step - loss: 0.4510 - acc: 0.8492\n",
      "Epoch 50/50\n",
      "15800/15800 [==============================] - 11s 703us/step - loss: 0.4454 - acc: 0.8518\n",
      "2454/2454 [==============================] - 2s 705us/step\n",
      "128\n",
      "Epoch 1/50\n",
      "15800/15800 [==============================] - 14s 855us/step - loss: 1.8692 - acc: 0.4090\n",
      "Epoch 2/50\n",
      "15800/15800 [==============================] - 15s 953us/step - loss: 1.4652 - acc: 0.5212\n",
      "Epoch 3/50\n",
      "15800/15800 [==============================] - 12s 773us/step - loss: 1.3184 - acc: 0.5641\n",
      "Epoch 4/50\n",
      "15800/15800 [==============================] - 11s 699us/step - loss: 1.2127 - acc: 0.6056\n",
      "Epoch 5/50\n",
      "15800/15800 [==============================] - 12s 732us/step - loss: 1.1300 - acc: 0.6325\n",
      "Epoch 6/50\n",
      "15800/15800 [==============================] - 12s 751us/step - loss: 1.0632 - acc: 0.6529\n",
      "Epoch 7/50\n",
      "15800/15800 [==============================] - 11s 692us/step - loss: 1.0084 - acc: 0.6661\n",
      "Epoch 8/50\n",
      "15800/15800 [==============================] - 11s 720us/step - loss: 0.9628 - acc: 0.6869\n",
      "Epoch 9/50\n",
      "15800/15800 [==============================] - 13s 822us/step - loss: 0.9240 - acc: 0.6974\n",
      "Epoch 10/50\n",
      "15800/15800 [==============================] - 12s 740us/step - loss: 0.8919 - acc: 0.7066\n",
      "Epoch 11/50\n",
      "15800/15800 [==============================] - 12s 762us/step - loss: 0.8613 - acc: 0.7130\n",
      "Epoch 12/50\n",
      "15800/15800 [==============================] - 11s 711us/step - loss: 0.8380 - acc: 0.7248\n",
      "Epoch 13/50\n",
      "15800/15800 [==============================] - 12s 786us/step - loss: 0.8118 - acc: 0.7318\n",
      "Epoch 14/50\n",
      "15800/15800 [==============================] - 12s 758us/step - loss: 0.7867 - acc: 0.7385\n",
      "Epoch 15/50\n",
      "15800/15800 [==============================] - 11s 725us/step - loss: 0.7698 - acc: 0.7439\n",
      "Epoch 16/50\n",
      "15800/15800 [==============================] - 11s 715us/step - loss: 0.7482 - acc: 0.7495\n",
      "Epoch 17/50\n",
      "15800/15800 [==============================] - 12s 739us/step - loss: 0.7306 - acc: 0.7553\n",
      "Epoch 18/50\n",
      "15800/15800 [==============================] - 12s 758us/step - loss: 0.7144 - acc: 0.7599\n",
      "Epoch 19/50\n",
      "15800/15800 [==============================] - 12s 742us/step - loss: 0.7001 - acc: 0.7683\n",
      "Epoch 20/50\n",
      "15800/15800 [==============================] - 12s 756us/step - loss: 0.6863 - acc: 0.7704\n",
      "Epoch 21/50\n",
      "15800/15800 [==============================] - 11s 720us/step - loss: 0.6703 - acc: 0.7776\n",
      "Epoch 22/50\n",
      "15800/15800 [==============================] - 11s 678us/step - loss: 0.6566 - acc: 0.7809\n",
      "Epoch 23/50\n",
      "15800/15800 [==============================] - 12s 772us/step - loss: 0.6425 - acc: 0.7875\n",
      "Epoch 24/50\n",
      "15800/15800 [==============================] - 11s 727us/step - loss: 0.6316 - acc: 0.7889\n",
      "Epoch 25/50\n",
      "15800/15800 [==============================] - 11s 698us/step - loss: 0.6196 - acc: 0.7961\n",
      "Epoch 26/50\n",
      "15800/15800 [==============================] - 12s 751us/step - loss: 0.6086 - acc: 0.7953\n",
      "Epoch 27/50\n",
      "15800/15800 [==============================] - 12s 765us/step - loss: 0.5966 - acc: 0.8025\n",
      "Epoch 28/50\n",
      "15800/15800 [==============================] - 11s 698us/step - loss: 0.5815 - acc: 0.8079\n",
      "Epoch 29/50\n",
      "15800/15800 [==============================] - 12s 743us/step - loss: 0.5793 - acc: 0.8060\n",
      "Epoch 30/50\n",
      "15800/15800 [==============================] - 11s 710us/step - loss: 0.5633 - acc: 0.8096\n",
      "Epoch 31/50\n",
      "15800/15800 [==============================] - 12s 764us/step - loss: 0.5539 - acc: 0.8141\n",
      "Epoch 32/50\n",
      "15800/15800 [==============================] - 12s 729us/step - loss: 0.5496 - acc: 0.8183\n",
      "Epoch 33/50\n",
      "15800/15800 [==============================] - 12s 753us/step - loss: 0.5400 - acc: 0.8181\n",
      "Epoch 34/50\n",
      "15800/15800 [==============================] - 11s 719us/step - loss: 0.5327 - acc: 0.8205\n",
      "Epoch 35/50\n",
      "15800/15800 [==============================] - 11s 716us/step - loss: 0.5244 - acc: 0.8265\n",
      "Epoch 36/50\n",
      "15800/15800 [==============================] - 16s 996us/step - loss: 0.5130 - acc: 0.8289\n",
      "Epoch 37/50\n",
      "15800/15800 [==============================] - 25s 2ms/step - loss: 0.5056 - acc: 0.8300\n",
      "Epoch 38/50\n",
      "15800/15800 [==============================] - 26s 2ms/step - loss: 0.5060 - acc: 0.8298\n",
      "Epoch 39/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.4956 - acc: 0.8328\n",
      "Epoch 40/50\n",
      "15800/15800 [==============================] - 13s 829us/step - loss: 0.4892 - acc: 0.8363\n",
      "Epoch 41/50\n",
      "15800/15800 [==============================] - 13s 794us/step - loss: 0.4809 - acc: 0.8381\n",
      "Epoch 42/50\n",
      "15800/15800 [==============================] - 13s 813us/step - loss: 0.4751 - acc: 0.8378\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15800/15800 [==============================] - 13s 822us/step - loss: 0.4687 - acc: 0.8450\n",
      "Epoch 44/50\n",
      "15800/15800 [==============================] - 14s 862us/step - loss: 0.4637 - acc: 0.8462\n",
      "Epoch 45/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.4602 - acc: 0.8461\n",
      "Epoch 46/50\n",
      "15800/15800 [==============================] - 13s 816us/step - loss: 0.4500 - acc: 0.8478\n",
      "Epoch 47/50\n",
      "15800/15800 [==============================] - 15s 925us/step - loss: 0.4449 - acc: 0.8494\n",
      "Epoch 48/50\n",
      "15800/15800 [==============================] - 14s 904us/step - loss: 0.4385 - acc: 0.8508\n",
      "Epoch 49/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.4361 - acc: 0.8556\n",
      "Epoch 50/50\n",
      "15800/15800 [==============================] - 14s 878us/step - loss: 0.4292 - acc: 0.8549\n",
      "2454/2454 [==============================] - 2s 869us/step\n",
      "144\n",
      "Epoch 1/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 1.8256 - acc: 0.4137\n",
      "Epoch 2/50\n",
      "15800/15800 [==============================] - 14s 917us/step - loss: 1.4309 - acc: 0.5269\n",
      "Epoch 3/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 1.2738 - acc: 0.5827\n",
      "Epoch 4/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 1.1706 - acc: 0.6172\n",
      "Epoch 5/50\n",
      "15800/15800 [==============================] - 15s 942us/step - loss: 1.0879 - acc: 0.6479\n",
      "Epoch 6/50\n",
      "15800/15800 [==============================] - 16s 983us/step - loss: 1.0242 - acc: 0.6688\n",
      "Epoch 7/50\n",
      "15800/15800 [==============================] - 15s 976us/step - loss: 0.9788 - acc: 0.6843\n",
      "Epoch 8/50\n",
      "15800/15800 [==============================] - 14s 859us/step - loss: 0.9324 - acc: 0.6942\n",
      "Epoch 9/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.8943 - acc: 0.7063\n",
      "Epoch 10/50\n",
      "15800/15800 [==============================] - 16s 989us/step - loss: 0.8619 - acc: 0.7183\n",
      "Epoch 11/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.8283 - acc: 0.7294\n",
      "Epoch 12/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.8018 - acc: 0.7347\n",
      "Epoch 13/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.7716 - acc: 0.7431\n",
      "Epoch 14/50\n",
      "15800/15800 [==============================] - 14s 892us/step - loss: 0.7496 - acc: 0.7513\n",
      "Epoch 15/50\n",
      "15800/15800 [==============================] - 13s 835us/step - loss: 0.7270 - acc: 0.7592\n",
      "Epoch 16/50\n",
      "15800/15800 [==============================] - 16s 989us/step - loss: 0.7032 - acc: 0.7672\n",
      "Epoch 17/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.6850 - acc: 0.7726\n",
      "Epoch 18/50\n",
      "15800/15800 [==============================] - 13s 853us/step - loss: 0.6688 - acc: 0.7770\n",
      "Epoch 19/50\n",
      "15800/15800 [==============================] - 13s 848us/step - loss: 0.6525 - acc: 0.7823\n",
      "Epoch 20/50\n",
      "15800/15800 [==============================] - 14s 876us/step - loss: 0.6375 - acc: 0.7864\n",
      "Epoch 21/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.6226 - acc: 0.7941\n",
      "Epoch 22/50\n",
      "15800/15800 [==============================] - 16s 988us/step - loss: 0.6086 - acc: 0.7966\n",
      "Epoch 23/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.5971 - acc: 0.8007\n",
      "Epoch 24/50\n",
      "15800/15800 [==============================] - 16s 984us/step - loss: 0.5833 - acc: 0.8059\n",
      "Epoch 25/50\n",
      "15800/15800 [==============================] - 15s 924us/step - loss: 0.5726 - acc: 0.8087\n",
      "Epoch 26/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.5636 - acc: 0.8115\n",
      "Epoch 27/50\n",
      "15800/15800 [==============================] - 15s 921us/step - loss: 0.5496 - acc: 0.8183\n",
      "Epoch 28/50\n",
      "15800/15800 [==============================] - 15s 926us/step - loss: 0.5377 - acc: 0.8205\n",
      "Epoch 29/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.5291 - acc: 0.8242\n",
      "Epoch 30/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.5237 - acc: 0.8261\n",
      "Epoch 31/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.5094 - acc: 0.8280\n",
      "Epoch 32/50\n",
      "15800/15800 [==============================] - 22s 1ms/step - loss: 0.5078 - acc: 0.8316\n",
      "Epoch 33/50\n",
      "15800/15800 [==============================] - 15s 970us/step - loss: 0.4914 - acc: 0.8341\n",
      "Epoch 34/50\n",
      "15800/15800 [==============================] - 13s 843us/step - loss: 0.4854 - acc: 0.8365\n",
      "Epoch 35/50\n",
      "15800/15800 [==============================] - 14s 880us/step - loss: 0.4771 - acc: 0.8417\n",
      "Epoch 36/50\n",
      "15800/15800 [==============================] - 13s 851us/step - loss: 0.4705 - acc: 0.8398\n",
      "Epoch 37/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.4669 - acc: 0.8425\n",
      "Epoch 38/50\n",
      "15800/15800 [==============================] - 14s 864us/step - loss: 0.4521 - acc: 0.8494\n",
      "Epoch 39/50\n",
      "15800/15800 [==============================] - 15s 929us/step - loss: 0.4501 - acc: 0.8504\n",
      "Epoch 40/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.4415 - acc: 0.8516\n",
      "Epoch 41/50\n",
      "15800/15800 [==============================] - 14s 888us/step - loss: 0.4368 - acc: 0.8529\n",
      "Epoch 42/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.4378 - acc: 0.8530\n",
      "Epoch 43/50\n",
      "15800/15800 [==============================] - 14s 909us/step - loss: 0.4216 - acc: 0.8575\n",
      "Epoch 44/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.4203 - acc: 0.8564\n",
      "Epoch 45/50\n",
      "15800/15800 [==============================] - 15s 949us/step - loss: 0.4084 - acc: 0.8620\n",
      "Epoch 46/50\n",
      "15800/15800 [==============================] - 16s 987us/step - loss: 0.4051 - acc: 0.8615\n",
      "Epoch 47/50\n",
      "15800/15800 [==============================] - 16s 990us/step - loss: 0.4033 - acc: 0.8624\n",
      "Epoch 48/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.3983 - acc: 0.8671\n",
      "Epoch 49/50\n",
      "15800/15800 [==============================] - ETA: 0s - loss: 0.3934 - acc: 0.867 - 16s 1ms/step - loss: 0.3935 - acc: 0.8672\n",
      "Epoch 50/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.3881 - acc: 0.8691\n",
      "2454/2454 [==============================] - 2s 822us/step\n",
      "160\n",
      "Epoch 1/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 1.8225 - acc: 0.4182\n",
      "Epoch 2/50\n",
      "15800/15800 [==============================] - 13s 834us/step - loss: 1.4143 - acc: 0.5346\n",
      "Epoch 3/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 1.2577 - acc: 0.5884\n",
      "Epoch 4/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 1.1537 - acc: 0.6244\n",
      "Epoch 5/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 1.0713 - acc: 0.6550\n",
      "Epoch 6/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 1.0090 - acc: 0.6745\n",
      "Epoch 7/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.9561 - acc: 0.6901\n",
      "Epoch 8/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.9115 - acc: 0.7011\n",
      "Epoch 9/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.8731 - acc: 0.7142\n",
      "Epoch 10/50\n",
      "15800/15800 [==============================] - 16s 990us/step - loss: 0.8399 - acc: 0.7256\n",
      "Epoch 11/50\n",
      "15800/15800 [==============================] - 15s 960us/step - loss: 0.8054 - acc: 0.7339\n",
      "Epoch 12/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.7807 - acc: 0.7397\n",
      "Epoch 13/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.7557 - acc: 0.7476\n",
      "Epoch 14/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.7348 - acc: 0.7577\n",
      "Epoch 15/50\n",
      "15800/15800 [==============================] - 15s 953us/step - loss: 0.7072 - acc: 0.7642\n",
      "Epoch 16/50\n",
      "15800/15800 [==============================] - 14s 879us/step - loss: 0.6900 - acc: 0.7677\n",
      "Epoch 17/50\n",
      "15800/15800 [==============================] - 15s 958us/step - loss: 0.6755 - acc: 0.7737\n",
      "Epoch 18/50\n",
      "15800/15800 [==============================] - 15s 956us/step - loss: 0.6531 - acc: 0.7793\n",
      "Epoch 19/50\n",
      "15800/15800 [==============================] - 15s 972us/step - loss: 0.6384 - acc: 0.7868\n",
      "Epoch 20/50\n",
      "15800/15800 [==============================] - 14s 902us/step - loss: 0.6197 - acc: 0.7929\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15800/15800 [==============================] - 15s 950us/step - loss: 0.6100 - acc: 0.7965\n",
      "Epoch 22/50\n",
      "15800/15800 [==============================] - 15s 947us/step - loss: 0.5925 - acc: 0.8018\n",
      "Epoch 23/50\n",
      "15800/15800 [==============================] - 15s 943us/step - loss: 0.5772 - acc: 0.8070\n",
      "Epoch 24/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.5667 - acc: 0.8087\n",
      "Epoch 25/50\n",
      "15800/15800 [==============================] - 16s 983us/step - loss: 0.5564 - acc: 0.8130\n",
      "Epoch 26/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.5428 - acc: 0.8169\n",
      "Epoch 27/50\n",
      "15800/15800 [==============================] - 15s 923us/step - loss: 0.5306 - acc: 0.8234\n",
      "Epoch 28/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.5201 - acc: 0.8270\n",
      "Epoch 29/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.5210 - acc: 0.8271\n",
      "Epoch 30/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.5007 - acc: 0.8327\n",
      "Epoch 31/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.4973 - acc: 0.8309\n",
      "Epoch 32/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.4869 - acc: 0.8350\n",
      "Epoch 33/50\n",
      "15800/15800 [==============================] - 15s 927us/step - loss: 0.4727 - acc: 0.8430\n",
      "Epoch 34/50\n",
      "15800/15800 [==============================] - 14s 904us/step - loss: 0.4688 - acc: 0.8409\n",
      "Epoch 35/50\n",
      "15800/15800 [==============================] - 16s 991us/step - loss: 0.4590 - acc: 0.8463\n",
      "Epoch 36/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.4550 - acc: 0.8453\n",
      "Epoch 37/50\n",
      "15800/15800 [==============================] - 14s 904us/step - loss: 0.4468 - acc: 0.8487\n",
      "Epoch 38/50\n",
      "15800/15800 [==============================] - 15s 956us/step - loss: 0.4378 - acc: 0.8541\n",
      "Epoch 39/50\n",
      "15800/15800 [==============================] - 23s 1ms/step - loss: 0.4339 - acc: 0.8523\n",
      "Epoch 40/50\n",
      "15800/15800 [==============================] - 23s 1ms/step - loss: 0.4213 - acc: 0.8591\n",
      "Epoch 41/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.4182 - acc: 0.8556\n",
      "Epoch 42/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.4111 - acc: 0.8634\n",
      "Epoch 43/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.4098 - acc: 0.8622\n",
      "Epoch 44/50\n",
      "15800/15800 [==============================] - 15s 959us/step - loss: 0.4050 - acc: 0.8613\n",
      "Epoch 45/50\n",
      "15800/15800 [==============================] - 15s 927us/step - loss: 0.3960 - acc: 0.8679\n",
      "Epoch 46/50\n",
      "15800/15800 [==============================] - 14s 907us/step - loss: 0.3958 - acc: 0.8684\n",
      "Epoch 47/50\n",
      "15800/15800 [==============================] - 15s 918us/step - loss: 0.3831 - acc: 0.8677\n",
      "Epoch 48/50\n",
      "15800/15800 [==============================] - 14s 888us/step - loss: 0.3820 - acc: 0.8723\n",
      "Epoch 49/50\n",
      "15800/15800 [==============================] - 15s 933us/step - loss: 0.3812 - acc: 0.8730\n",
      "Epoch 50/50\n",
      "15800/15800 [==============================] - 16s 996us/step - loss: 0.3711 - acc: 0.8749\n",
      "2454/2454 [==============================] - 2s 778us/step\n"
     ]
    }
   ],
   "source": [
    "results_nn_pca = defaultdict(list)\n",
    "num_nodes = 0\n",
    "for i in range(10):\n",
    "    num_nodes += 16\n",
    "    estimator = KerasClassifier(model2, epochs=50, batch_size=5, verbose=1)\n",
    "    estimator.fit(X_train_pca_res, y_train_pca_res) #for model2\n",
    "    pred = estimator.predict(X_test_pca)\n",
    "    results_nn_pca[num_nodes].append(accuracy_score(y_test, pred))\n",
    "    #results_nn_pca[num_nodes].append(f1_score(y_test, pred))\n",
    "    results_nn_pca[num_nodes].append(classification_report(y_test, pred))\n",
    "    results_nn_pca[num_nodes].append(create_confusion_matrix(y_test, pred))\n",
    "#print(f'max f1:{min(results_nn_pca, key=lambda x: results_nn_pca[x][1])}\\n')\n",
    "#for k, v in results_nn_pca.items():\n",
    "#    print(f\"nn with {k} nodes in the hidden layer:    acc={v[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Epoch 1/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 1.9977 - acc: 0.4032\n",
      "Epoch 2/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 1.5030 - acc: 0.5465\n",
      "Epoch 3/50\n",
      "15800/15800 [==============================] - 13s 807us/step - loss: 1.3878 - acc: 0.5792\n",
      "Epoch 4/50\n",
      "15800/15800 [==============================] - 12s 775us/step - loss: 1.3231 - acc: 0.5987\n",
      "Epoch 5/50\n",
      "15800/15800 [==============================] - 13s 802us/step - loss: 1.2762 - acc: 0.6097\n",
      "Epoch 6/50\n",
      "15800/15800 [==============================] - 14s 874us/step - loss: 1.2386 - acc: 0.6195\n",
      "Epoch 7/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 1.2101 - acc: 0.6307\n",
      "Epoch 8/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 1.1866 - acc: 0.6396\n",
      "Epoch 9/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 1.1642 - acc: 0.6436\n",
      "Epoch 10/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 1.1401 - acc: 0.6507\n",
      "Epoch 11/50\n",
      "15800/15800 [==============================] - 13s 812us/step - loss: 1.1215 - acc: 0.6620\n",
      "Epoch 12/50\n",
      "15800/15800 [==============================] - 14s 866us/step - loss: 1.1044 - acc: 0.6684\n",
      "Epoch 13/50\n",
      "15800/15800 [==============================] - 14s 896us/step - loss: 1.0906 - acc: 0.6704\n",
      "Epoch 14/50\n",
      "15800/15800 [==============================] - 15s 942us/step - loss: 1.0767 - acc: 0.6744\n",
      "Epoch 15/50\n",
      "15800/15800 [==============================] - 13s 854us/step - loss: 1.0640 - acc: 0.6828\n",
      "Epoch 16/50\n",
      "15800/15800 [==============================] - 15s 952us/step - loss: 1.0538 - acc: 0.6844\n",
      "Epoch 17/50\n",
      "15800/15800 [==============================] - 15s 931us/step - loss: 1.0426 - acc: 0.6874\n",
      "Epoch 18/50\n",
      "15800/15800 [==============================] - 16s 987us/step - loss: 1.0321 - acc: 0.6892\n",
      "Epoch 19/50\n",
      "15800/15800 [==============================] - 14s 888us/step - loss: 1.0228 - acc: 0.6941\n",
      "Epoch 20/50\n",
      "15800/15800 [==============================] - 15s 949us/step - loss: 1.0148 - acc: 0.6947\n",
      "Epoch 21/50\n",
      "15800/15800 [==============================] - 14s 913us/step - loss: 1.0070 - acc: 0.6977\n",
      "Epoch 22/50\n",
      "15800/15800 [==============================] - 15s 928us/step - loss: 0.9985 - acc: 0.6988\n",
      "Epoch 23/50\n",
      "15800/15800 [==============================] - 14s 881us/step - loss: 0.9934 - acc: 0.7058\n",
      "Epoch 24/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.9868 - acc: 0.7056\n",
      "Epoch 25/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.9792 - acc: 0.7054\n",
      "Epoch 26/50\n",
      "15800/15800 [==============================] - 13s 835us/step - loss: 0.9730 - acc: 0.7037\n",
      "Epoch 27/50\n",
      "15800/15800 [==============================] - 15s 959us/step - loss: 0.9674 - acc: 0.7079\n",
      "Epoch 28/50\n",
      "15800/15800 [==============================] - 14s 900us/step - loss: 0.9629 - acc: 0.7084\n",
      "Epoch 29/50\n",
      "15800/15800 [==============================] - 12s 777us/step - loss: 0.9574 - acc: 0.7096\n",
      "Epoch 30/50\n",
      "15800/15800 [==============================] - 15s 941us/step - loss: 0.9534 - acc: 0.7123\n",
      "Epoch 31/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.9496 - acc: 0.7131\n",
      "Epoch 32/50\n",
      "15800/15800 [==============================] - 14s 886us/step - loss: 0.9440 - acc: 0.7150\n",
      "Epoch 33/50\n",
      "15800/15800 [==============================] - 15s 921us/step - loss: 0.9429 - acc: 0.7166\n",
      "Epoch 34/50\n",
      "15800/15800 [==============================] - 13s 805us/step - loss: 0.9383 - acc: 0.7168\n",
      "Epoch 35/50\n",
      "15800/15800 [==============================] - 15s 939us/step - loss: 0.9328 - acc: 0.7197\n",
      "Epoch 36/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.9297 - acc: 0.7204\n",
      "Epoch 37/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.9249 - acc: 0.7189\n",
      "Epoch 38/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.9213 - acc: 0.7189\n",
      "Epoch 39/50\n",
      "15800/15800 [==============================] - 14s 881us/step - loss: 0.9160 - acc: 0.7200\n",
      "Epoch 40/50\n",
      "15800/15800 [==============================] - 14s 863us/step - loss: 0.9134 - acc: 0.7214\n",
      "Epoch 41/50\n",
      "15800/15800 [==============================] - 12s 787us/step - loss: 0.9116 - acc: 0.7207\n",
      "Epoch 42/50\n",
      "15800/15800 [==============================] - 13s 838us/step - loss: 0.9074 - acc: 0.7232\n",
      "Epoch 43/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.9052 - acc: 0.7248\n",
      "Epoch 44/50\n",
      "15800/15800 [==============================] - 14s 918us/step - loss: 0.9033 - acc: 0.7278\n",
      "Epoch 45/50\n",
      "15800/15800 [==============================] - 16s 982us/step - loss: 0.9015 - acc: 0.7252\n",
      "Epoch 46/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.8992 - acc: 0.7233\n",
      "Epoch 47/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.8962 - acc: 0.7279\n",
      "Epoch 48/50\n",
      "15800/15800 [==============================] - 15s 951us/step - loss: 0.8927 - acc: 0.7287\n",
      "Epoch 49/50\n",
      "15800/15800 [==============================] - 15s 947us/step - loss: 0.8918 - acc: 0.7295\n",
      "Epoch 50/50\n",
      "15800/15800 [==============================] - 14s 912us/step - loss: 0.8884 - acc: 0.7312\n",
      "2454/2454 [==============================] - 2s 856us/step\n",
      "32\n",
      "Epoch 1/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 1.7761 - acc: 0.4632\n",
      "Epoch 2/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 1.3026 - acc: 0.6001\n",
      "Epoch 3/50\n",
      "15800/15800 [==============================] - 15s 927us/step - loss: 1.1727 - acc: 0.6377\n",
      "Epoch 4/50\n",
      "15800/15800 [==============================] - 15s 928us/step - loss: 1.0934 - acc: 0.6661\n",
      "Epoch 5/50\n",
      "15800/15800 [==============================] - 14s 917us/step - loss: 1.0283 - acc: 0.6843\n",
      "Epoch 6/50\n",
      "15800/15800 [==============================] - 14s 891us/step - loss: 0.9780 - acc: 0.7027\n",
      "Epoch 7/50\n",
      "15800/15800 [==============================] - 15s 936us/step - loss: 0.9393 - acc: 0.7085\n",
      "Epoch 8/50\n",
      "15800/15800 [==============================] - 14s 916us/step - loss: 0.9046 - acc: 0.7184\n",
      "Epoch 9/50\n",
      "15800/15800 [==============================] - 15s 963us/step - loss: 0.8754 - acc: 0.7289\n",
      "Epoch 10/50\n",
      "15800/15800 [==============================] - 16s 987us/step - loss: 0.8526 - acc: 0.7332\n",
      "Epoch 11/50\n",
      "15800/15800 [==============================] - 15s 934us/step - loss: 0.8300 - acc: 0.7428\n",
      "Epoch 12/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.8055 - acc: 0.7506\n",
      "Epoch 13/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.7892 - acc: 0.7517\n",
      "Epoch 14/50\n",
      "15800/15800 [==============================] - 14s 907us/step - loss: 0.7772 - acc: 0.7574\n",
      "Epoch 15/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.7637 - acc: 0.7624\n",
      "Epoch 16/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.7507 - acc: 0.7672\n",
      "Epoch 17/50\n",
      "15800/15800 [==============================] - 15s 935us/step - loss: 0.7387 - acc: 0.7704\n",
      "Epoch 18/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.7282 - acc: 0.7722\n",
      "Epoch 19/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.7225 - acc: 0.7754\n",
      "Epoch 20/50\n",
      "15800/15800 [==============================] - 26s 2ms/step - loss: 0.7122 - acc: 0.7750\n",
      "Epoch 21/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.7059 - acc: 0.7816\n",
      "Epoch 22/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.6939 - acc: 0.7864\n",
      "Epoch 23/50\n",
      "15800/15800 [==============================] - 16s 989us/step - loss: 0.6906 - acc: 0.7863\n",
      "Epoch 24/50\n",
      "15800/15800 [==============================] - 14s 879us/step - loss: 0.6829 - acc: 0.7892\n",
      "Epoch 25/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.6790 - acc: 0.7894\n",
      "Epoch 26/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.6694 - acc: 0.7929\n",
      "Epoch 27/50\n",
      "15800/15800 [==============================] - 15s 962us/step - loss: 0.6669 - acc: 0.7932\n",
      "Epoch 28/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.6606 - acc: 0.7966\n",
      "Epoch 29/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.6566 - acc: 0.7945\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.6505 - acc: 0.8006\n",
      "Epoch 31/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.6442 - acc: 0.8024\n",
      "Epoch 32/50\n",
      "15800/15800 [==============================] - 15s 921us/step - loss: 0.6416 - acc: 0.8010\n",
      "Epoch 33/50\n",
      "15800/15800 [==============================] - 15s 938us/step - loss: 0.6387 - acc: 0.8008\n",
      "Epoch 34/50\n",
      "15800/15800 [==============================] - 14s 867us/step - loss: 0.6363 - acc: 0.8042\n",
      "Epoch 35/50\n",
      "15800/15800 [==============================] - 14s 858us/step - loss: 0.6278 - acc: 0.8065\n",
      "Epoch 36/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.6272 - acc: 0.8061\n",
      "Epoch 37/50\n",
      "15800/15800 [==============================] - 14s 863us/step - loss: 0.6198 - acc: 0.8087\n",
      "Epoch 38/50\n",
      "15800/15800 [==============================] - 15s 978us/step - loss: 0.6215 - acc: 0.8053\n",
      "Epoch 39/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.6167 - acc: 0.8102\n",
      "Epoch 40/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.6121 - acc: 0.8106\n",
      "Epoch 41/50\n",
      "15800/15800 [==============================] - 13s 792us/step - loss: 0.6124 - acc: 0.8135\n",
      "Epoch 42/50\n",
      "15800/15800 [==============================] - 14s 859us/step - loss: 0.6078 - acc: 0.8127\n",
      "Epoch 43/50\n",
      "15800/15800 [==============================] - 15s 935us/step - loss: 0.6002 - acc: 0.8153\n",
      "Epoch 44/50\n",
      "15800/15800 [==============================] - 22s 1ms/step - loss: 0.6014 - acc: 0.8127\n",
      "Epoch 45/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.5949 - acc: 0.8173\n",
      "Epoch 46/50\n",
      "15800/15800 [==============================] - 14s 877us/step - loss: 0.5933 - acc: 0.8144\n",
      "Epoch 47/50\n",
      "15800/15800 [==============================] - 15s 953us/step - loss: 0.5942 - acc: 0.8191\n",
      "Epoch 48/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.5845 - acc: 0.8204\n",
      "Epoch 49/50\n",
      "15800/15800 [==============================] - 14s 879us/step - loss: 0.5875 - acc: 0.8171\n",
      "Epoch 50/50\n",
      "15800/15800 [==============================] - 13s 822us/step - loss: 0.5840 - acc: 0.8191\n",
      "2454/2454 [==============================] - 2s 939us/step\n",
      "48\n",
      "Epoch 1/50\n",
      "15800/15800 [==============================] - 16s 989us/step - loss: 1.6405 - acc: 0.5063\n",
      "Epoch 2/50\n",
      "15800/15800 [==============================] - 15s 953us/step - loss: 1.2007 - acc: 0.6258\n",
      "Epoch 3/50\n",
      "15800/15800 [==============================] - 15s 938us/step - loss: 1.0706 - acc: 0.6674\n",
      "Epoch 4/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.9837 - acc: 0.6932\n",
      "Epoch 5/50\n",
      "15800/15800 [==============================] - 15s 931us/step - loss: 0.9122 - acc: 0.7144\n",
      "Epoch 6/50\n",
      "15800/15800 [==============================] - 14s 858us/step - loss: 0.8641 - acc: 0.7299\n",
      "Epoch 7/50\n",
      "15800/15800 [==============================] - 15s 922us/step - loss: 0.8188 - acc: 0.7411\n",
      "Epoch 8/50\n",
      "15800/15800 [==============================] - 15s 923us/step - loss: 0.7861 - acc: 0.7527\n",
      "Epoch 9/50\n",
      "15800/15800 [==============================] - 13s 811us/step - loss: 0.7532 - acc: 0.7618\n",
      "Epoch 10/50\n",
      "15800/15800 [==============================] - 16s 984us/step - loss: 0.7228 - acc: 0.7718\n",
      "Epoch 11/50\n",
      "15800/15800 [==============================] - 13s 816us/step - loss: 0.7034 - acc: 0.7756\n",
      "Epoch 12/50\n",
      "15800/15800 [==============================] - 14s 888us/step - loss: 0.6776 - acc: 0.7867\n",
      "Epoch 13/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.6622 - acc: 0.7873\n",
      "Epoch 14/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.6457 - acc: 0.7957\n",
      "Epoch 15/50\n",
      "15800/15800 [==============================] - 14s 900us/step - loss: 0.6313 - acc: 0.8023\n",
      "Epoch 16/50\n",
      "15800/15800 [==============================] - 16s 992us/step - loss: 0.6192 - acc: 0.8046\n",
      "Epoch 17/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.6057 - acc: 0.8070\n",
      "Epoch 18/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.5935 - acc: 0.8146\n",
      "Epoch 19/50\n",
      "15800/15800 [==============================] - 14s 887us/step - loss: 0.5865 - acc: 0.8154\n",
      "Epoch 20/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.5725 - acc: 0.8199\n",
      "Epoch 21/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.5674 - acc: 0.8185\n",
      "Epoch 22/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.5603 - acc: 0.8245\n",
      "Epoch 23/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.5474 - acc: 0.8277\n",
      "Epoch 24/50\n",
      "15800/15800 [==============================] - 22s 1ms/step - loss: 0.5408 - acc: 0.8299\n",
      "Epoch 25/50\n",
      "15800/15800 [==============================] - 15s 955us/step - loss: 0.5360 - acc: 0.8298\n",
      "Epoch 26/50\n",
      "15800/15800 [==============================] - 14s 898us/step - loss: 0.5229 - acc: 0.8370\n",
      "Epoch 27/50\n",
      "15800/15800 [==============================] - 15s 931us/step - loss: 0.5180 - acc: 0.8369\n",
      "Epoch 28/50\n",
      "15800/15800 [==============================] - 15s 920us/step - loss: 0.5139 - acc: 0.8372\n",
      "Epoch 29/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.5026 - acc: 0.8413\n",
      "Epoch 30/50\n",
      "15800/15800 [==============================] - 15s 972us/step - loss: 0.5010 - acc: 0.8421\n",
      "Epoch 31/50\n",
      "15800/15800 [==============================] - 13s 843us/step - loss: 0.4889 - acc: 0.8458\n",
      "Epoch 32/50\n",
      "15800/15800 [==============================] - 14s 908us/step - loss: 0.4845 - acc: 0.8468\n",
      "Epoch 33/50\n",
      "15800/15800 [==============================] - 15s 977us/step - loss: 0.4824 - acc: 0.8508\n",
      "Epoch 34/50\n",
      "15800/15800 [==============================] - 14s 911us/step - loss: 0.4751 - acc: 0.8482\n",
      "Epoch 35/50\n",
      "15800/15800 [==============================] - 16s 988us/step - loss: 0.4710 - acc: 0.8513\n",
      "Epoch 36/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.4668 - acc: 0.8530\n",
      "Epoch 37/50\n",
      "15800/15800 [==============================] - 14s 870us/step - loss: 0.4630 - acc: 0.8553\n",
      "Epoch 38/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.4563 - acc: 0.8550\n",
      "Epoch 39/50\n",
      "15800/15800 [==============================] - 15s 935us/step - loss: 0.4546 - acc: 0.8610\n",
      "Epoch 40/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.4463 - acc: 0.8590\n",
      "Epoch 41/50\n",
      "15800/15800 [==============================] - 15s 968us/step - loss: 0.4453 - acc: 0.8590\n",
      "Epoch 42/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.4402 - acc: 0.8608\n",
      "Epoch 43/50\n",
      "15800/15800 [==============================] - 16s 996us/step - loss: 0.4356 - acc: 0.8601\n",
      "Epoch 44/50\n",
      "15800/15800 [==============================] - 14s 884us/step - loss: 0.4251 - acc: 0.8654\n",
      "Epoch 45/50\n",
      "15800/15800 [==============================] - 14s 914us/step - loss: 0.4290 - acc: 0.8609\n",
      "Epoch 46/50\n",
      "15800/15800 [==============================] - 14s 856us/step - loss: 0.4226 - acc: 0.8688\n",
      "Epoch 47/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.4168 - acc: 0.8677\n",
      "Epoch 48/50\n",
      "15800/15800 [==============================] - 13s 848us/step - loss: 0.4170 - acc: 0.8668\n",
      "Epoch 49/50\n",
      "15800/15800 [==============================] - 16s 983us/step - loss: 0.4132 - acc: 0.8696\n",
      "Epoch 50/50\n",
      "15800/15800 [==============================] - 14s 906us/step - loss: 0.4110 - acc: 0.8704\n",
      "2454/2454 [==============================] - 2s 991us/step\n",
      "64\n",
      "Epoch 1/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 1.5508 - acc: 0.5302\n",
      "Epoch 2/50\n",
      "15800/15800 [==============================] - 15s 928us/step - loss: 1.1372 - acc: 0.6446\n",
      "Epoch 3/50\n",
      "15800/15800 [==============================] - 14s 887us/step - loss: 0.9833 - acc: 0.6949\n",
      "Epoch 4/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.8900 - acc: 0.7199\n",
      "Epoch 5/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.8123 - acc: 0.7465\n",
      "Epoch 6/50\n",
      "15800/15800 [==============================] - 14s 888us/step - loss: 0.7619 - acc: 0.7589\n",
      "Epoch 7/50\n",
      "15800/15800 [==============================] - 15s 920us/step - loss: 0.7172 - acc: 0.7753\n",
      "Epoch 8/50\n",
      "15800/15800 [==============================] - 15s 934us/step - loss: 0.6854 - acc: 0.7842\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.6582 - acc: 0.7934\n",
      "Epoch 10/50\n",
      "15800/15800 [==============================] - 16s 988us/step - loss: 0.6301 - acc: 0.8025\n",
      "Epoch 11/50\n",
      "15800/15800 [==============================] - 14s 890us/step - loss: 0.6032 - acc: 0.8122\n",
      "Epoch 12/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.5839 - acc: 0.8140\n",
      "Epoch 13/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.5683 - acc: 0.8204\n",
      "Epoch 14/50\n",
      "15800/15800 [==============================] - 16s 987us/step - loss: 0.5534 - acc: 0.8282\n",
      "Epoch 15/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.5318 - acc: 0.8292\n",
      "Epoch 16/50\n",
      "15800/15800 [==============================] - 15s 932us/step - loss: 0.5213 - acc: 0.8331\n",
      "Epoch 17/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.5074 - acc: 0.8361\n",
      "Epoch 18/50\n",
      "15800/15800 [==============================] - 16s 992us/step - loss: 0.4941 - acc: 0.8424\n",
      "Epoch 19/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.4801 - acc: 0.8425\n",
      "Epoch 20/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.4697 - acc: 0.8487\n",
      "Epoch 21/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.4599 - acc: 0.8527\n",
      "Epoch 22/50\n",
      "15800/15800 [==============================] - 15s 958us/step - loss: 0.4525 - acc: 0.8544\n",
      "Epoch 23/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.4420 - acc: 0.8581\n",
      "Epoch 24/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.4358 - acc: 0.8565\n",
      "Epoch 25/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.4254 - acc: 0.8632\n",
      "Epoch 26/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.4192 - acc: 0.8654\n",
      "Epoch 27/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.4124 - acc: 0.8676\n",
      "Epoch 28/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.4039 - acc: 0.8697\n",
      "Epoch 29/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.3990 - acc: 0.8698\n",
      "Epoch 30/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.3946 - acc: 0.8708\n",
      "Epoch 31/50\n",
      "15800/15800 [==============================] - 15s 952us/step - loss: 0.3812 - acc: 0.8772\n",
      "Epoch 32/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.3844 - acc: 0.8770\n",
      "Epoch 33/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.3727 - acc: 0.8778\n",
      "Epoch 34/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.3637 - acc: 0.8834\n",
      "Epoch 35/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.3643 - acc: 0.8837\n",
      "Epoch 36/50\n",
      "15800/15800 [==============================] - 16s 993us/step - loss: 0.3636 - acc: 0.8844\n",
      "Epoch 37/50\n",
      "15800/15800 [==============================] - 16s 991us/step - loss: 0.3504 - acc: 0.8839\n",
      "Epoch 38/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.3438 - acc: 0.8877\n",
      "Epoch 39/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.3453 - acc: 0.8862\n",
      "Epoch 40/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.3342 - acc: 0.8917\n",
      "Epoch 41/50\n",
      "15800/15800 [==============================] - 15s 960us/step - loss: 0.3318 - acc: 0.8924\n",
      "Epoch 42/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.3298 - acc: 0.8935\n",
      "Epoch 43/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.3263 - acc: 0.8957\n",
      "Epoch 44/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.3269 - acc: 0.8950\n",
      "Epoch 45/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.3191 - acc: 0.8973\n",
      "Epoch 46/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.3171 - acc: 0.8970\n",
      "Epoch 47/50\n",
      "15800/15800 [==============================] - 15s 972us/step - loss: 0.3149 - acc: 0.8984\n",
      "Epoch 48/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.3062 - acc: 0.9019\n",
      "Epoch 49/50\n",
      "15800/15800 [==============================] - 15s 974us/step - loss: 0.3083 - acc: 0.9004\n",
      "Epoch 50/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.3042 - acc: 0.9028\n",
      "2454/2454 [==============================] - 2s 919us/step\n",
      "80\n",
      "Epoch 1/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 1.5253 - acc: 0.5346\n",
      "Epoch 2/50\n",
      "15800/15800 [==============================] - 15s 954us/step - loss: 1.1164 - acc: 0.6527\n",
      "Epoch 3/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.9721 - acc: 0.6968\n",
      "Epoch 4/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.8701 - acc: 0.7279\n",
      "Epoch 5/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.7950 - acc: 0.7485\n",
      "Epoch 6/50\n",
      "15800/15800 [==============================] - 14s 877us/step - loss: 0.7342 - acc: 0.7687\n",
      "Epoch 7/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.6878 - acc: 0.7801\n",
      "Epoch 8/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.6479 - acc: 0.7944\n",
      "Epoch 9/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.6168 - acc: 0.8068\n",
      "Epoch 10/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.5872 - acc: 0.8126\n",
      "Epoch 11/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.5618 - acc: 0.8220\n",
      "Epoch 12/50\n",
      "15800/15800 [==============================] - 14s 913us/step - loss: 0.5430 - acc: 0.8272\n",
      "Epoch 13/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.5191 - acc: 0.8356\n",
      "Epoch 14/50\n",
      "15800/15800 [==============================] - 15s 918us/step - loss: 0.5027 - acc: 0.8388\n",
      "Epoch 15/50\n",
      "15800/15800 [==============================] - 16s 987us/step - loss: 0.4874 - acc: 0.8458\n",
      "Epoch 16/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.4707 - acc: 0.8514\n",
      "Epoch 17/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.4623 - acc: 0.8504\n",
      "Epoch 18/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.4502 - acc: 0.8558\n",
      "Epoch 19/50\n",
      "15800/15800 [==============================] - 15s 941us/step - loss: 0.4325 - acc: 0.8609\n",
      "Epoch 20/50\n",
      "15800/15800 [==============================] - 15s 949us/step - loss: 0.4195 - acc: 0.8631\n",
      "Epoch 21/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.4157 - acc: 0.8661\n",
      "Epoch 22/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.4002 - acc: 0.8723\n",
      "Epoch 23/50\n",
      "15800/15800 [==============================] - 15s 952us/step - loss: 0.3976 - acc: 0.8739\n",
      "Epoch 24/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.3847 - acc: 0.8753\n",
      "Epoch 25/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.3722 - acc: 0.8818\n",
      "Epoch 26/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.3688 - acc: 0.8799\n",
      "Epoch 27/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.3636 - acc: 0.8797\n",
      "Epoch 28/50\n",
      "15800/15800 [==============================] - 14s 895us/step - loss: 0.3529 - acc: 0.8870\n",
      "Epoch 29/50\n",
      "15800/15800 [==============================] - 14s 858us/step - loss: 0.3445 - acc: 0.8874\n",
      "Epoch 30/50\n",
      "15800/15800 [==============================] - 15s 930us/step - loss: 0.3441 - acc: 0.8869\n",
      "Epoch 31/50\n",
      "15800/15800 [==============================] - 15s 948us/step - loss: 0.3286 - acc: 0.8937\n",
      "Epoch 32/50\n",
      "15800/15800 [==============================] - 14s 877us/step - loss: 0.3321 - acc: 0.8931\n",
      "Epoch 33/50\n",
      "15800/15800 [==============================] - 15s 956us/step - loss: 0.3171 - acc: 0.8963\n",
      "Epoch 34/50\n",
      "15800/15800 [==============================] - 15s 928us/step - loss: 0.3223 - acc: 0.8985\n",
      "Epoch 35/50\n",
      "15800/15800 [==============================] - 14s 912us/step - loss: 0.3121 - acc: 0.8974\n",
      "Epoch 36/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.3114 - acc: 0.8979\n",
      "Epoch 37/50\n",
      "15800/15800 [==============================] - 26s 2ms/step - loss: 0.3006 - acc: 0.9046\n",
      "Epoch 38/50\n",
      "15800/15800 [==============================] - 16s 986us/step - loss: 0.3081 - acc: 0.9025\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.2940 - acc: 0.9058\n",
      "Epoch 40/50\n",
      "15800/15800 [==============================] - 16s 992us/step - loss: 0.2952 - acc: 0.9044\n",
      "Epoch 41/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.2871 - acc: 0.9066\n",
      "Epoch 42/50\n",
      "15800/15800 [==============================] - 15s 972us/step - loss: 0.2920 - acc: 0.9049\n",
      "Epoch 43/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.2839 - acc: 0.9113\n",
      "Epoch 44/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.2756 - acc: 0.9121\n",
      "Epoch 45/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.2717 - acc: 0.9127\n",
      "Epoch 46/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.2623 - acc: 0.9128\n",
      "Epoch 47/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.2711 - acc: 0.9148\n",
      "Epoch 48/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.2646 - acc: 0.9149\n",
      "Epoch 49/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.2594 - acc: 0.9154\n",
      "Epoch 50/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.2508 - acc: 0.9174\n",
      "2454/2454 [==============================] - 3s 1ms/step\n",
      "96\n",
      "Epoch 1/50\n",
      "15800/15800 [==============================] - 27s 2ms/step - loss: 1.4854 - acc: 0.5425\n",
      "Epoch 2/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 1.0708 - acc: 0.6672\n",
      "Epoch 3/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.9138 - acc: 0.7144\n",
      "Epoch 4/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.8143 - acc: 0.7433\n",
      "Epoch 5/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.7435 - acc: 0.7670\n",
      "Epoch 6/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.6866 - acc: 0.7846\n",
      "Epoch 7/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.6387 - acc: 0.7973\n",
      "Epoch 8/50\n",
      "15800/15800 [==============================] - 16s 987us/step - loss: 0.5968 - acc: 0.8106\n",
      "Epoch 9/50\n",
      "15800/15800 [==============================] - 16s 993us/step - loss: 0.5704 - acc: 0.8191\n",
      "Epoch 10/50\n",
      "15800/15800 [==============================] - 14s 912us/step - loss: 0.5418 - acc: 0.8280\n",
      "Epoch 11/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.5138 - acc: 0.8359\n",
      "Epoch 12/50\n",
      "15800/15800 [==============================] - 16s 983us/step - loss: 0.4897 - acc: 0.8447\n",
      "Epoch 13/50\n",
      "15800/15800 [==============================] - 13s 805us/step - loss: 0.4738 - acc: 0.8492\n",
      "Epoch 14/50\n",
      "15800/15800 [==============================] - 14s 895us/step - loss: 0.4539 - acc: 0.8572\n",
      "Epoch 15/50\n",
      "15800/15800 [==============================] - 15s 961us/step - loss: 0.4378 - acc: 0.8599\n",
      "Epoch 16/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.4240 - acc: 0.8578\n",
      "Epoch 17/50\n",
      "15800/15800 [==============================] - 14s 916us/step - loss: 0.4036 - acc: 0.8684\n",
      "Epoch 18/50\n",
      "15800/15800 [==============================] - 15s 931us/step - loss: 0.3948 - acc: 0.8742\n",
      "Epoch 19/50\n",
      "15800/15800 [==============================] - 14s 875us/step - loss: 0.3824 - acc: 0.8771\n",
      "Epoch 20/50\n",
      "15800/15800 [==============================] - 14s 900us/step - loss: 0.3700 - acc: 0.8797\n",
      "Epoch 21/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.3570 - acc: 0.8856\n",
      "Epoch 22/50\n",
      "15800/15800 [==============================] - 16s 1000us/step - loss: 0.3456 - acc: 0.8877\n",
      "Epoch 23/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.3440 - acc: 0.8908\n",
      "Epoch 24/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.3322 - acc: 0.8894\n",
      "Epoch 25/50\n",
      "15800/15800 [==============================] - 16s 997us/step - loss: 0.3190 - acc: 0.8951\n",
      "Epoch 26/50\n",
      "15800/15800 [==============================] - 14s 903us/step - loss: 0.3169 - acc: 0.8972\n",
      "Epoch 27/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.3062 - acc: 0.9018\n",
      "Epoch 28/50\n",
      "15800/15800 [==============================] - 14s 871us/step - loss: 0.2968 - acc: 0.9038\n",
      "Epoch 29/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.2976 - acc: 0.9034\n",
      "Epoch 30/50\n",
      "15800/15800 [==============================] - 15s 923us/step - loss: 0.2955 - acc: 0.9037\n",
      "Epoch 31/50\n",
      "15800/15800 [==============================] - 15s 969us/step - loss: 0.2806 - acc: 0.9078\n",
      "Epoch 32/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.2745 - acc: 0.9108\n",
      "Epoch 33/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.2824 - acc: 0.9089\n",
      "Epoch 34/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.2669 - acc: 0.9121\n",
      "Epoch 35/50\n",
      "15800/15800 [==============================] - 15s 970us/step - loss: 0.2646 - acc: 0.9133\n",
      "Epoch 36/50\n",
      "15800/15800 [==============================] - 16s 988us/step - loss: 0.2565 - acc: 0.9162\n",
      "Epoch 37/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.2563 - acc: 0.9159\n",
      "Epoch 38/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.2447 - acc: 0.9206\n",
      "Epoch 39/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.2432 - acc: 0.9218\n",
      "Epoch 40/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.2446 - acc: 0.9202\n",
      "Epoch 41/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.2380 - acc: 0.9223\n",
      "Epoch 42/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.2303 - acc: 0.9259\n",
      "Epoch 43/50\n",
      "15800/15800 [==============================] - 25s 2ms/step - loss: 0.2246 - acc: 0.9293\n",
      "Epoch 44/50\n",
      "15800/15800 [==============================] - 16s 985us/step - loss: 0.2301 - acc: 0.9263\n",
      "Epoch 45/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.2256 - acc: 0.9264\n",
      "Epoch 46/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.2164 - acc: 0.9303\n",
      "Epoch 47/50\n",
      "15800/15800 [==============================] - 15s 980us/step - loss: 0.2157 - acc: 0.9307\n",
      "Epoch 48/50\n",
      "15800/15800 [==============================] - 15s 968us/step - loss: 0.2137 - acc: 0.9285\n",
      "Epoch 49/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.2074 - acc: 0.9332\n",
      "Epoch 50/50\n",
      "15800/15800 [==============================] - 14s 915us/step - loss: 0.2129 - acc: 0.9325\n",
      "2454/2454 [==============================] - 2s 888us/step\n",
      "112\n",
      "Epoch 1/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 1.4633 - acc: 0.5453\n",
      "Epoch 2/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 1.0497 - acc: 0.6673\n",
      "Epoch 3/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.8890 - acc: 0.7151\n",
      "Epoch 4/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.7911 - acc: 0.7488\n",
      "Epoch 5/50\n",
      "15800/15800 [==============================] - 22s 1ms/step - loss: 0.7164 - acc: 0.7715\n",
      "Epoch 6/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.6588 - acc: 0.7906\n",
      "Epoch 7/50\n",
      "15800/15800 [==============================] - 14s 917us/step - loss: 0.6176 - acc: 0.8036\n",
      "Epoch 8/50\n",
      "15800/15800 [==============================] - 16s 991us/step - loss: 0.5728 - acc: 0.8155\n",
      "Epoch 9/50\n",
      "15800/15800 [==============================] - 14s 901us/step - loss: 0.5425 - acc: 0.8242\n",
      "Epoch 10/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.5178 - acc: 0.8360\n",
      "Epoch 11/50\n",
      "15800/15800 [==============================] - 16s 989us/step - loss: 0.4894 - acc: 0.8402\n",
      "Epoch 12/50\n",
      "15800/15800 [==============================] - 15s 965us/step - loss: 0.4748 - acc: 0.8480\n",
      "Epoch 13/50\n",
      "15800/15800 [==============================] - 15s 925us/step - loss: 0.4472 - acc: 0.8555\n",
      "Epoch 14/50\n",
      "15800/15800 [==============================] - 15s 955us/step - loss: 0.4287 - acc: 0.8604\n",
      "Epoch 15/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.4140 - acc: 0.8655\n",
      "Epoch 16/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.3949 - acc: 0.8730\n",
      "Epoch 17/50\n",
      "15800/15800 [==============================] - 16s 1000us/step - loss: 0.3939 - acc: 0.8723\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15800/15800 [==============================] - 15s 959us/step - loss: 0.3711 - acc: 0.8804\n",
      "Epoch 19/50\n",
      "15800/15800 [==============================] - 15s 952us/step - loss: 0.3555 - acc: 0.8856\n",
      "Epoch 20/50\n",
      "15800/15800 [==============================] - 16s 988us/step - loss: 0.3510 - acc: 0.8832\n",
      "Epoch 21/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.3390 - acc: 0.8904\n",
      "Epoch 22/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.3273 - acc: 0.8929\n",
      "Epoch 23/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.3216 - acc: 0.8949\n",
      "Epoch 24/50\n",
      "15800/15800 [==============================] - 16s 989us/step - loss: 0.3075 - acc: 0.9001\n",
      "Epoch 25/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.3072 - acc: 0.9001\n",
      "Epoch 26/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.2968 - acc: 0.9020\n",
      "Epoch 27/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.2946 - acc: 0.9029\n",
      "Epoch 28/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.2823 - acc: 0.9054\n",
      "Epoch 29/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.2739 - acc: 0.9108\n",
      "Epoch 30/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.2683 - acc: 0.9108\n",
      "Epoch 31/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.2686 - acc: 0.9127\n",
      "Epoch 32/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.2612 - acc: 0.9149\n",
      "Epoch 33/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.2536 - acc: 0.9172\n",
      "Epoch 34/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.2474 - acc: 0.9172\n",
      "Epoch 35/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.2457 - acc: 0.9197\n",
      "Epoch 36/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.2471 - acc: 0.9204\n",
      "Epoch 37/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.2409 - acc: 0.9235\n",
      "Epoch 38/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.2365 - acc: 0.9210\n",
      "Epoch 39/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.2207 - acc: 0.9261\n",
      "Epoch 40/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.2262 - acc: 0.9275\n",
      "Epoch 41/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.2201 - acc: 0.9261\n",
      "Epoch 42/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.2114 - acc: 0.9303\n",
      "Epoch 43/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.2202 - acc: 0.9259\n",
      "Epoch 44/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.2154 - acc: 0.9301\n",
      "Epoch 45/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.2126 - acc: 0.9285\n",
      "Epoch 46/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.2091 - acc: 0.9319\n",
      "Epoch 47/50\n",
      "15800/15800 [==============================] - 22s 1ms/step - loss: 0.2034 - acc: 0.9317\n",
      "Epoch 48/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.1952 - acc: 0.9370\n",
      "Epoch 49/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.1998 - acc: 0.9367\n",
      "Epoch 50/50\n",
      "15800/15800 [==============================] - 33s 2ms/step - loss: 0.1939 - acc: 0.9363\n",
      "2454/2454 [==============================] - 4s 2ms/step\n",
      "128\n",
      "Epoch 1/50\n",
      "15800/15800 [==============================] - 25s 2ms/step - loss: 1.4381 - acc: 0.5576\n",
      "Epoch 2/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 1.0288 - acc: 0.6756\n",
      "Epoch 3/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.8693 - acc: 0.7226\n",
      "Epoch 4/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.7637 - acc: 0.7568\n",
      "Epoch 5/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.6871 - acc: 0.7791\n",
      "Epoch 6/50\n",
      "15800/15800 [==============================] - 14s 913us/step - loss: 0.6311 - acc: 0.7969\n",
      "Epoch 7/50\n",
      "15800/15800 [==============================] - 23s 1ms/step - loss: 0.5884 - acc: 0.8118\n",
      "Epoch 8/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.5422 - acc: 0.8261\n",
      "Epoch 9/50\n",
      "15800/15800 [==============================] - 22s 1ms/step - loss: 0.5093 - acc: 0.8354\n",
      "Epoch 10/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.4795 - acc: 0.8447\n",
      "Epoch 11/50\n",
      "15800/15800 [==============================] - 15s 967us/step - loss: 0.4571 - acc: 0.8498\n",
      "Epoch 12/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.4340 - acc: 0.8616\n",
      "Epoch 13/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.4152 - acc: 0.8664\n",
      "Epoch 14/50\n",
      "15800/15800 [==============================] - 15s 978us/step - loss: 0.3955 - acc: 0.8689\n",
      "Epoch 15/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.3737 - acc: 0.8785\n",
      "Epoch 16/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.3635 - acc: 0.8789\n",
      "Epoch 17/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.3487 - acc: 0.8865\n",
      "Epoch 18/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.3309 - acc: 0.8922\n",
      "Epoch 19/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.3366 - acc: 0.8916\n",
      "Epoch 20/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.3270 - acc: 0.8962\n",
      "Epoch 21/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.2976 - acc: 0.9016\n",
      "Epoch 22/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.2961 - acc: 0.9059\n",
      "Epoch 23/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.2837 - acc: 0.9060\n",
      "Epoch 24/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.2763 - acc: 0.9103\n",
      "Epoch 25/50\n",
      "15800/15800 [==============================] - 15s 962us/step - loss: 0.2684 - acc: 0.9109\n",
      "Epoch 26/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.2602 - acc: 0.9147\n",
      "Epoch 27/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.2705 - acc: 0.9149\n",
      "Epoch 28/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.2550 - acc: 0.9178\n",
      "Epoch 29/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.2592 - acc: 0.9185\n",
      "Epoch 30/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.2346 - acc: 0.9244\n",
      "Epoch 31/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.2305 - acc: 0.9221\n",
      "Epoch 32/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.2274 - acc: 0.9249\n",
      "Epoch 33/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.2190 - acc: 0.9270\n",
      "Epoch 34/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.2238 - acc: 0.9266\n",
      "Epoch 35/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.2237 - acc: 0.9278\n",
      "Epoch 36/50\n",
      "15800/15800 [==============================] - 22s 1ms/step - loss: 0.2015 - acc: 0.9319\n",
      "Epoch 37/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.2193 - acc: 0.9306\n",
      "Epoch 38/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.2007 - acc: 0.9316\n",
      "Epoch 39/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.2071 - acc: 0.9329\n",
      "Epoch 40/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.1910 - acc: 0.9368\n",
      "Epoch 41/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.1879 - acc: 0.9384\n",
      "Epoch 42/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.1861 - acc: 0.9403\n",
      "Epoch 43/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.1812 - acc: 0.9392\n",
      "Epoch 44/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.1804 - acc: 0.9397\n",
      "Epoch 45/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.1928 - acc: 0.9385\n",
      "Epoch 46/50\n",
      "15800/15800 [==============================] - 22s 1ms/step - loss: 0.1831 - acc: 0.9420\n",
      "Epoch 47/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.1748 - acc: 0.9426\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.1613 - acc: 0.9459\n",
      "Epoch 49/50\n",
      "15800/15800 [==============================] - 25s 2ms/step - loss: 0.1651 - acc: 0.9444\n",
      "Epoch 50/50\n",
      "15800/15800 [==============================] - 22s 1ms/step - loss: 0.1643 - acc: 0.9437\n",
      "2454/2454 [==============================] - 3s 1ms/step\n",
      "144\n",
      "Epoch 1/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 1.4311 - acc: 0.5589\n",
      "Epoch 2/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 1.0063 - acc: 0.6853\n",
      "Epoch 3/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.8460 - acc: 0.7313\n",
      "Epoch 4/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.7397 - acc: 0.7647\n",
      "Epoch 5/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.6637 - acc: 0.7882\n",
      "Epoch 6/50\n",
      "15800/15800 [==============================] - 16s 981us/step - loss: 0.6050 - acc: 0.8076\n",
      "Epoch 7/50\n",
      "15800/15800 [==============================] - 16s 981us/step - loss: 0.5582 - acc: 0.8222\n",
      "Epoch 8/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.5179 - acc: 0.8339\n",
      "Epoch 9/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.4805 - acc: 0.8466\n",
      "Epoch 10/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.4553 - acc: 0.8498\n",
      "Epoch 11/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.4394 - acc: 0.8561\n",
      "Epoch 12/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.4086 - acc: 0.8675\n",
      "Epoch 13/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.3918 - acc: 0.8738\n",
      "Epoch 14/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.3782 - acc: 0.8818\n",
      "Epoch 15/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.3615 - acc: 0.8813\n",
      "Epoch 16/50\n",
      "15800/15800 [==============================] - 15s 968us/step - loss: 0.3423 - acc: 0.8887\n",
      "Epoch 17/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.3318 - acc: 0.8939\n",
      "Epoch 18/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.3155 - acc: 0.8965\n",
      "Epoch 19/50\n",
      "15800/15800 [==============================] - 15s 957us/step - loss: 0.3031 - acc: 0.8978\n",
      "Epoch 20/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.2958 - acc: 0.9048\n",
      "Epoch 21/50\n",
      "15800/15800 [==============================] - 15s 973us/step - loss: 0.2925 - acc: 0.9035\n",
      "Epoch 22/50\n",
      "15800/15800 [==============================] - 15s 971us/step - loss: 0.2708 - acc: 0.9089\n",
      "Epoch 23/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.2695 - acc: 0.9121\n",
      "Epoch 24/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.2726 - acc: 0.9111\n",
      "Epoch 25/50\n",
      "15800/15800 [==============================] - 15s 931us/step - loss: 0.2538 - acc: 0.9175\n",
      "Epoch 26/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.2475 - acc: 0.9172\n",
      "Epoch 27/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.2354 - acc: 0.9208\n",
      "Epoch 28/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.2332 - acc: 0.9220\n",
      "Epoch 29/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.2328 - acc: 0.9268\n",
      "Epoch 30/50\n",
      "15800/15800 [==============================] - 15s 974us/step - loss: 0.2186 - acc: 0.9277\n",
      "Epoch 31/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.2221 - acc: 0.9262\n",
      "Epoch 32/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.2140 - acc: 0.9292\n",
      "Epoch 33/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.2061 - acc: 0.9308\n",
      "Epoch 34/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.2032 - acc: 0.9335\n",
      "Epoch 35/50\n",
      "15800/15800 [==============================] - 16s 983us/step - loss: 0.1928 - acc: 0.9382\n",
      "Epoch 36/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.1973 - acc: 0.9363\n",
      "Epoch 37/50\n",
      "15800/15800 [==============================] - 15s 981us/step - loss: 0.1924 - acc: 0.9378\n",
      "Epoch 38/50\n",
      "15800/15800 [==============================] - 16s 993us/step - loss: 0.1900 - acc: 0.9381\n",
      "Epoch 39/50\n",
      "15800/15800 [==============================] - 15s 948us/step - loss: 0.1786 - acc: 0.9423\n",
      "Epoch 40/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.1758 - acc: 0.9423\n",
      "Epoch 41/50\n",
      "15800/15800 [==============================] - 24s 2ms/step - loss: 0.1922 - acc: 0.9389\n",
      "Epoch 42/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.1865 - acc: 0.9421\n",
      "Epoch 43/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.1638 - acc: 0.9471\n",
      "Epoch 44/50\n",
      "15800/15800 [==============================] - 25s 2ms/step - loss: 0.1792 - acc: 0.9420\n",
      "Epoch 45/50\n",
      "15800/15800 [==============================] - 26s 2ms/step - loss: 0.1673 - acc: 0.9450\n",
      "Epoch 46/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.1672 - acc: 0.9453\n",
      "Epoch 47/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.1635 - acc: 0.9490\n",
      "Epoch 48/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.1604 - acc: 0.9477\n",
      "Epoch 49/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.1459 - acc: 0.9522\n",
      "Epoch 50/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.1666 - acc: 0.9479\n",
      "2454/2454 [==============================] - 3s 1ms/step\n",
      "160\n",
      "Epoch 1/50\n",
      "15800/15800 [==============================] - 24s 2ms/step - loss: 1.4208 - acc: 0.5645\n",
      "Epoch 2/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.9978 - acc: 0.6885\n",
      "Epoch 3/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.8331 - acc: 0.7391\n",
      "Epoch 4/50\n",
      "15800/15800 [==============================] - 24s 2ms/step - loss: 0.7216 - acc: 0.7682\n",
      "Epoch 5/50\n",
      "15800/15800 [==============================] - 22s 1ms/step - loss: 0.6507 - acc: 0.7916\n",
      "Epoch 6/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.5895 - acc: 0.8116\n",
      "Epoch 7/50\n",
      "15800/15800 [==============================] - 22s 1ms/step - loss: 0.5382 - acc: 0.8254\n",
      "Epoch 8/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.4991 - acc: 0.8380\n",
      "Epoch 9/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.4641 - acc: 0.8520\n",
      "Epoch 10/50\n",
      "15800/15800 [==============================] - 23s 1ms/step - loss: 0.4299 - acc: 0.8621\n",
      "Epoch 11/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.4010 - acc: 0.8678\n",
      "Epoch 12/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.3816 - acc: 0.8772\n",
      "Epoch 13/50\n",
      "15800/15800 [==============================] - 23s 1ms/step - loss: 0.3730 - acc: 0.8802\n",
      "Epoch 14/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.3477 - acc: 0.8864\n",
      "Epoch 15/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.3302 - acc: 0.8923\n",
      "Epoch 16/50\n",
      "15800/15800 [==============================] - 24s 2ms/step - loss: 0.3124 - acc: 0.8989\n",
      "Epoch 17/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.3069 - acc: 0.8984\n",
      "Epoch 18/50\n",
      "15800/15800 [==============================] - 25s 2ms/step - loss: 0.2936 - acc: 0.9045\n",
      "Epoch 19/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.2862 - acc: 0.9043\n",
      "Epoch 20/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.2717 - acc: 0.9116\n",
      "Epoch 21/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.2649 - acc: 0.9137\n",
      "Epoch 22/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.2579 - acc: 0.9162\n",
      "Epoch 23/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.2502 - acc: 0.9178\n",
      "Epoch 24/50\n",
      "15800/15800 [==============================] - 16s 998us/step - loss: 0.2383 - acc: 0.9215\n",
      "Epoch 25/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.2427 - acc: 0.9208\n",
      "Epoch 26/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.2208 - acc: 0.9254\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.2210 - acc: 0.9273\n",
      "Epoch 28/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.2146 - acc: 0.9296\n",
      "Epoch 29/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.2225 - acc: 0.9299\n",
      "Epoch 30/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.2069 - acc: 0.9353\n",
      "Epoch 31/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.2007 - acc: 0.9341\n",
      "Epoch 32/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.1968 - acc: 0.9366\n",
      "Epoch 33/50\n",
      "15800/15800 [==============================] - 16s 983us/step - loss: 0.1885 - acc: 0.9373\n",
      "Epoch 34/50\n",
      "15800/15800 [==============================] - 15s 934us/step - loss: 0.1935 - acc: 0.9398\n",
      "Epoch 35/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.1932 - acc: 0.9381\n",
      "Epoch 36/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.1788 - acc: 0.9416\n",
      "Epoch 37/50\n",
      "15800/15800 [==============================] - 20s 1ms/step - loss: 0.1801 - acc: 0.9416\n",
      "Epoch 38/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.1673 - acc: 0.9468\n",
      "Epoch 39/50\n",
      "15800/15800 [==============================] - 15s 966us/step - loss: 0.1639 - acc: 0.9472\n",
      "Epoch 40/50\n",
      "15800/15800 [==============================] - 15s 953us/step - loss: 0.1713 - acc: 0.9466\n",
      "Epoch 41/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.1622 - acc: 0.9467\n",
      "Epoch 42/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.1571 - acc: 0.9478\n",
      "Epoch 43/50\n",
      "15800/15800 [==============================] - 16s 991us/step - loss: 0.1542 - acc: 0.9506\n",
      "Epoch 44/50\n",
      "15800/15800 [==============================] - 17s 1ms/step - loss: 0.1632 - acc: 0.9503\n",
      "Epoch 45/50\n",
      "15800/15800 [==============================] - 16s 1ms/step - loss: 0.1486 - acc: 0.9508\n",
      "Epoch 46/50\n",
      "15800/15800 [==============================] - 16s 990us/step - loss: 0.1536 - acc: 0.9518\n",
      "Epoch 47/50\n",
      "15800/15800 [==============================] - 19s 1ms/step - loss: 0.1451 - acc: 0.9534\n",
      "Epoch 48/50\n",
      "15800/15800 [==============================] - 25s 2ms/step - loss: 0.1521 - acc: 0.9528\n",
      "Epoch 49/50\n",
      "15800/15800 [==============================] - 18s 1ms/step - loss: 0.1562 - acc: 0.9558\n",
      "Epoch 50/50\n",
      "15800/15800 [==============================] - 21s 1ms/step - loss: 0.1565 - acc: 0.9491\n",
      "2454/2454 [==============================] - 3s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "results_nn_lda = defaultdict(list)\n",
    "num_nodes = 0\n",
    "for i in range(10):\n",
    "    num_nodes += 16\n",
    "    estimator = KerasClassifier(model3, epochs=50, batch_size=5, verbose=1)\n",
    "    estimator.fit(X_train_lda_res, y_train_lda_res) #for model2\n",
    "    pred = estimator.predict(X_test_lda)\n",
    "    results_nn_lda[num_nodes].append(accuracy_score(y_test, pred))\n",
    "    #results_nn_lda[num_nodes].append(f1_score(y_test, pred))\n",
    "    results_nn_lda[num_nodes].append(classification_report(y_test, pred))\n",
    "    results_nn_lda[num_nodes].append(create_confusion_matrix(y_test, pred))\n",
    "#print(f'max f1:{min(results_nn_lda, key=lambda x: results_nn_lda[x][1])}\\n')\n",
    "#for k, v in results_nn_lda.items():\n",
    "#    print(f\"nn with {k} nodes in the hidden layer:    acc={v[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn with 16 nodes in the hidden layer:    acc=0.7224938875305623\n",
      "nn with 16 nodes in the hidden layer:    acc=                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.33      0.43      0.37        47\n",
      "                         Baby Foods       0.69      0.46      0.56       112\n",
      "                     Baked Products       0.93      0.77      0.84       229\n",
      "                      Beef Products       0.94      0.90      0.92       286\n",
      "                          Beverages       0.56      0.80      0.66        90\n",
      "                  Breakfast Cereals       0.81      0.85      0.83       115\n",
      "            Cereal Grains and Pasta       0.53      0.76      0.62        50\n",
      "             Dairy and Egg Products       0.76      0.85      0.80        86\n",
      "                         Fast Foods       0.81      0.46      0.58       114\n",
      "                      Fats and Oils       0.88      0.93      0.90        55\n",
      "     Finfish and Shellfish Products       0.80      0.87      0.84        70\n",
      "            Fruits and Fruit Juices       0.55      0.61      0.58        87\n",
      "      Lamb, Veal, and Game Products       0.72      0.84      0.77       106\n",
      "        Legumes and Legume Products       0.80      0.69      0.74       108\n",
      "    Meals, Entrees, and Side Dishes       0.22      0.41      0.29        34\n",
      "              Nut and Seed Products       0.64      0.81      0.72        47\n",
      "                      Pork Products       0.86      0.81      0.83        99\n",
      "                   Poultry Products       0.76      0.78      0.77       111\n",
      "                   Restaurant Foods       0.27      0.72      0.40        32\n",
      "        Sausages and Luncheon Meats       0.71      0.51      0.59        71\n",
      "                             Snacks       0.50      0.64      0.56        39\n",
      "         Soups, Sauces, and Gravies       0.71      0.66      0.68       118\n",
      "                   Spices and Herbs       0.58      0.58      0.58        24\n",
      "                             Sweets       0.63      0.66      0.65        97\n",
      "  Vegetables and Vegetable Products       0.83      0.64      0.72       227\n",
      "\n",
      "                          micro avg       0.72      0.72      0.72      2454\n",
      "                          macro avg       0.67      0.70      0.67      2454\n",
      "                       weighted avg       0.75      0.72      0.73      2454\n",
      "\n",
      "nn with 32 nodes in the hidden layer:    acc=0.7579462102689487\n",
      "nn with 32 nodes in the hidden layer:    acc=                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.48      0.60      0.53        47\n",
      "                         Baby Foods       0.69      0.52      0.59       112\n",
      "                     Baked Products       0.93      0.83      0.88       229\n",
      "                      Beef Products       0.94      0.90      0.92       286\n",
      "                          Beverages       0.54      0.81      0.65        90\n",
      "                  Breakfast Cereals       0.82      0.89      0.85       115\n",
      "            Cereal Grains and Pasta       0.61      0.84      0.71        50\n",
      "             Dairy and Egg Products       0.84      0.85      0.84        86\n",
      "                         Fast Foods       0.72      0.68      0.70       114\n",
      "                      Fats and Oils       0.91      0.87      0.89        55\n",
      "     Finfish and Shellfish Products       0.81      0.89      0.84        70\n",
      "            Fruits and Fruit Juices       0.52      0.78      0.63        87\n",
      "      Lamb, Veal, and Game Products       0.64      0.83      0.72       106\n",
      "        Legumes and Legume Products       0.76      0.71      0.74       108\n",
      "    Meals, Entrees, and Side Dishes       0.38      0.53      0.44        34\n",
      "              Nut and Seed Products       0.77      0.72      0.75        47\n",
      "                      Pork Products       0.91      0.87      0.89        99\n",
      "                   Poultry Products       0.86      0.80      0.83       111\n",
      "                   Restaurant Foods       0.53      0.59      0.56        32\n",
      "        Sausages and Luncheon Meats       0.86      0.59      0.70        71\n",
      "                             Snacks       0.53      0.59      0.56        39\n",
      "         Soups, Sauces, and Gravies       0.78      0.58      0.66       118\n",
      "                   Spices and Herbs       0.64      0.58      0.61        24\n",
      "                             Sweets       0.70      0.64      0.67        97\n",
      "  Vegetables and Vegetable Products       0.82      0.72      0.77       227\n",
      "\n",
      "                          micro avg       0.76      0.76      0.76      2454\n",
      "                          macro avg       0.72      0.73      0.72      2454\n",
      "                       weighted avg       0.78      0.76      0.76      2454\n",
      "\n",
      "nn with 48 nodes in the hidden layer:    acc=0.7815810920945395\n",
      "nn with 48 nodes in the hidden layer:    acc=                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.41      0.60      0.49        47\n",
      "                         Baby Foods       0.68      0.62      0.65       112\n",
      "                     Baked Products       0.94      0.76      0.84       229\n",
      "                      Beef Products       0.96      0.89      0.92       286\n",
      "                          Beverages       0.73      0.73      0.73        90\n",
      "                  Breakfast Cereals       0.85      0.86      0.86       115\n",
      "            Cereal Grains and Pasta       0.66      0.86      0.75        50\n",
      "             Dairy and Egg Products       0.80      0.81      0.80        86\n",
      "                         Fast Foods       0.81      0.65      0.72       114\n",
      "                      Fats and Oils       0.80      0.95      0.87        55\n",
      "     Finfish and Shellfish Products       0.94      0.84      0.89        70\n",
      "            Fruits and Fruit Juices       0.72      0.59      0.65        87\n",
      "      Lamb, Veal, and Game Products       0.71      0.85      0.77       106\n",
      "        Legumes and Legume Products       0.79      0.78      0.78       108\n",
      "    Meals, Entrees, and Side Dishes       0.39      0.68      0.49        34\n",
      "              Nut and Seed Products       0.74      0.91      0.82        47\n",
      "                      Pork Products       0.93      0.89      0.91        99\n",
      "                   Poultry Products       0.87      0.87      0.87       111\n",
      "                   Restaurant Foods       0.49      0.69      0.57        32\n",
      "        Sausages and Luncheon Meats       0.73      0.76      0.74        71\n",
      "                             Snacks       0.61      0.69      0.65        39\n",
      "         Soups, Sauces, and Gravies       0.71      0.74      0.72       118\n",
      "                   Spices and Herbs       0.62      0.62      0.62        24\n",
      "                             Sweets       0.72      0.64      0.68        97\n",
      "  Vegetables and Vegetable Products       0.80      0.81      0.81       227\n",
      "\n",
      "                          micro avg       0.78      0.78      0.78      2454\n",
      "                          macro avg       0.74      0.76      0.74      2454\n",
      "                       weighted avg       0.80      0.78      0.79      2454\n",
      "\n",
      "nn with 64 nodes in the hidden layer:    acc=0.7942135289323553\n",
      "nn with 64 nodes in the hidden layer:    acc=                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.43      0.51      0.47        47\n",
      "                         Baby Foods       0.76      0.62      0.69       112\n",
      "                     Baked Products       0.92      0.79      0.85       229\n",
      "                      Beef Products       0.95      0.93      0.94       286\n",
      "                          Beverages       0.75      0.68      0.71        90\n",
      "                  Breakfast Cereals       0.85      0.87      0.86       115\n",
      "            Cereal Grains and Pasta       0.55      0.94      0.69        50\n",
      "             Dairy and Egg Products       0.78      0.88      0.83        86\n",
      "                         Fast Foods       0.82      0.66      0.73       114\n",
      "                      Fats and Oils       0.87      0.87      0.87        55\n",
      "     Finfish and Shellfish Products       0.87      0.86      0.86        70\n",
      "            Fruits and Fruit Juices       0.69      0.68      0.69        87\n",
      "      Lamb, Veal, and Game Products       0.78      0.84      0.81       106\n",
      "        Legumes and Legume Products       0.82      0.82      0.82       108\n",
      "    Meals, Entrees, and Side Dishes       0.38      0.59      0.47        34\n",
      "              Nut and Seed Products       0.79      0.87      0.83        47\n",
      "                      Pork Products       0.89      0.88      0.88        99\n",
      "                   Poultry Products       0.88      0.91      0.89       111\n",
      "                   Restaurant Foods       0.55      0.69      0.61        32\n",
      "        Sausages and Luncheon Meats       0.70      0.75      0.72        71\n",
      "                             Snacks       0.74      0.59      0.66        39\n",
      "         Soups, Sauces, and Gravies       0.81      0.71      0.76       118\n",
      "                   Spices and Herbs       0.52      0.62      0.57        24\n",
      "                             Sweets       0.68      0.77      0.72        97\n",
      "  Vegetables and Vegetable Products       0.85      0.81      0.83       227\n",
      "\n",
      "                          micro avg       0.79      0.79      0.79      2454\n",
      "                          macro avg       0.74      0.77      0.75      2454\n",
      "                       weighted avg       0.81      0.79      0.80      2454\n",
      "\n",
      "nn with 80 nodes in the hidden layer:    acc=0.8060309698451508\n",
      "nn with 80 nodes in the hidden layer:    acc=                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.49      0.47      0.48        47\n",
      "                         Baby Foods       0.75      0.68      0.71       112\n",
      "                     Baked Products       0.91      0.84      0.87       229\n",
      "                      Beef Products       0.96      0.92      0.94       286\n",
      "                          Beverages       0.57      0.83      0.68        90\n",
      "                  Breakfast Cereals       0.87      0.91      0.89       115\n",
      "            Cereal Grains and Pasta       0.73      0.88      0.80        50\n",
      "             Dairy and Egg Products       0.88      0.81      0.84        86\n",
      "                         Fast Foods       0.85      0.68      0.75       114\n",
      "                      Fats and Oils       0.78      0.89      0.83        55\n",
      "     Finfish and Shellfish Products       0.83      0.91      0.87        70\n",
      "            Fruits and Fruit Juices       0.65      0.75      0.70        87\n",
      "      Lamb, Veal, and Game Products       0.78      0.85      0.81       106\n",
      "        Legumes and Legume Products       0.81      0.81      0.81       108\n",
      "    Meals, Entrees, and Side Dishes       0.49      0.53      0.51        34\n",
      "              Nut and Seed Products       0.89      0.83      0.86        47\n",
      "                      Pork Products       0.93      0.91      0.92        99\n",
      "                   Poultry Products       0.84      0.95      0.89       111\n",
      "                   Restaurant Foods       0.53      0.78      0.63        32\n",
      "        Sausages and Luncheon Meats       0.84      0.69      0.76        71\n",
      "                             Snacks       0.70      0.67      0.68        39\n",
      "         Soups, Sauces, and Gravies       0.89      0.61      0.72       118\n",
      "                   Spices and Herbs       0.65      0.62      0.64        24\n",
      "                             Sweets       0.73      0.73      0.73        97\n",
      "  Vegetables and Vegetable Products       0.82      0.83      0.83       227\n",
      "\n",
      "                          micro avg       0.81      0.81      0.81      2454\n",
      "                          macro avg       0.77      0.78      0.77      2454\n",
      "                       weighted avg       0.82      0.81      0.81      2454\n",
      "\n",
      "nn with 96 nodes in the hidden layer:    acc=0.8137734311328443\n",
      "nn with 96 nodes in the hidden layer:    acc=                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.43      0.55      0.49        47\n",
      "                         Baby Foods       0.76      0.68      0.72       112\n",
      "                     Baked Products       0.94      0.84      0.89       229\n",
      "                      Beef Products       0.94      0.94      0.94       286\n",
      "                          Beverages       0.77      0.60      0.68        90\n",
      "                  Breakfast Cereals       0.83      0.91      0.87       115\n",
      "            Cereal Grains and Pasta       0.72      0.88      0.79        50\n",
      "             Dairy and Egg Products       0.86      0.84      0.85        86\n",
      "                         Fast Foods       0.79      0.74      0.76       114\n",
      "                      Fats and Oils       0.86      0.93      0.89        55\n",
      "     Finfish and Shellfish Products       0.90      0.91      0.91        70\n",
      "            Fruits and Fruit Juices       0.67      0.84      0.74        87\n",
      "      Lamb, Veal, and Game Products       0.85      0.83      0.84       106\n",
      "        Legumes and Legume Products       0.82      0.81      0.81       108\n",
      "    Meals, Entrees, and Side Dishes       0.63      0.65      0.64        34\n",
      "              Nut and Seed Products       0.71      0.87      0.78        47\n",
      "                      Pork Products       0.92      0.88      0.90        99\n",
      "                   Poultry Products       0.83      0.95      0.89       111\n",
      "                   Restaurant Foods       0.68      0.78      0.72        32\n",
      "        Sausages and Luncheon Meats       0.77      0.68      0.72        71\n",
      "                             Snacks       0.68      0.67      0.68        39\n",
      "         Soups, Sauces, and Gravies       0.75      0.74      0.74       118\n",
      "                   Spices and Herbs       0.40      0.67      0.50        24\n",
      "                             Sweets       0.73      0.74      0.74        97\n",
      "  Vegetables and Vegetable Products       0.91      0.80      0.85       227\n",
      "\n",
      "                          micro avg       0.81      0.81      0.81      2454\n",
      "                          macro avg       0.77      0.79      0.77      2454\n",
      "                       weighted avg       0.82      0.81      0.82      2454\n",
      "\n",
      "nn with 112 nodes in the hidden layer:    acc=0.8268133659331703\n",
      "nn with 112 nodes in the hidden layer:    acc=                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.45      0.55      0.50        47\n",
      "                         Baby Foods       0.75      0.62      0.68       112\n",
      "                     Baked Products       0.92      0.90      0.91       229\n",
      "                      Beef Products       0.92      0.95      0.93       286\n",
      "                          Beverages       0.72      0.84      0.78        90\n",
      "                  Breakfast Cereals       0.86      0.93      0.89       115\n",
      "            Cereal Grains and Pasta       0.79      0.82      0.80        50\n",
      "             Dairy and Egg Products       0.83      0.90      0.86        86\n",
      "                         Fast Foods       0.82      0.74      0.77       114\n",
      "                      Fats and Oils       0.91      0.89      0.90        55\n",
      "     Finfish and Shellfish Products       0.92      0.87      0.90        70\n",
      "            Fruits and Fruit Juices       0.70      0.75      0.72        87\n",
      "      Lamb, Veal, and Game Products       0.83      0.80      0.82       106\n",
      "        Legumes and Legume Products       0.87      0.83      0.85       108\n",
      "    Meals, Entrees, and Side Dishes       0.66      0.62      0.64        34\n",
      "              Nut and Seed Products       0.87      0.85      0.86        47\n",
      "                      Pork Products       0.98      0.84      0.90        99\n",
      "                   Poultry Products       0.80      0.95      0.87       111\n",
      "                   Restaurant Foods       0.65      0.75      0.70        32\n",
      "        Sausages and Luncheon Meats       0.81      0.72      0.76        71\n",
      "                             Snacks       0.82      0.69      0.75        39\n",
      "         Soups, Sauces, and Gravies       0.68      0.81      0.74       118\n",
      "                   Spices and Herbs       0.61      0.58      0.60        24\n",
      "                             Sweets       0.79      0.75      0.77        97\n",
      "  Vegetables and Vegetable Products       0.91      0.82      0.86       227\n",
      "\n",
      "                          micro avg       0.83      0.83      0.83      2454\n",
      "                          macro avg       0.79      0.79      0.79      2454\n",
      "                       weighted avg       0.83      0.83      0.83      2454\n",
      "\n",
      "nn with 128 nodes in the hidden layer:    acc=0.8243683781581093\n",
      "nn with 128 nodes in the hidden layer:    acc=                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.39      0.47      0.43        47\n",
      "                         Baby Foods       0.86      0.63      0.73       112\n",
      "                     Baked Products       0.90      0.92      0.91       229\n",
      "                      Beef Products       0.95      0.95      0.95       286\n",
      "                          Beverages       0.73      0.76      0.74        90\n",
      "                  Breakfast Cereals       0.85      0.90      0.87       115\n",
      "            Cereal Grains and Pasta       0.70      0.84      0.76        50\n",
      "             Dairy and Egg Products       0.71      0.91      0.80        86\n",
      "                         Fast Foods       0.84      0.70      0.77       114\n",
      "                      Fats and Oils       0.81      0.95      0.87        55\n",
      "     Finfish and Shellfish Products       0.95      0.80      0.87        70\n",
      "            Fruits and Fruit Juices       0.72      0.72      0.72        87\n",
      "      Lamb, Veal, and Game Products       0.85      0.84      0.84       106\n",
      "        Legumes and Legume Products       0.85      0.76      0.80       108\n",
      "    Meals, Entrees, and Side Dishes       0.67      0.65      0.66        34\n",
      "              Nut and Seed Products       0.87      0.85      0.86        47\n",
      "                      Pork Products       0.86      0.95      0.90        99\n",
      "                   Poultry Products       0.96      0.88      0.92       111\n",
      "                   Restaurant Foods       0.64      0.84      0.73        32\n",
      "        Sausages and Luncheon Meats       0.84      0.82      0.83        71\n",
      "                             Snacks       0.62      0.77      0.69        39\n",
      "         Soups, Sauces, and Gravies       0.70      0.83      0.76       118\n",
      "                   Spices and Herbs       0.63      0.50      0.56        24\n",
      "                             Sweets       0.77      0.57      0.65        97\n",
      "  Vegetables and Vegetable Products       0.88      0.88      0.88       227\n",
      "\n",
      "                          micro avg       0.82      0.82      0.82      2454\n",
      "                          macro avg       0.78      0.79      0.78      2454\n",
      "                       weighted avg       0.83      0.82      0.82      2454\n",
      "\n",
      "nn with 144 nodes in the hidden layer:    acc=0.8264058679706602\n",
      "nn with 144 nodes in the hidden layer:    acc=                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.41      0.57      0.48        47\n",
      "                         Baby Foods       0.83      0.63      0.72       112\n",
      "                     Baked Products       0.93      0.83      0.88       229\n",
      "                      Beef Products       0.94      0.95      0.94       286\n",
      "                          Beverages       0.72      0.81      0.76        90\n",
      "                  Breakfast Cereals       0.86      0.93      0.90       115\n",
      "            Cereal Grains and Pasta       0.68      0.88      0.77        50\n",
      "             Dairy and Egg Products       0.86      0.84      0.85        86\n",
      "                         Fast Foods       0.68      0.83      0.75       114\n",
      "                      Fats and Oils       0.86      0.89      0.88        55\n",
      "     Finfish and Shellfish Products       0.91      0.83      0.87        70\n",
      "            Fruits and Fruit Juices       0.79      0.67      0.72        87\n",
      "      Lamb, Veal, and Game Products       0.89      0.82      0.85       106\n",
      "        Legumes and Legume Products       0.87      0.83      0.85       108\n",
      "    Meals, Entrees, and Side Dishes       0.68      0.56      0.61        34\n",
      "              Nut and Seed Products       0.85      0.85      0.85        47\n",
      "                      Pork Products       0.90      0.92      0.91        99\n",
      "                   Poultry Products       0.91      0.95      0.93       111\n",
      "                   Restaurant Foods       0.63      0.84      0.72        32\n",
      "        Sausages and Luncheon Meats       0.90      0.66      0.76        71\n",
      "                             Snacks       0.67      0.82      0.74        39\n",
      "         Soups, Sauces, and Gravies       0.72      0.77      0.74       118\n",
      "                   Spices and Herbs       0.76      0.54      0.63        24\n",
      "                             Sweets       0.88      0.67      0.76        97\n",
      "  Vegetables and Vegetable Products       0.84      0.90      0.87       227\n",
      "\n",
      "                          micro avg       0.83      0.83      0.83      2454\n",
      "                          macro avg       0.80      0.79      0.79      2454\n",
      "                       weighted avg       0.84      0.83      0.83      2454\n",
      "\n",
      "nn with 160 nodes in the hidden layer:    acc=0.8207008964955175\n",
      "nn with 160 nodes in the hidden layer:    acc=                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.45      0.47      0.46        47\n",
      "                         Baby Foods       0.82      0.66      0.73       112\n",
      "                     Baked Products       0.95      0.82      0.88       229\n",
      "                      Beef Products       0.95      0.92      0.94       286\n",
      "                          Beverages       0.74      0.61      0.67        90\n",
      "                  Breakfast Cereals       0.89      0.90      0.89       115\n",
      "            Cereal Grains and Pasta       0.63      0.88      0.73        50\n",
      "             Dairy and Egg Products       0.82      0.90      0.86        86\n",
      "                         Fast Foods       0.75      0.80      0.77       114\n",
      "                      Fats and Oils       0.83      0.89      0.86        55\n",
      "     Finfish and Shellfish Products       0.95      0.80      0.87        70\n",
      "            Fruits and Fruit Juices       0.70      0.70      0.70        87\n",
      "      Lamb, Veal, and Game Products       0.78      0.88      0.82       106\n",
      "        Legumes and Legume Products       0.87      0.86      0.87       108\n",
      "    Meals, Entrees, and Side Dishes       0.70      0.62      0.66        34\n",
      "              Nut and Seed Products       0.95      0.79      0.86        47\n",
      "                      Pork Products       0.94      0.89      0.91        99\n",
      "                   Poultry Products       0.85      0.95      0.90       111\n",
      "                   Restaurant Foods       0.69      0.75      0.72        32\n",
      "        Sausages and Luncheon Meats       0.86      0.76      0.81        71\n",
      "                             Snacks       0.67      0.74      0.71        39\n",
      "         Soups, Sauces, and Gravies       0.81      0.76      0.79       118\n",
      "                   Spices and Herbs       0.39      0.67      0.49        24\n",
      "                             Sweets       0.79      0.67      0.73        97\n",
      "  Vegetables and Vegetable Products       0.79      0.94      0.86       227\n",
      "\n",
      "                          micro avg       0.82      0.82      0.82      2454\n",
      "                          macro avg       0.78      0.79      0.78      2454\n",
      "                       weighted avg       0.83      0.82      0.82      2454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(f'max f1:{min(results_nn_res, key=lambda x: results_nn_res[x][1])}\\n')\n",
    "for k, v in results_nn_res.items():\n",
    "    print(f\"nn with {k} nodes in the hidden layer:    acc={v[0]}\")\n",
    "    print(f\"nn with {k} nodes in the hidden layer:    acc={v[1]}\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.41      0.57      0.48        47\n",
      "                         Baby Foods       0.83      0.63      0.72       112\n",
      "                     Baked Products       0.93      0.83      0.88       229\n",
      "                      Beef Products       0.94      0.95      0.94       286\n",
      "                          Beverages       0.72      0.81      0.76        90\n",
      "                  Breakfast Cereals       0.86      0.93      0.90       115\n",
      "            Cereal Grains and Pasta       0.68      0.88      0.77        50\n",
      "             Dairy and Egg Products       0.86      0.84      0.85        86\n",
      "                         Fast Foods       0.68      0.83      0.75       114\n",
      "                      Fats and Oils       0.86      0.89      0.88        55\n",
      "     Finfish and Shellfish Products       0.91      0.83      0.87        70\n",
      "            Fruits and Fruit Juices       0.79      0.67      0.72        87\n",
      "      Lamb, Veal, and Game Products       0.89      0.82      0.85       106\n",
      "        Legumes and Legume Products       0.87      0.83      0.85       108\n",
      "    Meals, Entrees, and Side Dishes       0.68      0.56      0.61        34\n",
      "              Nut and Seed Products       0.85      0.85      0.85        47\n",
      "                      Pork Products       0.90      0.92      0.91        99\n",
      "                   Poultry Products       0.91      0.95      0.93       111\n",
      "                   Restaurant Foods       0.63      0.84      0.72        32\n",
      "        Sausages and Luncheon Meats       0.90      0.66      0.76        71\n",
      "                             Snacks       0.67      0.82      0.74        39\n",
      "         Soups, Sauces, and Gravies       0.72      0.77      0.74       118\n",
      "                   Spices and Herbs       0.76      0.54      0.63        24\n",
      "                             Sweets       0.88      0.67      0.76        97\n",
      "  Vegetables and Vegetable Products       0.84      0.90      0.87       227\n",
      "\n",
      "                          micro avg       0.83      0.83      0.83      2454\n",
      "                          macro avg       0.80      0.79      0.79      2454\n",
      "                       weighted avg       0.84      0.83      0.83      2454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#n=144 found to be working best by comparing f1 scores\n",
    "print(results_nn_res[144][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn with 16 nodes in the hidden layer:    acc=0.6104319478402608\n",
      "nn with 16 nodes in the hidden layer:    acc=                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.23      0.17      0.20        47\n",
      "                         Baby Foods       0.75      0.39      0.51       112\n",
      "                     Baked Products       0.92      0.70      0.79       229\n",
      "                      Beef Products       0.77      0.83      0.80       286\n",
      "                          Beverages       0.73      0.77      0.75        90\n",
      "                  Breakfast Cereals       0.88      0.77      0.82       115\n",
      "            Cereal Grains and Pasta       0.45      0.78      0.57        50\n",
      "             Dairy and Egg Products       0.69      0.65      0.67        86\n",
      "                         Fast Foods       0.45      0.13      0.20       114\n",
      "                      Fats and Oils       0.81      0.87      0.84        55\n",
      "     Finfish and Shellfish Products       0.58      0.83      0.68        70\n",
      "            Fruits and Fruit Juices       0.44      0.78      0.56        87\n",
      "      Lamb, Veal, and Game Products       0.57      0.39      0.46       106\n",
      "        Legumes and Legume Products       0.60      0.60      0.60       108\n",
      "    Meals, Entrees, and Side Dishes       0.27      0.50      0.35        34\n",
      "              Nut and Seed Products       0.66      0.81      0.72        47\n",
      "                      Pork Products       0.49      0.67      0.56        99\n",
      "                   Poultry Products       0.54      0.31      0.39       111\n",
      "                   Restaurant Foods       0.12      0.50      0.20        32\n",
      "        Sausages and Luncheon Meats       0.45      0.52      0.48        71\n",
      "                             Snacks       0.44      0.49      0.46        39\n",
      "         Soups, Sauces, and Gravies       0.64      0.69      0.66       118\n",
      "                   Spices and Herbs       0.36      0.58      0.44        24\n",
      "                             Sweets       0.73      0.57      0.64        97\n",
      "  Vegetables and Vegetable Products       0.75      0.55      0.63       227\n",
      "\n",
      "                          micro avg       0.61      0.61      0.61      2454\n",
      "                          macro avg       0.57      0.59      0.56      2454\n",
      "                       weighted avg       0.65      0.61      0.61      2454\n",
      "\n",
      "nn with 32 nodes in the hidden layer:    acc=0.6568867155664222\n",
      "nn with 32 nodes in the hidden layer:    acc=                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.25      0.32      0.28        47\n",
      "                         Baby Foods       0.57      0.53      0.55       112\n",
      "                     Baked Products       0.90      0.64      0.75       229\n",
      "                      Beef Products       0.84      0.79      0.82       286\n",
      "                          Beverages       0.75      0.57      0.65        90\n",
      "                  Breakfast Cereals       0.82      0.81      0.82       115\n",
      "            Cereal Grains and Pasta       0.43      0.88      0.58        50\n",
      "             Dairy and Egg Products       0.88      0.67      0.76        86\n",
      "                         Fast Foods       0.61      0.60      0.60       114\n",
      "                      Fats and Oils       0.84      0.93      0.88        55\n",
      "     Finfish and Shellfish Products       0.64      0.80      0.71        70\n",
      "            Fruits and Fruit Juices       0.54      0.66      0.59        87\n",
      "      Lamb, Veal, and Game Products       0.61      0.54      0.57       106\n",
      "        Legumes and Legume Products       0.69      0.69      0.69       108\n",
      "    Meals, Entrees, and Side Dishes       0.31      0.53      0.39        34\n",
      "              Nut and Seed Products       0.66      0.79      0.72        47\n",
      "                      Pork Products       0.52      0.72      0.60        99\n",
      "                   Poultry Products       0.59      0.45      0.51       111\n",
      "                   Restaurant Foods       0.35      0.50      0.41        32\n",
      "        Sausages and Luncheon Meats       0.58      0.69      0.63        71\n",
      "                             Snacks       0.43      0.51      0.47        39\n",
      "         Soups, Sauces, and Gravies       0.76      0.70      0.73       118\n",
      "                   Spices and Herbs       0.26      0.62      0.37        24\n",
      "                             Sweets       0.64      0.70      0.67        97\n",
      "  Vegetables and Vegetable Products       0.81      0.56      0.66       227\n",
      "\n",
      "                          micro avg       0.66      0.66      0.66      2454\n",
      "                          macro avg       0.61      0.65      0.62      2454\n",
      "                       weighted avg       0.69      0.66      0.66      2454\n",
      "\n",
      "nn with 48 nodes in the hidden layer:    acc=0.7041564792176039\n",
      "nn with 48 nodes in the hidden layer:    acc=                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.35      0.47      0.40        47\n",
      "                         Baby Foods       0.70      0.55      0.62       112\n",
      "                     Baked Products       0.90      0.81      0.85       229\n",
      "                      Beef Products       0.90      0.73      0.81       286\n",
      "                          Beverages       0.63      0.81      0.71        90\n",
      "                  Breakfast Cereals       0.90      0.86      0.88       115\n",
      "            Cereal Grains and Pasta       0.55      0.82      0.66        50\n",
      "             Dairy and Egg Products       0.77      0.71      0.74        86\n",
      "                         Fast Foods       0.70      0.54      0.61       114\n",
      "                      Fats and Oils       0.86      0.93      0.89        55\n",
      "     Finfish and Shellfish Products       0.67      0.80      0.73        70\n",
      "            Fruits and Fruit Juices       0.59      0.79      0.68        87\n",
      "      Lamb, Veal, and Game Products       0.52      0.61      0.57       106\n",
      "        Legumes and Legume Products       0.72      0.75      0.73       108\n",
      "    Meals, Entrees, and Side Dishes       0.35      0.50      0.41        34\n",
      "              Nut and Seed Products       0.71      0.89      0.79        47\n",
      "                      Pork Products       0.58      0.63      0.60        99\n",
      "                   Poultry Products       0.59      0.69      0.64       111\n",
      "                   Restaurant Foods       0.34      0.62      0.44        32\n",
      "        Sausages and Luncheon Meats       0.65      0.66      0.66        71\n",
      "                             Snacks       0.71      0.31      0.43        39\n",
      "         Soups, Sauces, and Gravies       0.84      0.64      0.72       118\n",
      "                   Spices and Herbs       0.61      0.58      0.60        24\n",
      "                             Sweets       0.69      0.78      0.73        97\n",
      "  Vegetables and Vegetable Products       0.79      0.67      0.72       227\n",
      "\n",
      "                          micro avg       0.70      0.70      0.70      2454\n",
      "                          macro avg       0.67      0.69      0.67      2454\n",
      "                       weighted avg       0.73      0.70      0.71      2454\n",
      "\n",
      "nn with 64 nodes in the hidden layer:    acc=0.6809290953545232\n",
      "nn with 64 nodes in the hidden layer:    acc=                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.36      0.49      0.41        47\n",
      "                         Baby Foods       0.59      0.61      0.60       112\n",
      "                     Baked Products       0.94      0.66      0.78       229\n",
      "                      Beef Products       0.92      0.53      0.68       286\n",
      "                          Beverages       0.69      0.74      0.72        90\n",
      "                  Breakfast Cereals       0.87      0.79      0.83       115\n",
      "            Cereal Grains and Pasta       0.55      0.88      0.68        50\n",
      "             Dairy and Egg Products       0.76      0.78      0.77        86\n",
      "                         Fast Foods       0.75      0.61      0.68       114\n",
      "                      Fats and Oils       0.80      0.96      0.88        55\n",
      "     Finfish and Shellfish Products       0.64      0.83      0.73        70\n",
      "            Fruits and Fruit Juices       0.62      0.69      0.66        87\n",
      "      Lamb, Veal, and Game Products       0.45      0.64      0.53       106\n",
      "        Legumes and Legume Products       0.78      0.64      0.70       108\n",
      "    Meals, Entrees, and Side Dishes       0.41      0.56      0.47        34\n",
      "              Nut and Seed Products       0.75      0.89      0.82        47\n",
      "                      Pork Products       0.57      0.52      0.54        99\n",
      "                   Poultry Products       0.51      0.81      0.62       111\n",
      "                   Restaurant Foods       0.39      0.62      0.48        32\n",
      "        Sausages and Luncheon Meats       0.77      0.66      0.71        71\n",
      "                             Snacks       0.45      0.69      0.55        39\n",
      "         Soups, Sauces, and Gravies       0.73      0.70      0.72       118\n",
      "                   Spices and Herbs       0.53      0.67      0.59        24\n",
      "                             Sweets       0.70      0.77      0.74        97\n",
      "  Vegetables and Vegetable Products       0.79      0.70      0.74       227\n",
      "\n",
      "                          micro avg       0.68      0.68      0.68      2454\n",
      "                          macro avg       0.65      0.70      0.66      2454\n",
      "                       weighted avg       0.72      0.68      0.69      2454\n",
      "\n",
      "nn with 80 nodes in the hidden layer:    acc=0.715158924205379\n",
      "nn with 80 nodes in the hidden layer:    acc=                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.34      0.23      0.28        47\n",
      "                         Baby Foods       0.73      0.58      0.65       112\n",
      "                     Baked Products       0.94      0.72      0.82       229\n",
      "                      Beef Products       0.83      0.85      0.84       286\n",
      "                          Beverages       0.46      0.87      0.60        90\n",
      "                  Breakfast Cereals       0.79      0.92      0.85       115\n",
      "            Cereal Grains and Pasta       0.53      0.82      0.64        50\n",
      "             Dairy and Egg Products       0.78      0.76      0.77        86\n",
      "                         Fast Foods       0.79      0.65      0.71       114\n",
      "                      Fats and Oils       0.80      0.93      0.86        55\n",
      "     Finfish and Shellfish Products       0.66      0.84      0.74        70\n",
      "            Fruits and Fruit Juices       0.67      0.62      0.64        87\n",
      "      Lamb, Veal, and Game Products       0.51      0.65      0.58       106\n",
      "        Legumes and Legume Products       0.74      0.81      0.77       108\n",
      "    Meals, Entrees, and Side Dishes       0.35      0.56      0.43        34\n",
      "              Nut and Seed Products       0.88      0.81      0.84        47\n",
      "                      Pork Products       0.79      0.57      0.66        99\n",
      "                   Poultry Products       0.66      0.73      0.69       111\n",
      "                   Restaurant Foods       0.40      0.53      0.46        32\n",
      "        Sausages and Luncheon Meats       0.81      0.59      0.68        71\n",
      "                             Snacks       0.66      0.54      0.59        39\n",
      "         Soups, Sauces, and Gravies       0.80      0.66      0.73       118\n",
      "                   Spices and Herbs       0.47      0.62      0.54        24\n",
      "                             Sweets       0.74      0.61      0.67        97\n",
      "  Vegetables and Vegetable Products       0.83      0.71      0.76       227\n",
      "\n",
      "                          micro avg       0.72      0.72      0.72      2454\n",
      "                          macro avg       0.68      0.69      0.67      2454\n",
      "                       weighted avg       0.74      0.72      0.72      2454\n",
      "\n",
      "nn with 96 nodes in the hidden layer:    acc=0.7233088834555828\n",
      "nn with 96 nodes in the hidden layer:    acc=                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.31      0.47      0.38        47\n",
      "                         Baby Foods       0.72      0.54      0.62       112\n",
      "                     Baked Products       0.94      0.73      0.83       229\n",
      "                      Beef Products       0.86      0.86      0.86       286\n",
      "                          Beverages       0.63      0.80      0.70        90\n",
      "                  Breakfast Cereals       0.81      0.88      0.85       115\n",
      "            Cereal Grains and Pasta       0.58      0.86      0.69        50\n",
      "             Dairy and Egg Products       0.77      0.76      0.76        86\n",
      "                         Fast Foods       0.68      0.70      0.69       114\n",
      "                      Fats and Oils       0.83      0.95      0.88        55\n",
      "     Finfish and Shellfish Products       0.66      0.84      0.74        70\n",
      "            Fruits and Fruit Juices       0.61      0.68      0.64        87\n",
      "      Lamb, Veal, and Game Products       0.73      0.58      0.64       106\n",
      "        Legumes and Legume Products       0.78      0.65      0.71       108\n",
      "    Meals, Entrees, and Side Dishes       0.47      0.53      0.50        34\n",
      "              Nut and Seed Products       0.84      0.79      0.81        47\n",
      "                      Pork Products       0.66      0.79      0.72        99\n",
      "                   Poultry Products       0.69      0.73      0.71       111\n",
      "                   Restaurant Foods       0.59      0.53      0.56        32\n",
      "        Sausages and Luncheon Meats       0.79      0.59      0.68        71\n",
      "                             Snacks       0.51      0.62      0.56        39\n",
      "         Soups, Sauces, and Gravies       0.73      0.69      0.71       118\n",
      "                   Spices and Herbs       0.30      0.62      0.41        24\n",
      "                             Sweets       0.73      0.78      0.76        97\n",
      "  Vegetables and Vegetable Products       0.80      0.64      0.71       227\n",
      "\n",
      "                          micro avg       0.72      0.72      0.72      2454\n",
      "                          macro avg       0.68      0.70      0.68      2454\n",
      "                       weighted avg       0.74      0.72      0.73      2454\n",
      "\n",
      "nn with 112 nodes in the hidden layer:    acc=0.721678891605542\n",
      "nn with 112 nodes in the hidden layer:    acc=                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.32      0.38      0.35        47\n",
      "                         Baby Foods       0.67      0.57      0.62       112\n",
      "                     Baked Products       0.90      0.79      0.84       229\n",
      "                      Beef Products       0.91      0.79      0.85       286\n",
      "                          Beverages       0.56      0.83      0.67        90\n",
      "                  Breakfast Cereals       0.79      0.90      0.84       115\n",
      "            Cereal Grains and Pasta       0.61      0.80      0.69        50\n",
      "             Dairy and Egg Products       0.80      0.77      0.78        86\n",
      "                         Fast Foods       0.79      0.58      0.67       114\n",
      "                      Fats and Oils       0.82      0.93      0.87        55\n",
      "     Finfish and Shellfish Products       0.67      0.87      0.76        70\n",
      "            Fruits and Fruit Juices       0.64      0.72      0.68        87\n",
      "      Lamb, Veal, and Game Products       0.54      0.77      0.64       106\n",
      "        Legumes and Legume Products       0.64      0.79      0.71       108\n",
      "    Meals, Entrees, and Side Dishes       0.51      0.53      0.52        34\n",
      "              Nut and Seed Products       0.88      0.77      0.82        47\n",
      "                      Pork Products       0.76      0.48      0.59        99\n",
      "                   Poultry Products       0.55      0.74      0.63       111\n",
      "                   Restaurant Foods       0.45      0.69      0.54        32\n",
      "        Sausages and Luncheon Meats       0.75      0.61      0.67        71\n",
      "                             Snacks       0.65      0.67      0.66        39\n",
      "         Soups, Sauces, and Gravies       0.78      0.66      0.72       118\n",
      "                   Spices and Herbs       0.65      0.54      0.59        24\n",
      "                             Sweets       0.85      0.57      0.68        97\n",
      "  Vegetables and Vegetable Products       0.83      0.74      0.78       227\n",
      "\n",
      "                          micro avg       0.72      0.72      0.72      2454\n",
      "                          macro avg       0.69      0.70      0.69      2454\n",
      "                       weighted avg       0.74      0.72      0.72      2454\n",
      "\n",
      "nn with 128 nodes in the hidden layer:    acc=0.747758761206194\n",
      "nn with 128 nodes in the hidden layer:    acc=                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.30      0.40      0.34        47\n",
      "                         Baby Foods       0.68      0.64      0.66       112\n",
      "                     Baked Products       0.94      0.80      0.87       229\n",
      "                      Beef Products       0.80      0.90      0.85       286\n",
      "                          Beverages       0.64      0.77      0.70        90\n",
      "                  Breakfast Cereals       0.89      0.90      0.90       115\n",
      "            Cereal Grains and Pasta       0.56      0.88      0.69        50\n",
      "             Dairy and Egg Products       0.72      0.78      0.75        86\n",
      "                         Fast Foods       0.70      0.75      0.72       114\n",
      "                      Fats and Oils       0.85      0.93      0.89        55\n",
      "     Finfish and Shellfish Products       0.75      0.80      0.77        70\n",
      "            Fruits and Fruit Juices       0.65      0.69      0.67        87\n",
      "      Lamb, Veal, and Game Products       0.79      0.58      0.67       106\n",
      "        Legumes and Legume Products       0.69      0.77      0.72       108\n",
      "    Meals, Entrees, and Side Dishes       0.70      0.56      0.62        34\n",
      "              Nut and Seed Products       0.82      0.79      0.80        47\n",
      "                      Pork Products       0.74      0.56      0.64        99\n",
      "                   Poultry Products       0.63      0.76      0.69       111\n",
      "                   Restaurant Foods       0.58      0.47      0.52        32\n",
      "        Sausages and Luncheon Meats       0.73      0.63      0.68        71\n",
      "                             Snacks       0.62      0.67      0.64        39\n",
      "         Soups, Sauces, and Gravies       0.79      0.75      0.77       118\n",
      "                   Spices and Herbs       0.62      0.67      0.64        24\n",
      "                             Sweets       0.82      0.66      0.73        97\n",
      "  Vegetables and Vegetable Products       0.86      0.76      0.81       227\n",
      "\n",
      "                          micro avg       0.75      0.75      0.75      2454\n",
      "                          macro avg       0.71      0.71      0.71      2454\n",
      "                       weighted avg       0.76      0.75      0.75      2454\n",
      "\n",
      "nn with 144 nodes in the hidden layer:    acc=0.7555012224938875\n",
      "nn with 144 nodes in the hidden layer:    acc=                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.42      0.53      0.47        47\n",
      "                         Baby Foods       0.74      0.61      0.67       112\n",
      "                     Baked Products       0.93      0.81      0.86       229\n",
      "                      Beef Products       0.89      0.86      0.88       286\n",
      "                          Beverages       0.64      0.79      0.71        90\n",
      "                  Breakfast Cereals       0.82      0.92      0.87       115\n",
      "            Cereal Grains and Pasta       0.57      0.80      0.67        50\n",
      "             Dairy and Egg Products       0.80      0.78      0.79        86\n",
      "                         Fast Foods       0.76      0.68      0.72       114\n",
      "                      Fats and Oils       0.86      0.93      0.89        55\n",
      "     Finfish and Shellfish Products       0.77      0.80      0.78        70\n",
      "            Fruits and Fruit Juices       0.67      0.79      0.73        87\n",
      "      Lamb, Veal, and Game Products       0.61      0.74      0.67       106\n",
      "        Legumes and Legume Products       0.76      0.78      0.77       108\n",
      "    Meals, Entrees, and Side Dishes       0.57      0.50      0.53        34\n",
      "              Nut and Seed Products       0.92      0.77      0.84        47\n",
      "                      Pork Products       0.82      0.59      0.68        99\n",
      "                   Poultry Products       0.62      0.83      0.71       111\n",
      "                   Restaurant Foods       0.46      0.66      0.54        32\n",
      "        Sausages and Luncheon Meats       0.91      0.58      0.71        71\n",
      "                             Snacks       0.77      0.59      0.67        39\n",
      "         Soups, Sauces, and Gravies       0.80      0.72      0.76       118\n",
      "                   Spices and Herbs       0.39      0.67      0.49        24\n",
      "                             Sweets       0.74      0.75      0.74        97\n",
      "  Vegetables and Vegetable Products       0.83      0.74      0.78       227\n",
      "\n",
      "                          micro avg       0.76      0.76      0.76      2454\n",
      "                          macro avg       0.72      0.73      0.72      2454\n",
      "                       weighted avg       0.77      0.76      0.76      2454\n",
      "\n",
      "nn with 160 nodes in the hidden layer:    acc=0.7612061939690301\n",
      "nn with 160 nodes in the hidden layer:    acc=                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.50      0.36      0.42        47\n",
      "                         Baby Foods       0.74      0.57      0.64       112\n",
      "                     Baked Products       0.92      0.87      0.89       229\n",
      "                      Beef Products       0.86      0.92      0.89       286\n",
      "                          Beverages       0.63      0.73      0.68        90\n",
      "                  Breakfast Cereals       0.93      0.86      0.90       115\n",
      "            Cereal Grains and Pasta       0.74      0.74      0.74        50\n",
      "             Dairy and Egg Products       0.88      0.74      0.81        86\n",
      "                         Fast Foods       0.80      0.71      0.75       114\n",
      "                      Fats and Oils       0.86      0.93      0.89        55\n",
      "     Finfish and Shellfish Products       0.71      0.87      0.78        70\n",
      "            Fruits and Fruit Juices       0.62      0.77      0.69        87\n",
      "      Lamb, Veal, and Game Products       0.66      0.65      0.65       106\n",
      "        Legumes and Legume Products       0.80      0.68      0.73       108\n",
      "    Meals, Entrees, and Side Dishes       0.61      0.59      0.60        34\n",
      "              Nut and Seed Products       0.65      0.87      0.75        47\n",
      "                      Pork Products       0.66      0.72      0.69        99\n",
      "                   Poultry Products       0.74      0.60      0.66       111\n",
      "                   Restaurant Foods       0.51      0.66      0.58        32\n",
      "        Sausages and Luncheon Meats       0.73      0.63      0.68        71\n",
      "                             Snacks       0.75      0.62      0.68        39\n",
      "         Soups, Sauces, and Gravies       0.76      0.77      0.77       118\n",
      "                   Spices and Herbs       0.42      0.67      0.52        24\n",
      "                             Sweets       0.67      0.76      0.71        97\n",
      "  Vegetables and Vegetable Products       0.81      0.83      0.82       227\n",
      "\n",
      "                          micro avg       0.76      0.76      0.76      2454\n",
      "                          macro avg       0.72      0.72      0.72      2454\n",
      "                       weighted avg       0.77      0.76      0.76      2454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k, v in results_nn_pca.items():\n",
    "    print(f\"nn with {k} nodes in the hidden layer:    acc={v[0]}\")\n",
    "    print(f\"nn with {k} nodes in the hidden layer:    acc={v[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.42      0.53      0.47        47\n",
      "                         Baby Foods       0.74      0.61      0.67       112\n",
      "                     Baked Products       0.93      0.81      0.86       229\n",
      "                      Beef Products       0.89      0.86      0.88       286\n",
      "                          Beverages       0.64      0.79      0.71        90\n",
      "                  Breakfast Cereals       0.82      0.92      0.87       115\n",
      "            Cereal Grains and Pasta       0.57      0.80      0.67        50\n",
      "             Dairy and Egg Products       0.80      0.78      0.79        86\n",
      "                         Fast Foods       0.76      0.68      0.72       114\n",
      "                      Fats and Oils       0.86      0.93      0.89        55\n",
      "     Finfish and Shellfish Products       0.77      0.80      0.78        70\n",
      "            Fruits and Fruit Juices       0.67      0.79      0.73        87\n",
      "      Lamb, Veal, and Game Products       0.61      0.74      0.67       106\n",
      "        Legumes and Legume Products       0.76      0.78      0.77       108\n",
      "    Meals, Entrees, and Side Dishes       0.57      0.50      0.53        34\n",
      "              Nut and Seed Products       0.92      0.77      0.84        47\n",
      "                      Pork Products       0.82      0.59      0.68        99\n",
      "                   Poultry Products       0.62      0.83      0.71       111\n",
      "                   Restaurant Foods       0.46      0.66      0.54        32\n",
      "        Sausages and Luncheon Meats       0.91      0.58      0.71        71\n",
      "                             Snacks       0.77      0.59      0.67        39\n",
      "         Soups, Sauces, and Gravies       0.80      0.72      0.76       118\n",
      "                   Spices and Herbs       0.39      0.67      0.49        24\n",
      "                             Sweets       0.74      0.75      0.74        97\n",
      "  Vegetables and Vegetable Products       0.83      0.74      0.78       227\n",
      "\n",
      "                          micro avg       0.76      0.76      0.76      2454\n",
      "                          macro avg       0.72      0.73      0.72      2454\n",
      "                       weighted avg       0.77      0.76      0.76      2454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#n=144 found to be working best by comparing f1 scores\n",
    "print(results_nn_pca[144][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn with 16 nodes in the hidden layer:    acc=0.6764466177669112\n",
      "nn with 16 nodes in the hidden layer:    acc=                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.31      0.34      0.33        47\n",
      "                         Baby Foods       0.63      0.43      0.51       112\n",
      "                     Baked Products       0.92      0.65      0.76       229\n",
      "                      Beef Products       0.93      0.81      0.86       286\n",
      "                          Beverages       0.53      0.73      0.61        90\n",
      "                  Breakfast Cereals       0.83      0.81      0.82       115\n",
      "            Cereal Grains and Pasta       0.46      0.72      0.56        50\n",
      "             Dairy and Egg Products       0.84      0.81      0.83        86\n",
      "                         Fast Foods       0.73      0.47      0.57       114\n",
      "                      Fats and Oils       0.80      0.87      0.83        55\n",
      "     Finfish and Shellfish Products       0.69      0.67      0.68        70\n",
      "            Fruits and Fruit Juices       0.53      0.69      0.60        87\n",
      "      Lamb, Veal, and Game Products       0.68      0.74      0.71       106\n",
      "        Legumes and Legume Products       0.66      0.69      0.68       108\n",
      "    Meals, Entrees, and Side Dishes       0.19      0.71      0.30        34\n",
      "              Nut and Seed Products       0.71      0.72      0.72        47\n",
      "                      Pork Products       0.77      0.80      0.78        99\n",
      "                   Poultry Products       0.68      0.79      0.73       111\n",
      "                   Restaurant Foods       0.26      0.47      0.33        32\n",
      "        Sausages and Luncheon Meats       0.62      0.70      0.66        71\n",
      "                             Snacks       0.47      0.44      0.45        39\n",
      "         Soups, Sauces, and Gravies       0.67      0.53      0.59       118\n",
      "                   Spices and Herbs       0.52      0.62      0.57        24\n",
      "                             Sweets       0.78      0.56      0.65        97\n",
      "  Vegetables and Vegetable Products       0.74      0.67      0.70       227\n",
      "\n",
      "                          micro avg       0.68      0.68      0.68      2454\n",
      "                          macro avg       0.64      0.66      0.63      2454\n",
      "                       weighted avg       0.72      0.68      0.69      2454\n",
      "\n",
      "nn with 32 nodes in the hidden layer:    acc=0.7135289323553382\n",
      "nn with 32 nodes in the hidden layer:    acc=                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.20      0.30      0.24        47\n",
      "                         Baby Foods       0.53      0.54      0.54       112\n",
      "                     Baked Products       0.88      0.81      0.84       229\n",
      "                      Beef Products       0.93      0.83      0.88       286\n",
      "                          Beverages       0.55      0.72      0.62        90\n",
      "                  Breakfast Cereals       0.83      0.83      0.83       115\n",
      "            Cereal Grains and Pasta       0.53      0.84      0.65        50\n",
      "             Dairy and Egg Products       0.81      0.85      0.83        86\n",
      "                         Fast Foods       0.75      0.59      0.66       114\n",
      "                      Fats and Oils       0.85      0.93      0.89        55\n",
      "     Finfish and Shellfish Products       0.62      0.73      0.67        70\n",
      "            Fruits and Fruit Juices       0.67      0.71      0.69        87\n",
      "      Lamb, Veal, and Game Products       0.61      0.87      0.72       106\n",
      "        Legumes and Legume Products       0.71      0.65      0.68       108\n",
      "    Meals, Entrees, and Side Dishes       0.39      0.35      0.37        34\n",
      "              Nut and Seed Products       0.69      0.81      0.75        47\n",
      "                      Pork Products       0.83      0.78      0.80        99\n",
      "                   Poultry Products       0.79      0.65      0.71       111\n",
      "                   Restaurant Foods       0.39      0.53      0.45        32\n",
      "        Sausages and Luncheon Meats       0.75      0.56      0.65        71\n",
      "                             Snacks       0.45      0.54      0.49        39\n",
      "         Soups, Sauces, and Gravies       0.67      0.61      0.64       118\n",
      "                   Spices and Herbs       0.56      0.62      0.59        24\n",
      "                             Sweets       0.77      0.61      0.68        97\n",
      "  Vegetables and Vegetable Products       0.80      0.72      0.76       227\n",
      "\n",
      "                          micro avg       0.71      0.71      0.71      2454\n",
      "                          macro avg       0.66      0.68      0.66      2454\n",
      "                       weighted avg       0.73      0.71      0.72      2454\n",
      "\n",
      "nn with 48 nodes in the hidden layer:    acc=0.7074164629176855\n",
      "nn with 48 nodes in the hidden layer:    acc=                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.33      0.34      0.33        47\n",
      "                         Baby Foods       0.45      0.71      0.56       112\n",
      "                     Baked Products       0.91      0.79      0.85       229\n",
      "                      Beef Products       0.95      0.74      0.83       286\n",
      "                          Beverages       0.61      0.67      0.63        90\n",
      "                  Breakfast Cereals       0.76      0.80      0.78       115\n",
      "            Cereal Grains and Pasta       0.62      0.76      0.68        50\n",
      "             Dairy and Egg Products       0.78      0.80      0.79        86\n",
      "                         Fast Foods       0.66      0.68      0.67       114\n",
      "                      Fats and Oils       0.82      0.91      0.86        55\n",
      "     Finfish and Shellfish Products       0.71      0.73      0.72        70\n",
      "            Fruits and Fruit Juices       0.57      0.46      0.51        87\n",
      "      Lamb, Veal, and Game Products       0.71      0.73      0.72       106\n",
      "        Legumes and Legume Products       0.69      0.74      0.71       108\n",
      "    Meals, Entrees, and Side Dishes       0.54      0.62      0.58        34\n",
      "              Nut and Seed Products       0.71      0.89      0.79        47\n",
      "                      Pork Products       0.89      0.74      0.81        99\n",
      "                   Poultry Products       0.54      0.92      0.68       111\n",
      "                   Restaurant Foods       0.50      0.53      0.52        32\n",
      "        Sausages and Luncheon Meats       0.69      0.69      0.69        71\n",
      "                             Snacks       0.61      0.56      0.59        39\n",
      "         Soups, Sauces, and Gravies       0.80      0.48      0.60       118\n",
      "                   Spices and Herbs       0.44      0.62      0.52        24\n",
      "                             Sweets       0.69      0.68      0.68        97\n",
      "  Vegetables and Vegetable Products       0.81      0.65      0.72       227\n",
      "\n",
      "                          micro avg       0.71      0.71      0.71      2454\n",
      "                          macro avg       0.67      0.69      0.67      2454\n",
      "                       weighted avg       0.73      0.71      0.71      2454\n",
      "\n",
      "nn with 64 nodes in the hidden layer:    acc=0.7424612876935616\n",
      "nn with 64 nodes in the hidden layer:    acc=                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.31      0.34      0.32        47\n",
      "                         Baby Foods       0.63      0.61      0.62       112\n",
      "                     Baked Products       0.92      0.79      0.85       229\n",
      "                      Beef Products       0.94      0.89      0.92       286\n",
      "                          Beverages       0.52      0.81      0.63        90\n",
      "                  Breakfast Cereals       0.80      0.89      0.84       115\n",
      "            Cereal Grains and Pasta       0.59      0.82      0.68        50\n",
      "             Dairy and Egg Products       0.78      0.85      0.82        86\n",
      "                         Fast Foods       0.73      0.70      0.71       114\n",
      "                      Fats and Oils       0.89      0.87      0.88        55\n",
      "     Finfish and Shellfish Products       0.79      0.64      0.71        70\n",
      "            Fruits and Fruit Juices       0.57      0.77      0.66        87\n",
      "      Lamb, Veal, and Game Products       0.64      0.89      0.74       106\n",
      "        Legumes and Legume Products       0.74      0.78      0.76       108\n",
      "    Meals, Entrees, and Side Dishes       0.70      0.47      0.56        34\n",
      "              Nut and Seed Products       0.80      0.83      0.81        47\n",
      "                      Pork Products       0.84      0.87      0.86        99\n",
      "                   Poultry Products       0.82      0.59      0.69       111\n",
      "                   Restaurant Foods       0.49      0.59      0.54        32\n",
      "        Sausages and Luncheon Meats       0.68      0.68      0.68        71\n",
      "                             Snacks       0.63      0.62      0.62        39\n",
      "         Soups, Sauces, and Gravies       0.63      0.73      0.68       118\n",
      "                   Spices and Herbs       0.48      0.54      0.51        24\n",
      "                             Sweets       0.75      0.60      0.67        97\n",
      "  Vegetables and Vegetable Products       0.90      0.62      0.74       227\n",
      "\n",
      "                          micro avg       0.74      0.74      0.74      2454\n",
      "                          macro avg       0.70      0.71      0.70      2454\n",
      "                       weighted avg       0.76      0.74      0.75      2454\n",
      "\n",
      "nn with 80 nodes in the hidden layer:    acc=0.7567237163814181\n",
      "nn with 80 nodes in the hidden layer:    acc=                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.32      0.30      0.31        47\n",
      "                         Baby Foods       0.57      0.72      0.64       112\n",
      "                     Baked Products       0.90      0.75      0.81       229\n",
      "                      Beef Products       0.93      0.87      0.90       286\n",
      "                          Beverages       0.73      0.60      0.66        90\n",
      "                  Breakfast Cereals       0.78      0.88      0.82       115\n",
      "            Cereal Grains and Pasta       0.76      0.58      0.66        50\n",
      "             Dairy and Egg Products       0.77      0.83      0.80        86\n",
      "                         Fast Foods       0.76      0.60      0.67       114\n",
      "                      Fats and Oils       0.81      0.93      0.86        55\n",
      "     Finfish and Shellfish Products       0.76      0.74      0.75        70\n",
      "            Fruits and Fruit Juices       0.62      0.70      0.66        87\n",
      "      Lamb, Veal, and Game Products       0.85      0.80      0.83       106\n",
      "        Legumes and Legume Products       0.72      0.73      0.73       108\n",
      "    Meals, Entrees, and Side Dishes       0.42      0.56      0.48        34\n",
      "              Nut and Seed Products       0.81      0.91      0.86        47\n",
      "                      Pork Products       0.81      0.87      0.84        99\n",
      "                   Poultry Products       0.83      0.81      0.82       111\n",
      "                   Restaurant Foods       0.39      0.69      0.49        32\n",
      "        Sausages and Luncheon Meats       0.68      0.73      0.70        71\n",
      "                             Snacks       0.62      0.59      0.61        39\n",
      "         Soups, Sauces, and Gravies       0.77      0.73      0.75       118\n",
      "                   Spices and Herbs       0.74      0.58      0.65        24\n",
      "                             Sweets       0.75      0.67      0.71        97\n",
      "  Vegetables and Vegetable Products       0.77      0.84      0.81       227\n",
      "\n",
      "                          micro avg       0.76      0.76      0.76      2454\n",
      "                          macro avg       0.71      0.72      0.71      2454\n",
      "                       weighted avg       0.77      0.76      0.76      2454\n",
      "\n",
      "nn with 96 nodes in the hidden layer:    acc=0.7624286878565607\n",
      "nn with 96 nodes in the hidden layer:    acc=                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.28      0.38      0.32        47\n",
      "                         Baby Foods       0.71      0.48      0.57       112\n",
      "                     Baked Products       0.92      0.82      0.87       229\n",
      "                      Beef Products       0.90      0.94      0.92       286\n",
      "                          Beverages       0.57      0.76      0.65        90\n",
      "                  Breakfast Cereals       0.89      0.84      0.87       115\n",
      "            Cereal Grains and Pasta       0.64      0.82      0.72        50\n",
      "             Dairy and Egg Products       0.77      0.84      0.80        86\n",
      "                         Fast Foods       0.84      0.67      0.75       114\n",
      "                      Fats and Oils       0.78      0.91      0.84        55\n",
      "     Finfish and Shellfish Products       0.77      0.71      0.74        70\n",
      "            Fruits and Fruit Juices       0.61      0.71      0.66        87\n",
      "      Lamb, Veal, and Game Products       0.84      0.73      0.78       106\n",
      "        Legumes and Legume Products       0.80      0.59      0.68       108\n",
      "    Meals, Entrees, and Side Dishes       0.53      0.62      0.57        34\n",
      "              Nut and Seed Products       0.84      0.89      0.87        47\n",
      "                      Pork Products       0.73      0.92      0.81        99\n",
      "                   Poultry Products       0.81      0.78      0.80       111\n",
      "                   Restaurant Foods       0.64      0.78      0.70        32\n",
      "        Sausages and Luncheon Meats       0.83      0.63      0.72        71\n",
      "                             Snacks       0.57      0.59      0.58        39\n",
      "         Soups, Sauces, and Gravies       0.75      0.71      0.73       118\n",
      "                   Spices and Herbs       0.48      0.67      0.56        24\n",
      "                             Sweets       0.79      0.62      0.69        97\n",
      "  Vegetables and Vegetable Products       0.75      0.84      0.79       227\n",
      "\n",
      "                          micro avg       0.76      0.76      0.76      2454\n",
      "                          macro avg       0.72      0.73      0.72      2454\n",
      "                       weighted avg       0.78      0.76      0.76      2454\n",
      "\n",
      "nn with 112 nodes in the hidden layer:    acc=0.758761206193969\n",
      "nn with 112 nodes in the hidden layer:    acc=                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.25      0.43      0.31        47\n",
      "                         Baby Foods       0.54      0.75      0.62       112\n",
      "                     Baked Products       0.88      0.76      0.82       229\n",
      "                      Beef Products       0.94      0.92      0.93       286\n",
      "                          Beverages       0.66      0.63      0.64        90\n",
      "                  Breakfast Cereals       0.87      0.84      0.86       115\n",
      "            Cereal Grains and Pasta       0.55      0.86      0.67        50\n",
      "             Dairy and Egg Products       0.86      0.84      0.85        86\n",
      "                         Fast Foods       0.72      0.76      0.74       114\n",
      "                      Fats and Oils       0.84      0.95      0.89        55\n",
      "     Finfish and Shellfish Products       0.74      0.77      0.76        70\n",
      "            Fruits and Fruit Juices       0.66      0.68      0.67        87\n",
      "      Lamb, Veal, and Game Products       0.74      0.85      0.79       106\n",
      "        Legumes and Legume Products       0.81      0.79      0.80       108\n",
      "    Meals, Entrees, and Side Dishes       0.58      0.53      0.55        34\n",
      "              Nut and Seed Products       0.76      0.79      0.77        47\n",
      "                      Pork Products       0.81      0.87      0.84        99\n",
      "                   Poultry Products       0.81      0.79      0.80       111\n",
      "                   Restaurant Foods       0.52      0.53      0.52        32\n",
      "        Sausages and Luncheon Meats       0.73      0.66      0.70        71\n",
      "                             Snacks       0.62      0.64      0.63        39\n",
      "         Soups, Sauces, and Gravies       0.71      0.60      0.65       118\n",
      "                   Spices and Herbs       0.67      0.58      0.62        24\n",
      "                             Sweets       0.78      0.51      0.61        97\n",
      "  Vegetables and Vegetable Products       0.90      0.76      0.82       227\n",
      "\n",
      "                          micro avg       0.76      0.76      0.76      2454\n",
      "                          macro avg       0.72      0.72      0.72      2454\n",
      "                       weighted avg       0.78      0.76      0.76      2454\n",
      "\n",
      "nn with 128 nodes in the hidden layer:    acc=0.7819885900570497\n",
      "nn with 128 nodes in the hidden layer:    acc=                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.36      0.34      0.35        47\n",
      "                         Baby Foods       0.70      0.55      0.62       112\n",
      "                     Baked Products       0.93      0.81      0.87       229\n",
      "                      Beef Products       0.93      0.89      0.91       286\n",
      "                          Beverages       0.64      0.73      0.68        90\n",
      "                  Breakfast Cereals       0.84      0.91      0.87       115\n",
      "            Cereal Grains and Pasta       0.62      0.76      0.68        50\n",
      "             Dairy and Egg Products       0.83      0.80      0.82        86\n",
      "                         Fast Foods       0.78      0.74      0.76       114\n",
      "                      Fats and Oils       0.84      0.93      0.88        55\n",
      "     Finfish and Shellfish Products       0.79      0.74      0.76        70\n",
      "            Fruits and Fruit Juices       0.70      0.71      0.70        87\n",
      "      Lamb, Veal, and Game Products       0.75      0.83      0.79       106\n",
      "        Legumes and Legume Products       0.77      0.74      0.75       108\n",
      "    Meals, Entrees, and Side Dishes       0.57      0.59      0.58        34\n",
      "              Nut and Seed Products       0.84      0.81      0.83        47\n",
      "                      Pork Products       0.82      0.90      0.86        99\n",
      "                   Poultry Products       0.84      0.80      0.82       111\n",
      "                   Restaurant Foods       0.66      0.72      0.69        32\n",
      "        Sausages and Luncheon Meats       0.67      0.79      0.72        71\n",
      "                             Snacks       0.60      0.64      0.62        39\n",
      "         Soups, Sauces, and Gravies       0.72      0.79      0.75       118\n",
      "                   Spices and Herbs       0.65      0.62      0.64        24\n",
      "                             Sweets       0.67      0.74      0.71        97\n",
      "  Vegetables and Vegetable Products       0.86      0.81      0.84       227\n",
      "\n",
      "                          micro avg       0.78      0.78      0.78      2454\n",
      "                          macro avg       0.74      0.75      0.74      2454\n",
      "                       weighted avg       0.79      0.78      0.78      2454\n",
      "\n",
      "nn with 144 nodes in the hidden layer:    acc=0.7909535452322738\n",
      "nn with 144 nodes in the hidden layer:    acc=                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.29      0.45      0.35        47\n",
      "                         Baby Foods       0.71      0.65      0.68       112\n",
      "                     Baked Products       0.89      0.86      0.88       229\n",
      "                      Beef Products       0.94      0.93      0.93       286\n",
      "                          Beverages       0.73      0.73      0.73        90\n",
      "                  Breakfast Cereals       0.86      0.83      0.84       115\n",
      "            Cereal Grains and Pasta       0.72      0.82      0.77        50\n",
      "             Dairy and Egg Products       0.79      0.84      0.81        86\n",
      "                         Fast Foods       0.84      0.66      0.74       114\n",
      "                      Fats and Oils       0.91      0.89      0.90        55\n",
      "     Finfish and Shellfish Products       0.91      0.69      0.78        70\n",
      "            Fruits and Fruit Juices       0.71      0.63      0.67        87\n",
      "      Lamb, Veal, and Game Products       0.78      0.85      0.81       106\n",
      "        Legumes and Legume Products       0.71      0.83      0.77       108\n",
      "    Meals, Entrees, and Side Dishes       0.41      0.44      0.42        34\n",
      "              Nut and Seed Products       0.76      0.89      0.82        47\n",
      "                      Pork Products       0.90      0.87      0.88        99\n",
      "                   Poultry Products       0.78      0.82      0.80       111\n",
      "                   Restaurant Foods       0.70      0.88      0.78        32\n",
      "        Sausages and Luncheon Meats       0.78      0.69      0.73        71\n",
      "                             Snacks       0.68      0.64      0.66        39\n",
      "         Soups, Sauces, and Gravies       0.76      0.77      0.77       118\n",
      "                   Spices and Herbs       0.68      0.62      0.65        24\n",
      "                             Sweets       0.72      0.70      0.71        97\n",
      "  Vegetables and Vegetable Products       0.84      0.85      0.84       227\n",
      "\n",
      "                          micro avg       0.79      0.79      0.79      2454\n",
      "                          macro avg       0.75      0.75      0.75      2454\n",
      "                       weighted avg       0.80      0.79      0.79      2454\n",
      "\n",
      "nn with 160 nodes in the hidden layer:    acc=0.7791361043194784\n",
      "nn with 160 nodes in the hidden layer:    acc=                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.30      0.32      0.31        47\n",
      "                         Baby Foods       0.76      0.62      0.69       112\n",
      "                     Baked Products       0.90      0.78      0.84       229\n",
      "                      Beef Products       0.95      0.91      0.93       286\n",
      "                          Beverages       0.61      0.79      0.69        90\n",
      "                  Breakfast Cereals       0.83      0.87      0.85       115\n",
      "            Cereal Grains and Pasta       0.67      0.82      0.74        50\n",
      "             Dairy and Egg Products       0.87      0.88      0.88        86\n",
      "                         Fast Foods       0.74      0.75      0.74       114\n",
      "                      Fats and Oils       0.96      0.85      0.90        55\n",
      "     Finfish and Shellfish Products       0.83      0.63      0.72        70\n",
      "            Fruits and Fruit Juices       0.69      0.76      0.72        87\n",
      "      Lamb, Veal, and Game Products       0.67      0.88      0.76       106\n",
      "        Legumes and Legume Products       0.83      0.77      0.80       108\n",
      "    Meals, Entrees, and Side Dishes       0.49      0.68      0.57        34\n",
      "              Nut and Seed Products       0.76      0.87      0.81        47\n",
      "                      Pork Products       0.83      0.91      0.87        99\n",
      "                   Poultry Products       0.92      0.75      0.83       111\n",
      "                   Restaurant Foods       0.70      0.72      0.71        32\n",
      "        Sausages and Luncheon Meats       0.73      0.77      0.75        71\n",
      "                             Snacks       0.52      0.64      0.57        39\n",
      "         Soups, Sauces, and Gravies       0.67      0.70      0.69       118\n",
      "                   Spices and Herbs       0.62      0.62      0.62        24\n",
      "                             Sweets       0.71      0.70      0.70        97\n",
      "  Vegetables and Vegetable Products       0.88      0.77      0.82       227\n",
      "\n",
      "                          micro avg       0.78      0.78      0.78      2454\n",
      "                          macro avg       0.74      0.75      0.74      2454\n",
      "                       weighted avg       0.79      0.78      0.78      2454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k, v in results_nn_lda.items():\n",
    "    print(f\"nn with {k} nodes in the hidden layer:    acc={v[0]}\")\n",
    "    print(f\"nn with {k} nodes in the hidden layer:    acc={v[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     precision    recall  f1-score   support\n",
      "\n",
      "American Indian/Alaska Native Foods       0.29      0.45      0.35        47\n",
      "                         Baby Foods       0.71      0.65      0.68       112\n",
      "                     Baked Products       0.89      0.86      0.88       229\n",
      "                      Beef Products       0.94      0.93      0.93       286\n",
      "                          Beverages       0.73      0.73      0.73        90\n",
      "                  Breakfast Cereals       0.86      0.83      0.84       115\n",
      "            Cereal Grains and Pasta       0.72      0.82      0.77        50\n",
      "             Dairy and Egg Products       0.79      0.84      0.81        86\n",
      "                         Fast Foods       0.84      0.66      0.74       114\n",
      "                      Fats and Oils       0.91      0.89      0.90        55\n",
      "     Finfish and Shellfish Products       0.91      0.69      0.78        70\n",
      "            Fruits and Fruit Juices       0.71      0.63      0.67        87\n",
      "      Lamb, Veal, and Game Products       0.78      0.85      0.81       106\n",
      "        Legumes and Legume Products       0.71      0.83      0.77       108\n",
      "    Meals, Entrees, and Side Dishes       0.41      0.44      0.42        34\n",
      "              Nut and Seed Products       0.76      0.89      0.82        47\n",
      "                      Pork Products       0.90      0.87      0.88        99\n",
      "                   Poultry Products       0.78      0.82      0.80       111\n",
      "                   Restaurant Foods       0.70      0.88      0.78        32\n",
      "        Sausages and Luncheon Meats       0.78      0.69      0.73        71\n",
      "                             Snacks       0.68      0.64      0.66        39\n",
      "         Soups, Sauces, and Gravies       0.76      0.77      0.77       118\n",
      "                   Spices and Herbs       0.68      0.62      0.65        24\n",
      "                             Sweets       0.72      0.70      0.71        97\n",
      "  Vegetables and Vegetable Products       0.84      0.85      0.84       227\n",
      "\n",
      "                          micro avg       0.79      0.79      0.79      2454\n",
      "                          macro avg       0.75      0.75      0.75      2454\n",
      "                       weighted avg       0.80      0.79      0.79      2454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#n=144 found to be working best by comparing f1 scores\n",
    "print(results_nn_lda[144][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
